[
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/logos/youtube.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/logos/youtube.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/logos/youtube.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/logos/youtube.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/demo.png",
        "from": "resources/demo.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/logos/youtube.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/logos/youtube.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/vscode.png",
        "from": "resources/vscode.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/logos/youtube.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/logos/youtube.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/different-views.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/different-views.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/stitched.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/stitched.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/aruco_localisation.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/aruco_localisation.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/logos/youtube.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/logos/youtube.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/arm-humanoid.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/arm-humanoid.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/logos/INFOTIV-logo.png",
        "from": "resources/logos/INFOTIV-logo.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/logos/dyno-robotics.png",
        "from": "resources/logos/dyno-robotics.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/logos/RISE-logo.png",
        "from": "resources/logos/RISE-logo.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/logos/CHALMERS-logo.png",
        "from": "resources/logos/CHALMERS-logo.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/logos/volvo.jpg",
        "from": "resources/logos/volvo.jpg"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/eur-pall.gif"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/AMR.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/camera.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/blueprint_storage.drawio.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "../../resources/bird_eye_view.png",
        "from": "resources/pandoc/../../resources/bird_eye_view.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "../../resources/bird_eye_view_gazebo.png",
        "from": "resources/pandoc/../../resources/bird_eye_view_gazebo.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "images/SMILE_IV_Jackal-Simlan_bringup%20launch.drawio.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "view_frames.png",
        "from": "resources/view_frames.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "misc/human-model.png"
    },
    {
        "type": "Fetching",
        "verbosity": "INFO",
        "path": "https://github.com/user-attachments/assets/dafeaf9a-3c15-4b72-a21d-4f20b1897350"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/coordsystems_img.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/coordsystems_img.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "/resources/humanoid-static_agents-frames.png: withBinaryFile: does not exist (No such file or directory)\nReplacing image with description.",
        "path": "/resources/humanoid-static_agents-frames.png"
    },
    {
        "type": "Fetching",
        "verbosity": "INFO",
        "path": "https://github.com/ros-planning/moveit_resources/actions/workflows/format.yml/badge.svg?branch=ros2"
    },
    {
        "type": "Fetching",
        "verbosity": "INFO",
        "path": "https://github.com/ros-planning/moveit_resources/actions/workflows/industrial_ci_action.yml/badge.svg?branch=ros2"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/pose_translation.jpg"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/dataset_generation.jpg"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/ML.drawio.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/pose_landmarks_index.png",
        "from": "resources/pose_landmarks_index.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "resources/Normalisation.drawio.png"
    },
    {
        "type": "LoadedResource",
        "verbosity": "INFO",
        "for": "resources/dev-container-config.png",
        "from": "resources/dev-container-config.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "high-level_diagram_SIMLAN.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "Humanoid_mocap_flow.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "legend.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20aruco_localization%20multi_detection.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20camera_bird_eye_view%20bird_eye_view.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20moveit_resources_panda_moveit_config%20demo.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20pallet_truck_bringup%20multiple_robot_spawn.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20pallet_truck_navigation%20map_server.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20pallet_truck_navigation%20nav2.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20simlan_bringup%20sim.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20static_agent_launcher%20static-agent.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "ros2%20launch%20visualize_real_data%20scenario_replayer.launch.py.drawio.png"
    },
    {
        "type": "CouldNotFetchResource",
        "verbosity": "WARNING",
        "message": "replacing image with description",
        "path": "SIMLAN_DIAGRAM.drawio.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/6ab7e32c3ba9fa7057408343cfe4f032b465a356.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/9bfca26e6273a37f17835a52ff91641525f0ff54.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/e8a09be72e11a866194f7707b75f7abd00dca027.svg"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/48329d94ff26faca975cc0beffe326b2d5846e63.svg"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/84e6c124fb61591f0124067dab47039400628e2c.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/demo.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/dev-container-config.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/logos/CHALMERS-logo.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/logos/INFOTIV-logo.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/logos/RISE-logo.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/logos/dyno-robotics.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/logos/volvo.jpg"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/pose_landmarks_index.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/resources/vscode.png"
    },
    {
        "type": "Extracting",
        "verbosity": "INFO",
        "path": "/tmp/media-e0c46393b624552d/view_frames.png"
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<br>"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "BlockNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<p align=\"center\">"
            ],
            "t": "RawBlock"
        }
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<img src=\"images/head_on_collision.png\" alt=\"Head-On Collision\" width=\"30%\">"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<img src=\"images/pallet_truck_side_collision.png\" alt=\"Pallet Truck Side Collision\" width=\"30%\">"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<img src=\"images/jackal_side_collision.png\" alt=\"Jackal Side Collision\" width=\"30%\">"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "BlockNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "</p>"
            ],
            "t": "RawBlock"
        }
    },
    {
        "type": "BlockNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<p align=\"center\">"
            ],
            "t": "RawBlock"
        }
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "<b>"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "InlineNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "</b>"
            ],
            "t": "RawInline"
        }
    },
    {
        "type": "BlockNotRendered",
        "verbosity": "INFO",
        "contents": {
            "c": [
                "html",
                "</p>"
            ],
            "t": "RawBlock"
        }
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "/tmp/media-e0c46393b624552d",
        "description": "Temp dir:"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "xelatex \"-halt-on-error\" \"-interaction\" \"nonstopmode\" \"-output-directory\" \"/tmp/media-e0c46393b624552d\" \"/tmp/media-e0c46393b624552d/input.tex\"",
        "description": "Command line:"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "(\"TEXINPUTS\",\"/tmp/media-e0c46393b624552d:\")\n(\"TEXMFOUTPUT\",\"/tmp/media-e0c46393b624552d\")\n(\"HOME\",\"/root\")\n(\"PATH\",\"/opt/texlive/texdir/bin/default:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\")\n(\"PWD\",\"/pandoc\")",
        "description": "Relevant environment variables:"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "% Options for packages loaded elsewhere\n\\PassOptionsToPackage{unicode}{hyperref}\n\\PassOptionsToPackage{hyphens}{url}\n\\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}\n\\documentclass[\n]{article}\n\\usepackage{xcolor}\n\\usepackage[margin=0.5in]{geometry}\n\\usepackage{amsmath,amssymb}\n\\setcounter{secnumdepth}{5}\n\\usepackage{iftex}\n\\ifPDFTeX\n  \\usepackage[T1]{fontenc}\n  \\usepackage[utf8]{inputenc}\n  \\usepackage{textcomp} % provide euro and other symbols\n\\else % if luatex or xetex\n  \\usepackage{unicode-math} % this also loads fontspec\n  \\defaultfontfeatures{Scale=MatchLowercase}\n  \\defaultfontfeatures[\\rmfamily]{Ligatures=TeX,Scale=1}\n\\fi\n\\usepackage{lmodern}\n\\ifPDFTeX\\else\n  % xetex/luatex font selection\n\\fi\n% Use upquote if available, for straight quotes in verbatim environments\n\\IfFileExists{upquote.sty}{\\usepackage{upquote}}{}\n\\IfFileExists{microtype.sty}{% use microtype if available\n  \\usepackage[]{microtype}\n  \\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts\n}{}\n\\makeatletter\n\\@ifundefined{KOMAClassName}{% if non-KOMA class\n  \\IfFileExists{parskip.sty}{%\n    \\usepackage{parskip}\n  }{% else\n    \\setlength{\\parindent}{0pt}\n    \\setlength{\\parskip}{6pt plus 2pt minus 1pt}}\n}{% if KOMA class\n  \\KOMAoptions{parskip=half}}\n\\makeatother\n\\usepackage{color}\n\\usepackage{fancyvrb}\n\\newcommand{\\VerbBar}{|}\n\\newcommand{\\VERB}{\\Verb[commandchars=\\\\\\{\\}]}\n\\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\\\\{\\}}\n% Add ',fontsize=\\small' for more characters per line\n\\usepackage{framed}\n\\definecolor{shadecolor}{RGB}{42,33,28}\n\\newenvironment{Shaded}{\\begin{snugshade}}{\\end{snugshade}}\n\\newcommand{\\AlertTok}[1]{\\textcolor[rgb]{1.00,1.00,0.00}{#1}}\n\\newcommand{\\AnnotationTok}[1]{\\textcolor[rgb]{0.00,0.40,1.00}{\\textbf{\\textit{#1}}}}\n\\newcommand{\\AttributeTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\BaseNTok}[1]{\\textcolor[rgb]{0.27,0.67,0.26}{#1}}\n\\newcommand{\\BuiltInTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\CharTok}[1]{\\textcolor[rgb]{0.02,0.61,0.04}{#1}}\n\\newcommand{\\CommentTok}[1]{\\textcolor[rgb]{0.00,0.40,1.00}{\\textbf{\\textit{#1}}}}\n\\newcommand{\\CommentVarTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\ConstantTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\ControlFlowTok}[1]{\\textcolor[rgb]{0.26,0.66,0.93}{\\textbf{#1}}}\n\\newcommand{\\DataTypeTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{\\underline{#1}}}\n\\newcommand{\\DecValTok}[1]{\\textcolor[rgb]{0.27,0.67,0.26}{#1}}\n\\newcommand{\\DocumentationTok}[1]{\\textcolor[rgb]{0.00,0.40,1.00}{\\textit{#1}}}\n\\newcommand{\\ErrorTok}[1]{\\textcolor[rgb]{1.00,1.00,0.00}{\\textbf{#1}}}\n\\newcommand{\\ExtensionTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\FloatTok}[1]{\\textcolor[rgb]{0.27,0.67,0.26}{#1}}\n\\newcommand{\\FunctionTok}[1]{\\textcolor[rgb]{1.00,0.58,0.35}{\\textbf{#1}}}\n\\newcommand{\\ImportTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\InformationTok}[1]{\\textcolor[rgb]{0.00,0.40,1.00}{\\textbf{\\textit{#1}}}}\n\\newcommand{\\KeywordTok}[1]{\\textcolor[rgb]{0.26,0.66,0.93}{\\textbf{#1}}}\n\\newcommand{\\NormalTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\OperatorTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\OtherTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\PreprocessorTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{\\textbf{#1}}}\n\\newcommand{\\RegionMarkerTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\SpecialCharTok}[1]{\\textcolor[rgb]{0.02,0.61,0.04}{#1}}\n\\newcommand{\\SpecialStringTok}[1]{\\textcolor[rgb]{0.02,0.61,0.04}{#1}}\n\\newcommand{\\StringTok}[1]{\\textcolor[rgb]{0.02,0.61,0.04}{#1}}\n\\newcommand{\\VariableTok}[1]{\\textcolor[rgb]{0.74,0.68,0.62}{#1}}\n\\newcommand{\\VerbatimStringTok}[1]{\\textcolor[rgb]{0.02,0.61,0.04}{#1}}\n\\newcommand{\\WarningTok}[1]{\\textcolor[rgb]{1.00,1.00,0.00}{\\textbf{#1}}}\n\\usepackage{longtable,booktabs,array}\n\\newcounter{none} % for unnumbered tables\n\\usepackage{calc} % for calculating minipage widths\n% Correct order of tables after \\paragraph or \\subparagraph\n\\usepackage{etoolbox}\n\\makeatletter\n\\patchcmd\\longtable{\\par}{\\if@noskipsec\\mbox{}\\fi\\par}{}{}\n\\makeatother\n% Allow footnotes in longtable head/foot\n\\IfFileExists{footnotehyper.sty}{\\usepackage{footnotehyper}}{\\usepackage{footnote}}\n\\makesavenoteenv{longtable}\n\\usepackage{graphicx}\n\\makeatletter\n\\newsavebox\\pandoc@box\n\\newcommand*\\pandocbounded[1]{% scales image to fit in text height/width\n  \\sbox\\pandoc@box{#1}%\n  \\Gscale@div\\@tempa{\\textheight}{\\dimexpr\\ht\\pandoc@box+\\dp\\pandoc@box\\relax}%\n  \\Gscale@div\\@tempb{\\linewidth}{\\wd\\pandoc@box}%\n  \\ifdim\\@tempb\\p@<\\@tempa\\p@\\let\\@tempa\\@tempb\\fi% select the smaller of both\n  \\ifdim\\@tempa\\p@<\\p@\\scalebox{\\@tempa}{\\usebox\\pandoc@box}%\n  \\else\\usebox{\\pandoc@box}%\n  \\fi%\n}\n% Set default figure placement to htbp\n\\def\\fps@figure{htbp}\n\\makeatother\n\\setlength{\\emergencystretch}{3em} % prevent overfull lines\n\\providecommand{\\tightlist}{%\n  \\setlength{\\itemsep}{0pt}\\setlength{\\parskip}{0pt}}\n\\usepackage{bookmark}\n\\IfFileExists{xurl.sty}{\\usepackage{xurl}}{} % add URL line breaks if available\n\\urlstyle{same}\n\\hypersetup{\n  colorlinks=true,\n  linkcolor={Maroon},\n  filecolor={Maroon},\n  citecolor={Blue},\n  urlcolor={NavyBlue},\n  pdfcreator={LaTeX via pandoc}}\n\n\\author{}\n\\date{}\n\n\\begin{document}\n\n{\n\\setcounter{tocdepth}{3}\n\\tableofcontents\n}\n\\section{SIMLAN, Simulation for Multi-Camera Robotics\n(3.0.0)}\\label{simlan-simulation-for-multi-camera-robotics-3.0.0}\n\nThis simulation environment, based on the Gazebo Ignition simulator and\nROS2, resembles a Volvo trucks warehouse and serves as a playground for\nrapid prototyping and testing of systems that rely on multi-camera setup\nfor perception, monitoring, localization or even navigation. This\nproject is inspired by\n\\href{https://www.volvogroup.com/en/news-and-media/news/2024/nov/ai-modern-manufacturing.html}{GPSS\n(Generic photo-based sensor system)} that utilizes ceiling mounted\ncameras, deep learning and computer vision algorithms, and very simple\ntransport robots.\n{[}\\href{https://www.youtube.com/watch?v=DA7lKiCdkCc}{{} GPSS demo}{]}\n\n\\subsection{\\texorpdfstring{SIMLAN Features\n{[}\\href{https://www.youtube.com/watch?v=mhA51PPdABc}{{} SIMLAN\ndemo}{]}}{SIMLAN Features {[} SIMLAN demo{]}}}\\label{simlan-features-simlan-demo}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Ignition Gazebo\n\\item\n  Library of assets\n\\item\n  Real-World environment inspired design (camera position and warehouse\n  layout)\n\\item\n  ROS 2 interfaces (Humble and Jazzy)\n\\item\n  ArUco marker localization\n\\item\n  Simple GPSS (Generic Photo-based Sensor System) navigation\n\\item\n  Multi-Robot localization and navigation using Nav2\n\\item\n  Bird’s-Eye view projection\n\\item\n  Multi-Sensor Support (LiDAR, RGB camera, semantic segmentation, Depth\n  etc.)\n\\item\n  Geofencing for safe zones and safestop on collision\n\\item\n  Motion capture for Human-Robot Collaboration/Interaction (HRC/HRI)\n\\end{itemize}\n\nPlease click the youTube link below to view the SIMLAN demo video:\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={SIMLAN, Simulation for Indoor Multi-Camera Localization and Navigation}]{/tmp/media-e0c46393b624552d/resources/demo.png}}\n\nHere are list of advantages of using SIMLAN Multi-Camera system\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Rapid prototyping and iteration of ML based algorithm.\n  (e.g.~reinforcement learning)\n\\item\n  Enhanced monitoring and coordination using bird eye view\n\\item\n  Simplified robot design and maintenance.\n\\item\n  Extendible with additional ML based vision systems\n\\item\n  Safety testing without physical risk or privacy concerns\n\\item\n  Scalable and reproducible testing (CI/CD)\n\\item\n  Cost-effective development\n\\end{itemize}\n\n\\subsection{\\texorpdfstring{Installation\n{[}\\href{https://www.youtube.com/watch?v=DgJXlsXUa-w}{{}\nDemo}{]}}{Installation {[} Demo{]}}}\\label{installation-demo}\n\n\\subsubsection{Dependencies}\\label{dependencies}\n\n\\textbf{Ubuntu 24.04:} use instruction in\n\\url{dependencies.md\\#linux-dependencies} to install docker and ensure\nthat your linux user account has \\texttt{docker} access.\n\\emph{Attention}: Make sure to restart the computer (for the changes in\ngroup membership to take effect.) before proceeding to the next step.\n\n\\textbf{Windows 11:} use instruction in\n\\url{dependencies.md\\#windows-dependencies} to install dependencies.\n\n\\textbf{Production environment}: follow installation procedure used in\n\\url{.devcontainer/Dockerfile} to install dependencies.\n\n\\textbf{Development environment}: to improve collaboration we use vscode\nand docker as explained in\n\\href{https://www.allisonthackston.com/articles/docker-development.html}{this\ninstruction} and \\href{https://github.com/athackst/dockerfiles}{docker\nfiles}. Install Visual Studio Code (VS Code) and open the project\nfolder. VS Code will prompt you to install the required extension\ndependencies. Make sure the \\texttt{Dev\\ containers} extension is\ninstalled. Reopen the project in VS Code, and you will be prompted to\nrebuild the container. Accept the prompt, this process may take a few\nminutes. Once VS Code is connected to Docker (as shown in the image\nbelow), open the terminal and run the following commands:\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={dev container in vscode}]{/tmp/media-e0c46393b624552d/resources/vscode.png}}\n\n(if you don’t see this try to build manually in vscode by pressing\n\\texttt{Ctrl\\ +\\ Shift\\ +\\ P} and select\n\\texttt{Dev\\ containers:\\ Rebuild\\ and\\ Reopen\\ in\\ container}. )\n\n\\subsubsection{Quick Start}\\label{quick-start}\n\nThe best place to learn about the various features, start different\ncomponents, and understand the project structure is\n\\href{./control.sh}{\\texttt{./control.sh}}.\n\n\\emph{Attention}: The following commands (using \\texttt{./control.sh})\nare executed in a separate terminal tab inside \\emph{vscode}.\n\nTo kill all the relevant process (related to gazebo, ros2), delete build\nfiles, delete recorded images and rosbag files using the following\ncommand:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ clean}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo clean up and build the ros2 simulation\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ build}\n\\end{Highlighting}\n\\end{Shaded}\n\n(optionally, in vscode you can click on Terminal-\\textgreater{} Run\nTask/Run build Task or use \\texttt{Ctrl\\ +\\ Shift\\ +\\ B})\n\n\\subsection{\\texorpdfstring{GPSS controls (pallet trucks, aruco)\n{[}\\href{https://www.youtube.com/watch?v=_UhRFR-L9iQ}{{}\nDemo}{]}}{GPSS controls (pallet trucks, aruco) {[} Demo{]}}}\\label{gpss-controls-pallet-trucks-aruco-demo}\n\nIt is possible for the cameras to detect ArUco markers on the floor and\npublish their location to TF, both relative to the camera, and the\nArUcos transform from origin. The package\n\\url{./camera_utility/aruco_localization} contain the code for handling\nArUco detection.\n\nYou can also use nav2 to make a robot\\_agent (that can be either\nrobot/pallet\\_truck) navigate by itself to a goal position. You can find\nthe code in \\url{simulation/pallet_truck/pallet_truck_navigation}\n\n\\textbf{Run these three in separate terminals}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ gpss }\\CommentTok{\\# spawn the simulation, robot\\_agents and GPSS ArUco detection}\n\\ExtensionTok{./control.sh}\\NormalTok{ nav  }\\CommentTok{\\# spawn map server, and separate nav2 stack in a separate namespace for each robot\\_agent}\n\\ExtensionTok{./control.sh}\\NormalTok{ send\\_goal }\\CommentTok{\\# send navigation goals to nav2 stack for each robot\\_agent}\n\\end{Highlighting}\n\\end{Shaded}\n\nIf you want to control any robot (pallet truck, humanoid, etc) manually\nyou can run the following command. Remember to specify what robot you\nwant to control by adding its namespace as argument,\ni.e.~\\texttt{./control.sh\\ teleop\\ pallet\\_truck\\_1}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ teleop }\\VariableTok{$\\{YOUR\\_ROBOT\\_NAMESPACE\\}}\n\\end{Highlighting}\n\\end{Shaded}\n\nIf you want to record any of your topics during the tests you can run\nthe following command. Change the topic in the control.sh script:\n\\texttt{ros2\\ bag\\ record\\ /topic} to whatever topic you want to record.\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ ros\\_record}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo replay your latest recorded rosbag run the following command:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ ros\\_replay}\n\\end{Highlighting}\n\\end{Shaded}\n\nIf you want to do a camera dump and save the image from each camera as a\n.png run the following command. The images will appear at\n\\texttt{/src/camera\\_utility/camera\\_number}.\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ camera\\_dump}\n\\end{Highlighting}\n\\end{Shaded}\n\n{}\n\nIf you want to take a screenshot of one of the cameras view, run the\nfollowing command. Replace \\texttt{\\#\\#\\#} with the camera you want to\ntake a screenshot of. (163, 164, 165 or 166)\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ screenshot }\\CommentTok{\\#\\#\\#}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ birdeye}\n\\end{Highlighting}\n\\end{Shaded}\n\n{}\n\nIf you want to add the tf links between the cameras and the ArUco\nmarkers without running the \\texttt{gpss} command you can run the\nfollowing command. This is not that usable as the \\texttt{gpss} run this\nas well, but it can be good for debugging.\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ aruco\\_detection}\n\\end{Highlighting}\n\\end{Shaded}\n\nFinally, to view the bird’s-eye perspective from each camera, run the\nfollowing command and open \\texttt{rviz} Then, navigate to the scroll\nmenu to the left, and under “Camera” change the Topic\n\\texttt{/static\\_agents/camera\\_XXX/image\\_projected} topic to visualize\nthe corresponding camera feed:\n\n{}\n\n\\subsection{\\texorpdfstring{RITA controls (humanoid, robotic arm)\n{[}\\href{https://www.youtube.com/watch?v=EiCNiPeifPk}{{}\nDemo}{]}}{RITA controls (humanoid, robotic arm) {[} Demo{]}}}\\label{rita-controls-humanoid-robotic-arm-demo}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ humanoid}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo move humanoid around in the simulator\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ teleop }\\VariableTok{$\\{YOUR\\_HUMANOID\\_NAMESPACE\\}}\n\\end{Highlighting}\n\\end{Shaded}\n\n{}\n\n\\paragraph{Arm controls}\\label{arm-controls}\n\nSpawn the Panda arm inside SIMLAN and instruct it to pick and place a\nbox around with the following commands:\n\n\\begin{verbatim}\n./control panda\n./control plan_motion\n./control pick\n\\end{verbatim}\n\n\\subsection{Advanced options}\\label{advanced-options}\n\nSee \\url{resources/ISSUES.md} to learn about additional advanced options\nand to check known issues before reporting any issue or requesting new\nfeatures. To start the project \\textbf{without NVIDIA GPU} please\ncomment out these lines in \\texttt{docker-compose.yaml} as shown below:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n  \\CommentTok{\\#   runtime: nvidia}\n  \\CommentTok{\\#}\n  \\CommentTok{\\# factory\\_simulation\\_nvidia:}\n  \\CommentTok{\\#  \\textless{}\\textless{}: *research{-}base}\n  \\CommentTok{\\#  container\\_name: factory\\_simulation\\_nvidia}\n  \\CommentTok{\\#  runtime: nvidia}\n  \\CommentTok{\\#  deploy:}\n  \\CommentTok{\\#    resources:}\n  \\CommentTok{\\#      reservations:}\n  \\CommentTok{\\#        devices:}\n  \\CommentTok{\\#          {-} driver: nvidia}\n  \\CommentTok{\\#            count: \"all\"}\n  \\CommentTok{\\#            capabilities: [compute,utility,graphics,display]}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\texttt{camera\\_enabled\\_ids} specifies which cameras are enabled in the\nscene for ArUco code detection and birdeye view.\n\n\\subsubsection{Customized startup}\\label{customized-startup}\n\nIn \\texttt{config.sh} it is possible to customize your scenarios. From\nthere you can edit what world you want to run, how many cameras you want\nenabled, and also edit Humanoid related properties. Modifying these\nvariables are preferred, rather than modifying the \\texttt{control.sh}\nfile.\n\n\\subsubsection{World fidelity}\\label{world-fidelity}\n\nin the \\texttt{config.sh} script, you can adjust the world fidelity\n\nThe active worlds are:\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}ll@{}}\n\\toprule\\noalign{}\narguments & configuration \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{default} & Contains the default world with maximum objects \\\\\n\\texttt{medium} & Based on default but boxes are removed \\\\\n\\texttt{light} & Based on medium but shelves are removed \\\\\n\\texttt{empty} & Everything except the ground is removed \\\\\n\\end{longtable}\n}\n\n\\subsubsection{Filtering log output}\\label{filtering-log-output}\n\nIn \\texttt{config.sh} you can set the level of logs you want outputted\ninto the terminal. Per default it is set to “info” to allow all logs.\nPossible values are: “debug”, “info”, “warn”, and “error”. Setting it to\n“warn” filters out all debug and info messages. Additionally, to filter\nout specific lines you can add the phrase you want filtered, inside of\n\\texttt{log\\_blacklist.txt} and setting the \\texttt{log\\_level} flag to\n“warn” or “error” will start filtering out all phrases found in the\nblacklist.\n\n\\subsubsection{Older versions}\\label{older-versions}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\href{https://github.com/infotiv-research/SIMLAN/tree/gz_classic_humble}{\\texttt{gz\\_classic\\_humble}}\n  branch contain code for \\textbf{Gazebo Classic (Gazebo11)} that has\n  reached end-of-life (EOL).\n\\item\n  \\href{https://github.com/infotiv-research/SIMLAN/tree/ign_humble}{\\texttt{ign\\_humble}}\n  branch contain code for \\textbf{ROS2 humble \\& Gazebo ignition}, an\n  earlier version of this repository.\n\\end{itemize}\n\n\\subsection{Documentation}\\label{documentation}\n\nLearn more about the project by reading these documents:\n\n\\begin{itemize}\n\\item\n  \\href{control.sh}{\\texttt{control.sh} script} is a shortcut to run\n  different launch scripts, please also see\n  \\href{resources/diagrams/}{these diagram}.\n\\item\n  \\href{config.sh}{\\texttt{config.sh}} contains information about, which\n  world is loaded, which cameras are active, what and where the robots\n  are spawned.\n\\item\n  \\href{PRESENTATION.md}{Marp Markdown Presentation}\n\\item\n  \\href{simulation/pallet_truck/pallet_truck_navigation/README.md}{Pallet\n  Truck Navigation Documentation}\n\\item\n  \\href{camera_utility/}{Camera Utilities and notebooks}:\n  (\\href{camera_utility/camera_calib.ipynb}{Extrinsic/Intrinsic\n  calibrations} and \\href{camera_utility/projection.ipynb}{Projection} )\n\\item\n  \\href{humanoid_utility/README.md}{Humanoid Utilities (pose2motion)}\n\\item\n  \\href{config_generation/README.md}{Configuration Generation}\n\\item\n  \\href{simulation/}{\\texttt{simulation/}}: ROS2 packages\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\href{simulation/README.md}{Simulation and Warehouse Specification\n    (fidelity)}\n  \\item\n    \\href{simulation/raw_models/README.md}{Building Gazebo models\n    (Blender/Phobos)}\n  \\item\n    \\href{simulation/raw_models/objects/README.md}{Objects\n    Specifications}\n  \\item\n    \\href{simulation/raw_models/warehouse/README.md}{Warehouse\n    Specification}\n  \\item\n    \\href{simulation/aruco_localization/README.md}{Aruco Localization\n    Documentation}\n  \\item\n    \\href{simulation/humanoid_robot/}{humanoid\\_robot Simulation}\n  \\item\n    \\href{simulation/bt_failsafe/README.md}{Geofencing and Collision\n    safe stop}\n  \\item\n    \\href{simulation/visualize_real_data/README.md}{Visualize Real Data}\n    \\textbf{requires data from Volvo}\n  \\item\n    \\href{simulation/humanoid_support_moveit_config/README.md}{Humanoid\n    Control}\n  \\end{itemize}\n\\item\n  \\href{CHANGELOG.md}{\\texttt{CHANGELOG.md}}\n\\item\n  \\href{credits.md}{\\texttt{credits.md}}\n\\item\n  \\href{LICENSE}{\\texttt{LICENSE} (apache 2)}\n\\item\n  \\href{contributing.md}{\\texttt{contributing.md}}\n\\end{itemize}\n\n\\subsection{Research Funding}\\label{research-funding}\n\nThis work was carried out within these research projects:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  The \\href{https://www.vinnova.se/p/smile-iv/}{SMILE IV} project\n  financed by Vinnova, FFI, Fordonsstrategisk forskning och innovation\n  under the grant number 2023-00789.\n\\item\n  The EUREKA ITEA4\n  \\href{https://www.vinnova.se/p/artwork---the-smart-and-connected-worker/}{ArtWork}\n  - The smart and connected worker financed by Vinnova under the grant\n  number 2023-00970.\n\\end{itemize}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 8\\tabcolsep) * \\real{0.2090}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 8\\tabcolsep) * \\real{0.2147}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 8\\tabcolsep) * \\real{0.1921}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 8\\tabcolsep) * \\real{0.2147}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 8\\tabcolsep) * \\real{0.1695}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nINFOTIV AB\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDyno-robotics\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nRISE Research Institutes of Sweden\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nCHALMERS\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nVolvo Group\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\pandocbounded{\\includegraphics[keepaspectratio]{/tmp/media-e0c46393b624552d/resources/logos/INFOTIV-logo.png}}\n&\n\\pandocbounded{\\includegraphics[keepaspectratio]{/tmp/media-e0c46393b624552d/resources/logos/dyno-robotics.png}}\n&\n\\pandocbounded{\\includegraphics[keepaspectratio]{/tmp/media-e0c46393b624552d/resources/logos/RISE-logo.png}}\n&\n\\pandocbounded{\\includegraphics[keepaspectratio]{/tmp/media-e0c46393b624552d/resources/logos/CHALMERS-logo.png}}\n&\n\\pandocbounded{\\includegraphics[keepaspectratio]{/tmp/media-e0c46393b624552d/resources/logos/volvo.jpg}} \\\\\n\\end{longtable}\n}\n\n\\href{https://github.com/infotiv-research/SIMLAN}{SIMLAN} project is\nstarted and is currently maintained by\n\\href{https://github.com/ebadi}{Hamid Ebadi}. To see a complete list of\ncontributors see the \\href{CHANGELOG.md}{changelog}.\n\n\\subsubsection{3.1.0: Improvements (Dec 2025) - Supervisor: Hamid\nEbadi}\\label{improvements-dec-2025---supervisor-hamid-ebadi}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  System integration tests by Pär\n\\item\n  System diagram by Anton\n\\item\n  Pytorch model by Pär\n\\item\n  Improved doc and AutoGluon configuration by Marwa\n\\end{itemize}\n\n\\subsubsection{3.0.0: Jazzy, humanoid (Oct 2025) - Supervisor: Hamid\nEbadi}\\label{jazzy-humanoid-oct-2025---supervisor-hamid-ebadi}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Collision sensor: Anton Stigemyr Hill\n\\item\n  Automatically generated parameter-files for robot\\_agents and world\n  fidelity : Anton Stigemyr Hill\n\\item\n  Shared map and obstacle generation for robot\\_agents: Anton Stigemyr\n  Hill\n\\item\n  Geofencing and safety stop: David Espedalen\n\\item\n  Humanoid motion capture: Casparsson and Siyu Yi, Hamid Ebadi\n\\item\n  Humanoid integration (pymoveit2 to moveit\\_py): Siyu Yi, Pär Aronsson\n\\item\n  Mocap (humanoid) with multi-camera training pipeline: Siyu Yi, Pär\n  Aronsson\n\\item\n  Panda arm integration: Pär Aronsson\n\\item\n  Dyno-robotics trajectory replay integration, scenario: Sebastian\n  Olsson\n\\end{itemize}\n\n\\subsubsection{2.1.0: Namespace cleanup and multi-agent navigation (Aug\n2025) - Supervisor: Hamid\nEbadi}\\label{namespace-cleanup-and-multi-agent-navigation-aug-2025---supervisor-hamid-ebadi}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Implemented generic robot-agent control supporting multiple meshes\n  (e.g., pallet truck, forklift) and distinct ArUco IDs: Pär Aronsson\n\\item\n  Robot-agent and navigation2 (nav2) namespace: Pär Aronsson\n\\item\n  Multi-agent navigation capabilities using GPSS: Pär Aronsson\n\\end{itemize}\n\n\\subsubsection{2.0.0: GPSS (May 2025) - Supervisor: Hamid\nEbadi}\\label{gpss-may-2025---supervisor-hamid-ebadi}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Upgrade Gazebo from classic to ignition, adapting new sensors: Nazeeh\n  Alhosary\n\\item\n  Aruco\\_localization, added localization and nav2 to new robot: Pär\n  Aronsson\n\\item\n  Navigation: Pär Aronsson\n\\item\n  Bird’s Eye View ros package: Converting projection.ipynb to\n  camera\\_bird\\_eye\\_view: Hamid Ebadi, Pär Aronsson\n\\item\n  Deprecated: Infobot, replaced with Pallet\\_truck (based on Jackal by\n  Clearpath Robotics)\n\\end{itemize}\n\n\\subsubsection{1.0.6: Collision (Feb 2025)}\\label{collision-feb-2025}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Add scenario execution library for ros2\n\\item\n  Add action servers for set\\_speed, teleport\\_robot and collision\n\\item\n  Add Node for TTC calculation\n\\item\n  Add package for custom messages\n\\end{itemize}\n\n\\subsubsection{1.0.5: Delivery 4 (Dec 2024)}\\label{delivery-4-dec-2024}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  D3.5 Disentanglement: One-parameter Object Movements.\n\\item\n  Trajectory visualization : Hamid Ebadi\n\\item\n  feat: added DynoWaitFor to make sure Jackal is launched last\n  (synchronisation issue)\n\\item\n  simlan\\_bringup pkg created : Christoffer Johannesson\n\\end{itemize}\n\n\\subsubsection{1.0.4: Delivery 3 (Oct 2024)}\\label{delivery-3-oct-2024}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  SMILE-IV and ArtWork projects contributions\n\\item\n  Updated camera extrinsic, fixing OpenCV camera calibration to Gazebo\n  simulator conversion : Erik Brorsson, Volvo\n\\item\n  D3.4 Out distribution data collection : Hamid Ebadi\n\\item\n  D3.3 In distribution data collection : Hamid Ebadi\n\\item\n  D3.2 Images for stitching : Hamid Ebadi\n\\item\n  D3.1 Dataset draft for HH : Hamid Ebadi\n\\item\n  CI/CD and Kubernetes integration by Filip Melberg, Vasiliki Kostara\n\\item\n  Jackal integration : Christoffer Johannesson, Hjalmar Ruscck\n\\item\n  Docker/vscode\n\\item\n  Disable GPU support by default\n\\item\n  POC for camera projection to pixel coordinates (jupyter notebook) :\n  Hamid Ebadi\n\\item\n  Camera image dump and image stitching : Hamid Ebadi\n\\end{itemize}\n\n\\subsubsection{1.0.3: Jackal Robot (Mar 2024) - Christoffer\nJohannesson}\\label{jackal-robot-mar-2024---christoffer-johannesson}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Added dyno fork of jackal repo from Clearpath Robotics.\n\\item\n  Updated to Humble, added bringup and support for namespacing. Jackal\n  can be spawned in Gazebo and controlled through the keyboard.\n\\item\n  Added .devcontainer folder with Dockerfile and devcontainer.json to\n  set up project container in VS Code.\n\\item\n  Added docker-compose to link all needed files and set environment\n  variables.\n\\item\n  Added .vscode folder with settings and tasks for easy building of the\n  project.\n\\item\n  Updated README with info on how to use Docker setup in VS Code, and\n  some features to make it easy to share the same setup with others.\n\\item\n  Features includes: python3 dependency install with pip, cloning of\n  other git repositories and how to make changes to those repositories.\n\\end{itemize}\n\n\\subsubsection{1.0.2: Delivery 2 (Feb 2024)}\\label{delivery-2-feb-2024}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Volvo warehouse 0.0.1 : Hamid Ebadi\n\\item\n  Volvo camera calibration in Gazebo 0.0.1 : Hamid Ebadi\n\\item\n  Integrate Infobot\\_agent 0.0.2: InfoBot differential-drive AMR\n  (Autonomous Mobile Robot) URDF and ROS launcher (GOPAL and forklift):\n  Hamid Ebadi\n\\item\n  Integrate Infobot\\_cartographer 2.1.5: cartographer for creating PGM\n  maps\n\\item\n  Integrate nav2\\_commander 0.0.2: ROS package to command Infobot where\n  the destination is : Hamid Ebadi\n\\item\n  Integrate Infobot\\_navigation2 2.1.5: Standard Nav2 stack launcher :\n  Hamid Ebadi\n\\item\n  Integrate Infobot\\_teleop 0.0.2: Teleoperation for InfotBot\n\\end{itemize}\n\n\\subsubsection{1.0.1: Delivery 1 (Dec 2023) - Supervisor: Hamid\nEbadi}\\label{delivery-1-dec-2023---supervisor-hamid-ebadi}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Basic warehouse model 1.0.0: Anders Bäckelie\n\\item\n  CAD modelling (eur-pallet, boxes, shelf, support\\_pole, traffic-cone,\n  steel\\_drum) 1.0.0 : Jacob Rohdin\n\\item\n  Physics (collision, inertia), visuals and Gazebo compatible mesh\n  creation 1.0.0: Anders Bäckelie\n\\item\n  Walking actor using scripted trajectories 1.0.0 : Anders Bäckelie\n\\item\n  Infobot\\_Gazebo\\_environment 1.0.0: ROS2 launcher to start Gazebo\n  world : Hamid Ebadi\n\\item\n  static\\_agent\\_launcher 1.0.0: Camera and Aruco tags : Hamid Ebadi\n\\item\n  camera-viewer 1.0.0: Python code to get Gazebo camera feed : Hamid\n  Ebadi\n\\end{itemize}\n\n\\section{Linux Dependencies}\\label{linux-dependencies}\n\n\\subsection{nvidia Driver}\\label{nvidia-driver}\n\nUse ‘nvidia-smi’ to ensure that the right nvidia driver is installed. If\nyou have not installed \\textbf{Additional Drivers} when installing\nUbuntu, you need to manually install nvidia drivers.\n\n\\subsection{Docker}\\label{docker}\n\n\\begin{verbatim}\nsudo apt install curl git\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\nsudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n\\end{verbatim}\n\n\\subsection{nvidia-container-toolkit}\\label{nvidia-container-toolkit}\n\nTo install docker and \\texttt{nvidia-container-toolkit} use the\nfollowing commands:\n\n\\begin{verbatim}\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\nsudo apt-get update\n\nsudo apt-get install -y nvidia-container-toolkit\n\nsudo nvidia-ctk runtime configure --runtime=docker\n\nINFO[0000] Config file does not exist; using empty config\nINFO[0000] Wrote updated config to /etc/docker/daemon.json\nINFO[0000] It is recommended that docker daemon be restarted.\n\nsudo systemctl restart docker\n\nsudo nvidia-ctk runtime configure --runtime=containerd\n\nINFO[0000] Using config version 1\nINFO[0000] Using CRI runtime plugin name \"cri\"\nWARN[0000] could not infer options from runtimes [runc crun]; using defaults\nINFO[0000] Wrote updated config to /etc/containerd/config.toml\nINFO[0000] It is recommended that containerd daemon be restarted.\n\\end{verbatim}\n\nRestart the computer to apply the group and user changes.\n\nTo check for correct installation docker’s nvidia runtime:\n\n\\begin{verbatim}\ndocker info|grep -i runtime\n Runtimes: nvidia runc\n Default Runtime: runc\n\\end{verbatim}\n\nOtherwise you get the following error message in vscode:\n\\texttt{Error\\ response\\ from\\ daemon:\\ unknown\\ or\\ invalid\\ runtime\\ name:\\ nvidia}\n\nOn a \\textbf{host} machine’s terminal (\\textbf{not} inside Visual Studio\nCode terminal): \\texttt{xhost\\ +local:docker}.\n\n\\section{Windows Dependencies}\\label{windows-dependencies}\n\nThese instruction is tested on Windows 11, docker desktop for\nwindows-ARM64 and VScode.\n\nTo get the docker container up and running, download and install Docker\nDesktop for your system: https://www.docker.com/products/docker-desktop/\n\nWhen this is done, clone the repo and open the folder in VScode. Then\nyou should automatically be prompted to download and install VScode\nextensions which are needed and recommended for the project.\n\nOnce that is completed, make sure Docker Desktop ir running and then you\nshould be able to start the container environment in VScode by pressing\nCtrl+Shift+p and searching for Dev Containers: Rebuild and Reopen in\nContainer.\n\nTo make Gazebo’s and Rviz’s GUI be visible from the docker container to\nyour screen, download and install the following program:\nhttps://sourceforge.net/projects/vcxsrv/\n\nWhen this is done, start the XLaunch program and configure it with these\nsettings:\n\n\\paragraph{Select display settings}\\label{select-display-settings}\n\n◉ Multiple windows ◯ Fullscreen ◯ One large window ◯ One window without\ntitlebar\n\nDisplay number: -1\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\paragraph{Select how to start\nclients}\\label{select-how-to-start-clients}\n\n◉ Start no client ◯ Start a program ◯ Open session via XDMCP\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\paragraph{Extra settings}\\label{extra-settings}\n\n☑ Clipboard (optional) ☑ Primary Selection (optional) ☐ Native opengl ☑\nDisable access control\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\nBefore continuing, make sure Docker Desktop is running.\n\n\\subsection{Legal Notice}\\label{legal-notice}\n\nWhen contributing to this project, you must agree that you have authored\n100\\% of the content, that you have the necessary rights to the content\nand that the content you contribute may be provided under the project\nlicense.\n\n\\subsection{Contributing}\\label{contributing}\n\nWe try to use: -\n\\href{https://code.visualstudio.com/docs/devcontainers/containers}{Docker,\nvscode + dev-container extension} to developer inside a Container -\n\\href{https://www.markdownguide.org/tools/vscode/}{Markdown} for\ndocumentation -\n\\href{https://www.conventionalcommits.org/en/v1.0.0/}{Conventional\nCommits} for commit messages -\n\\href{https://pre-commit.com/}{pre-commit} for git pre-commit hooks and\nbasic QA - \\href{https://semver.org/}{Semantic Versioning} for\nversioning - \\href{https://github.com/jgraph/drawio-desktop}{Draw.io}\nfor drawing diagram for documentation\n\n\\subsection{Technical}\\label{technical}\n\n\\begin{itemize}\n\\item\n  Avoid optimization unless you have a clear, measurable performance\n  problem, as premature optimization can lead to overly complex and\n  unreadable code.\n\\item\n  \\href{https://peps.python.org/pep-0020/}{PEP 20 – The Zen of Python}\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Simple is better than complex.\n  \\item\n    Readability counts.\n  \\item\n    If the implementation is hard to explain, it’s a bad idea.\n  \\end{itemize}\n\\item\n  Please be generous in giving credit when using an image or a piece of\n  code created by others. Add a link to the original author in\n  \\url{credits.md}\n\\item\n  Avoid pushing binary files such as images, models, etc (use\n  .gitignore) specially if they are constantly changing.\n\\end{itemize}\n\n\\subsubsection{git}\\label{git}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Try avoid breaking the \\texttt{main} branch but don’t be obseesed with\n  having a perfect merge request. We can always revert back to the\n  working version or fix the issues. That is why we are using\n  \\texttt{git}.\n\\item\n  Follow this simple git process:\n\\end{itemize}\n\n\\begin{verbatim}\ngit checkout main\ngit pull\ngit checkout -b \"branch_name\"\n# update files\ngit commit -m \"conventional_commit_type: conventional_commit_message\"\ngit push\n# Create a pull request.\n\\end{verbatim}\n\ncommon commit\\_type:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  feat: Introduces a new feature.\n\\item\n  fix: Patches a bug or issue.\n\\item\n  chore: Routine maintenance or changes that don’t affect the app’s\n  functionality.\n\\item\n  docs: Documentation changes.\n\\end{itemize}\n\nconventional\\_commit\\_message: - A conventional commit message uses the\nimperative mood in the subject line\n\nexample of - feat(auth): add login functionality - fix(ui): resolve\nbutton color issue\n\n\\url{https://www.conventionalcommits.org}\n\n\\subsubsection{Misc}\\label{misc}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Don’t use absolute path. Your code should run correctly both inside\n  the VS Code Dev Container and independently outside of it.If you need\n  to modify a configuration file at build time, use relative paths from\n  the project root directory (avoid using “..” as it becomes hard to see\n  which scripts are using a specific directory).For ROS2 resources, use\n  \\texttt{get\\_package\\_share\\_directory(project\\_name)} to locate\n  package files.\n\\item\n  When adding a new feature, add it to control.sh. Otherwise,\n  \\texttt{control.sh} should remain unchanged.\n\\item\n  Any configuration that requires modification should be defined in\n  \\texttt{config.sh}\n\\end{itemize}\n\n\\subsubsection{Documentation}\\label{documentation-1}\n\nDocumentation is done in a markdown file. Try to keep our documentation\nclose to your code. Keep the documentation short and clear.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\texttt{\\#} : Only used once for the tile of the project\n\\item\n  \\texttt{\\#\\#} : usually once in each markdown file and usually share\n  semantic with the markdown filename.\n\\item\n  \\texttt{\\#\\#\\#} : Different topics, try to split your documentation\n  into at least 4 topics\n\\item\n  \\texttt{\\#\\#\\#\\#} : sub topics. Try to avoid when you can use simple\n  paragraphs\n\\end{itemize}\n\nFollow this subset of\n\\href{https://www.markdownguide.org/tools/vscode/}{Markdown} tags.\n\n\\subsection{automatically generated parameter\nfiles:}\\label{automatically-generated-parameter-files}\n\nWhen building the workspaces, the generation-scripts found in the\nscripts/ directory are run. These automatically generate the\n\\texttt{bt.xml}, \\texttt{control.yaml}, \\texttt{gz\\_bridge.yaml},\n\\texttt{nav2\\_params.yaml}, aswell as validates the setup of the\n\\texttt{ROBOTS} list in the \\texttt{config.sh} script. This is done to\nautomatically set up the ros2 controllers, navigation stack parameters\nand other /topics depending on what robots and namespaces are spawned.\n\nEvery time the workspace is built, the \\texttt{generate\\_XXX} files\nprints that they were generated and at the top of each generated file, a\ncomment specifies from where the auto-generation occured. As of now the\nparameter files are saved in the package in which they’re used in\ninstead of directly in the share/ directory to increase code readability\nto new users.\n\nExplanation of the different generate\\_XXX files:\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 2\\tabcolsep) * \\real{0.4000}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 2\\tabcolsep) * \\real{0.6000}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nfile\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nexplanation\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{generate\\_bt\\_xml.py} & The bt\\_navigator needs to know which\nrobot it is checking conditions for, therefore the namespace of the\nrobot is needed \\\\\n\\texttt{generate\\_control\\_yaml.py} & The ros2\\_controller maps\n/cmd\\_vel topics to wheel\\_joint movements. Therefore the correct\nnamespace and frame\\_id are needed \\\\\n\\texttt{generate\\_gz\\_bridge\\_yaml.py} & Some gz\\_topics need to be\nmapped to ros2 topics. Therefore the corresponding namespaces are\nneeded \\\\\n\\texttt{generate\\_nav2\\_params\\_yaml.py} & The individual frame ids and\nsome ros2 topics are needed to define robots and their corresponding\nmaps \\\\\n\\texttt{validate\\_robots.py} & A converter from string to list of dicts\nincluding a sanity check to throw errors if the ROBOTS variable is\nwrongly configured \\\\\n\\end{longtable}\n}\n\n\\subsection{World Fidelity}\\label{world-fidelity-1}\n\nIt is possible to adjust the level fidelity for a world in\n\\texttt{config.sh}, there the \\texttt{world\\_setup} is sent to -\n\\texttt{simulation/simlan\\_bringup/launch/sim.launch.py}. -\n\\texttt{simulation/simlan\\_gazebo\\_environment/launch/simlan\\_factory.launch.py}\n(for world generation) -\n\\texttt{simulation/simlan\\_gazebo\\_environment/launch/generate\\_world\\_file.py}\n(both \\texttt{original\\_world} and the \\texttt{world\\_setup})\n\n\\subsection{Adding Aruco and camera (static\nagents)}\\label{adding-aruco-and-camera-static-agents}\n\nAruco codes and cameras are all attached to the same link in Gazebo. To\ncreate new static agents, go to\n\\texttt{simulation/static\\_agent\\_launcher/description/agents.urdf.xacro}.\nThere you only need to add a new line on the form\n\\texttt{\\textless{}xacro:camera\\ number=\"1\"\\ x=\"3\"\\ y=\"3\"\\ z=\"6\"\\ r=\"0\"\\ p=\"0\"\\ w=\"0\"/\\textgreater{}}\nfor a new camera, or a new line on the form\n\\texttt{\\textless{}xacro:aruco\\ number=\"1\"\\ x=\"3\"\\ y=\"3\"\\ z=\"0.1\"\\ r=\"0\"\\ p=\"0\"\\ w=\"0\"/\\textgreater{}}\nfor a new aruco. The commands are identical apart from the name.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\texttt{Number} is added to the name to make the static agent unique.\n  For cameras this mean they will publish on e.g.~the topic\n  \\texttt{static\\_agents/camera\\_{[}number{]}/image\\_raw}. For aruco the\n  number indicates which aruco png to use.\n\\item\n  \\texttt{x,\\ y,\\ z} is the coordinate offset from the link the agents\n  are all attached to.\n\\item\n  \\texttt{r,\\ p,\\ w} are the rotation, pitch, and yaw of the camera,\n  dictating in which direction and at what angle the cameras are\n  looking.\n\\end{itemize}\n\n\\href{https://classic.gazebosim.org/tutorials?tut=camera_distortion}{Gazebo\nsupports simulation of camera} based on the Brown’s distortion model. It\nexpects 5 distortion coefficients k1, k2, k3, p1, p2 that you can get\nfrom the camera calibration tools. The k coefficients are the radial\ncomponents of the distortion model, while the p coefficients are the\ntangential components.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\texttt{\\textless{}aspect\\_ratio\\textgreater{}} : The ratio of the\n  width and height of the camera.\n\\item\n  \\texttt{\\textless{}horizontal\\_fov\\textgreater{}}: The horizontal\n  field of view of the camera in radians.\n\\end{itemize}\n\n\\href{https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html}{OpenCV}\nuses five parameters, known as distortion coefficients given by like\nthis:\n\\texttt{k1,\\ k2,\\ p1,\\ p2\\ ,\\ k3\\ \\#\\ pay\\ attention\\ to\\ the\\ order}\n\n\\subsection{Using actors in Gazebo}\\label{using-actors-in-gazebo}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Placed in sdf or world file\n\\item\n  Actors use the actor tag (as opposed to the model tag most other\n  objects use).\n\\item\n  actor tags contain links like usual, but also a\n  \\texttt{\\textless{}script\\textgreater{}} tag.\n\\item\n  The script tag contains:\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    loop: Whether the script should loop on completion\n  \\item\n    delay\\_start: Time to wait before running the script, also waits\n    between loops\n  \\item\n    auto\\_start: Whether the script should start automatically when the\n    sim starts\n  \\item\n    A trajectory tag, which has an (unique) id and a type (used to\n    couple it with an animation)\n\n    \\begin{itemize}\n    \\tightlist\n    \\item\n      Inside the trajectory tags we define waypoint tags which consist\n      of a pose and the time where we are supposed to reach the pose.\n    \\item\n      Note: The trajectory is smoothed as a whole. This means that\n      you’ll get a fluid motion, but the exact poses contained in the\n      waypoints might not be reached.\n    \\end{itemize}\n  \\end{itemize}\n\\end{itemize}\n\nScript structure:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{\\textless{}}\\KeywordTok{script}\\NormalTok{\\textgreater{}}\n\\NormalTok{  \\textless{}}\\KeywordTok{loop}\\NormalTok{\\textgreater{}1\\textless{}/}\\KeywordTok{loop}\\NormalTok{\\textgreater{}}\n\\NormalTok{  \\textless{}}\\KeywordTok{auto\\_start}\\NormalTok{\\textgreater{}1\\textless{}/}\\KeywordTok{auto\\_start}\\NormalTok{\\textgreater{}}\n\\NormalTok{  \\textless{}}\\KeywordTok{trajectory} \\OtherTok{id=}\\StringTok{\\textquotesingle{}0\\textquotesingle{}} \\OtherTok{type=}\\StringTok{\\textquotesingle{}square\\textquotesingle{}}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{time}\\NormalTok{\\textgreater{}0\\textless{}/}\\KeywordTok{time}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{pose}\\NormalTok{\\textgreater{}{-}1 {-}1 1 0 {-}0 0\\textless{}/}\\KeywordTok{pose}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{time}\\NormalTok{\\textgreater{}1\\textless{}/}\\KeywordTok{time}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{pose}\\NormalTok{\\textgreater{}{-}1 1 1 0 {-}0 0\\textless{}/}\\KeywordTok{pose}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{time}\\NormalTok{\\textgreater{}2\\textless{}/}\\KeywordTok{time}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{pose}\\NormalTok{\\textgreater{}1 1 1 0 {-}0 0\\textless{}/}\\KeywordTok{pose}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{time}\\NormalTok{\\textgreater{}3\\textless{}/}\\KeywordTok{time}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{pose}\\NormalTok{\\textgreater{}1 {-}1 1 0 {-}0 0\\textless{}/}\\KeywordTok{pose}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{time}\\NormalTok{\\textgreater{}4\\textless{}/}\\KeywordTok{time}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{pose}\\NormalTok{\\textgreater{}{-}1 {-}1 1 0 {-}0 0\\textless{}/}\\KeywordTok{pose}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{waypoint}\\NormalTok{\\textgreater{}}\n\\NormalTok{  \\textless{}/}\\KeywordTok{trajectory}\\NormalTok{\\textgreater{}}\n\\NormalTok{\\textless{}/}\\KeywordTok{script}\\NormalTok{\\textgreater{}}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Gazebo supports two different skeleton animation file formats: COLLADA\n  (.dae) and Biovision Hierarchy (.bvh).\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    .bvh: Text-based format with section ‘HIERARCHY’ and section\n    ‘MOTION’.\n  \\item\n    .dae: XML-based format, structured into multiple sections.\n  \\end{itemize}\n\\item\n  .bvh works for Ignition, while .dae works for both Gazebo classic and\n  Ignition\n\\item\n  Skin is similar, simply import a collada file\n\\item\n  \\textless interpolate\\_x\\textgreater true\\textless/interpolate\\_x\\textgreater{}\n  makes the animation match the movement. The animation is done briefly\n  along the x-axis and then it can be interpolated into any direction by\n  gazebo.\n\\item\n  In a top down positive x,y frame of reference: 0 = right, 1.57 = up,\n  -1.57 = down, 3.14 = left\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Pos/negative matters! 0 to -1.57 does not behave the same as 0 to\n    4.71!\n  \\item\n    In other words increasing the angle of rotation means rotating left,\n    and decreasing it means rotating right.\n  \\end{itemize}\n\\item\n  Tension = how strictly it follows the waypoints in a span 0-1 where 0\n  is not very strict, 1 very strict\n\\end{itemize}\n\n\\subsection{Simulation Specification}\\label{simulation-specification}\n\nEnvironment (world)\n\n\\begin{itemize}\n\\tightlist\n\\item\n  An in-door factory warehouse\n\\item\n  An out door street/sidewalk (side walk or street) (FUTURE WORK)\n\\end{itemize}\n\nObjects\n\n\\begin{itemize}\n\\tightlist\n\\item\n  human actor\n\\item\n  shelves\n\\item\n  \\href{https://en.wikipedia.org/wiki/Pallet}{standard euro pallets}\n\\item\n  \\href{https://www.iqsdirectory.com/articles/storage-rack/pallet-racks.html}{pallet\n  racks}\n\\item\n  traffic cone\n\\item\n  Boxes\n\\item\n  \\href{https://www.mobile-industrial-robots.com/insights/get-started-with-amrs/agv-vs-amr-whats-the-difference/}{differential-drive\n  AMR (Autonomous Mobile Robot)} (FUTURE WORK)\n\\item\n  forklift (FUTURE WORK)\n\\end{itemize}\n\nTextures\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Aruco tag on actor and floor\n\\item\n  objects texture\n\\item\n  Floor texture\n\\end{itemize}\n\nPlacement of sensors\n\n\\begin{itemize}\n\\tightlist\n\\item\n  camera (depth) on ceiling\n\\item\n  2D Lidar/camera on AMR (FUTURE WORK)\n\\end{itemize}\n\nPhysics\n\n\\begin{itemize}\n\\tightlist\n\\item\n  mass\n\\item\n  moment of inertia\n\\item\n  collision\n\\item\n  friction (FUTURE WORK)\n\\item\n  damping\n\\end{itemize}\n\nLighting\n\nAgents movements:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  deterministically following waypoints trajectories (in curve or in\n  form of A-B-C…Z)\n\\item\n  AMR differential-drive using nav2 with obstacle avoidance (FUTURE\n  WORK)\n\\item\n  replaying scenario using rosbag\\hspace{0pt} (FUTURE WORK)\n\\end{itemize}\n\nAdditionally these are expected from the simulator:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  following realistic and standard measurements and sizes for warehouse,\n  pallettes, shelves, cart, human body, etc\n\\item\n  agent/robot status (position) and control via ROS\n\\item\n  exposing and recording camera images and agent status (e.g.~positions)\n  in Python\n\\item\n  tele-operation with keyboard and programmatically from python\n\\end{itemize}\n\n\\subsection{AMR}\\label{amr}\n\ndifferential-drive (casterwheel)/achermann (car) type of robot\n\n\\texttt{/cmd\\_vel} topic accepts \\texttt{Twist} formatted messages only\nnon-zero value for linear.x (forward/backward) and non-zero value for\nangular.z (differential drive, rotating in z axis)\n\n\\subsection{Warehouse}\\label{warehouse}\n\nThe warehouse was created in FreeCAD’s BIM Workbench. This workbench\nisn’t available by default but can easily be acquired by going to\n\\texttt{Tools} -\\textgreater{} \\texttt{Addon\\ Manager} -\\textgreater{}\n\\texttt{BIM} -\\textgreater{} \\texttt{Install/update\\ Selected}.\n\nUsing the measurements found in the blueprint in the documentation\nfolder I drew four lines and turned them into walls (line tool and wall\ntool respectively). By default the wall will be created around the line,\nso that the line is in the middle of the wall. This can be changed in\nthe wall properties so that it ends up entirely on one side of the line.\nAs the blueprint lacked walls I used the dimensions specified there as\nthe inner measurements, meaning that the origin point is located at the\ninner bottom left corner of the wall. All the inner space is in positive\nx and y coordinates, while the two of the walls are in negative\ncoordinate space. I used the Aligned Dimension tool from the Annotation\ntools to confirm that the inner measurements matched those of the\nblueprint.\n\nWhile the BIM Workbench has support for door objects, they tend to act\nas solids when imported into gazebo, so the door is just a hole in the\nwall. This hole was created by adding a cube object and having it\nintersect the wall where the door should be located. Then you select the\ncube and the wall (in that order) in the tree view and press\n\\texttt{Remove\\ Component}. This should remove the cube object and\ncreate a hole where the cube and wall overlapped. The hole didn’t appear\nin the right place, but it was possible to edit the position of the hole\nin its properties. I measured the location of the hole using Aligned\nDimension to make sure it ended up in the right spot.\n\nGoing to the top view, I created a new rectangle object covering the\nwhole warehouse. Then I turned it into a slab with the slab tool to\ncreate a floor for the warehouse.\n\nEverything was added to a level object (note: by default this level\nobject is named “Floor”, but don’t confuse it with the slab that\nconstitutes the physical floor) so that it’s grouped together. If we set\nthe wall heights to 0 they will automatically inherit the height of the\nLevel object, so we can change all the walls easily by changing the\nheight of the level.\n\nI added two materials from presets, concrete and wood. I applied the\nconcrete material to all walls and the wood material to the floor. These\nshould be considered to be temporary placeholders.\n\nFinally I exported the project as a Collada file (.dae) and added it\ninto a simple .world file to see if it loaded properly in Gazebo, and\nthe results seemed correct.\n\nSince the warehouse will be static we shouldn’t need to define any\nadditional parameters like mass or inertia, visuals and collision should\nbe enough. Textures might need some improvement as currently they’re\njust basic colors but it should be possible to add those in FreeCAD and\nhave them included in the .dae file so we can load them visually in\nGazebo later.\n\nI also added windows for slightly better visibility.\n\n\\subsection{Add warehouse to\nworld-file}\\label{add-warehouse-to-world-file}\n\nThe floor of the warehouse goes below z=0 so the ground plane was\nlowered by 0.2 so that the warehouse still rests on top of it. As our\nsimulations will mainly take place inside the warehouse the warehouse\nfloor replaces the ground plane at z=0. The warehouse itself was placed\nin the models directory and loaded into the world with an\n\\texttt{\\textless{}include\\textgreater{}} tag. Additionally the maze in\nthe stage4 world was moved away from the origin so that it is fully\ncontained inside the warehouse, though in the future it should be\nremoved altogether.\n\n\\subsection{Textures}\\label{textures}\n\nShelf, pallet, warehouse walls are using CC0 textures from\nhttps://polyhaven.com/textures Box and warehouse floor are using images\nfrom Volvo as a base.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  box: picture from\n  \\href{https://www.volvogroup.com/content/dam/volvo-group/markets/master/suppliers/useful-links-and-documents-for-existing-suppliers/logistics-solutions/volvo-group-packaging-system/Volvo-group-packaging-specifications_2015.pdf}{Volvo-group-packaging-specifications\\_2015.pdf}\n\\end{itemize}\n\n\\subsubsection{Conventions}\\label{conventions}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Keep your links/joints paired, and use the suffix \\_link and \\_joint\n  (e.g.~arm\\_link and arm\\_joint) and maybe follow\n  \\href{https://www.ros.org/reps/rep-0120.html}{REP 120 naming\n  conventions}\n\\item\n  Define visual, collision, inertial and Gazebo material (and maybe\n  friction) for all objects\n\\end{itemize}\n\n\\section{Converting FreeCAD meshes to SDF models (for\nGazebo)}\\label{converting-freecad-meshes-to-sdf-models-for-gazebo}\n\n\\subsection{Script step-by-step}\\label{script-step-by-step}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Install freecad\n  \\texttt{sudo\\ apt-get\\ install\\ freecad=0.19.2+dfsg1-3ubuntu1} (Tested\n  with version 0.19)\n\\item\n  Install Blender v3.3 LTS\n\\item\n  Download phobos.zip (tested with\n  \\href{https://github.com/dfki-ric/phobos/releases/tag/2.0.0}{phobos\n  2.0 “Perilled Pangolin”.} )\n\\item\n  Install phobos by following\n  \\href{https://github.com/dfki-ric/phobos/tree/2.0.0\\#installation}{the\n  guide on their github}\n\\item\n  In your phobos settings (easiest accessed through the blender GUI),\n  change the the models folder to where you want the output to be. You\n  can add a relative path here so that the output folder depends on\n  where you run the script, e.g.~setting the model folder to\n  \\texttt{./phobos\\_out/} would create a \\texttt{./phobos\\_out/}\n  directory as a sub-directory to wherever your run the script and save\n  the exported sdfs there.\n\\item\n  Enter freecad and load your \\texttt{.FCstd}, then select the body in\n  the tree view and select \\texttt{File}-\\textgreater{}\\texttt{Export}\n  and choose to export it as a Collada (\\texttt{.dae}) file.\n\\item\n  Run \\texttt{./build.sh}\n\\end{itemize}\n\nYou should now be able to load the model/directory created by the\nreformat script directly through Gazebo.\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\FunctionTok{wget}\\NormalTok{ https://download.blender.org/release/Blender3.3/blender{-}3.3.0{-}linux{-}x64.tar.xz}\n\\FunctionTok{tar} \\AttributeTok{{-}xf}\\NormalTok{ blender{-}3.3.0{-}linux{-}x64.tar.xz}\n\\FunctionTok{mv}\\NormalTok{ blender{-}3.3.0{-}linux{-}x64 blender}\n\\BuiltInTok{alias}\\NormalTok{ blender=}\\StringTok{\"}\\KeywordTok{\\textasciigrave{}}\\BuiltInTok{pwd}\\KeywordTok{\\textasciigrave{}}\\StringTok{/blender/blender\"}\n\\ExtensionTok{blender} \\AttributeTok{{-}{-}version}\n\\FunctionTok{git}\\NormalTok{ clone git@github.com:dfki{-}ric/phobos.git}\n\\BuiltInTok{cd}\\NormalTok{ phobos}\n\\FunctionTok{git}\\NormalTok{ checkout 2.0.0}\n\\ExtensionTok{blender} \\AttributeTok{{-}b} \\AttributeTok{{-}{-}python}\\NormalTok{ install\\_requirements.py}\n\\BuiltInTok{cd}\\NormalTok{ ..}\n\\ExtensionTok{./build.sh}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\subsection{In GUI}\\label{in-gui}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Import \\texttt{.dae} file\n\\item\n  Set phobostype to \\texttt{visual}\n\\item\n  Select the object and set the \\texttt{geometry\\ type}\n\\item\n  \\href{https://github.com/dfki-ric/phobos/wiki/Modeling-Walkthrough}{Guide}\n  says to\n  \\texttt{Object-\\textgreater{}Apply-\\textgreater{}Rotation\\ \\&\\ Scale}\n  here but I’m not sure what it actually accomplishes\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    This will apply the scaling of objects to their mesh information\n    (vertices) and applies the current orientation to the mesh as well.\n    After this option all objects have zero orientation. If this is not\n    desired one can also only apply the \\texttt{Scale}.\n  \\end{itemize}\n\\item\n  Create a “visual” collection and put the model into there, this lets\n  us create a tree structure. (unsure of necessity when we only have one\n  model)\n\\item\n  Select object and press \\texttt{Create\\ Link(s)}, make sure\n  \\texttt{selected\\ objects} mode is chosen.\n\\item\n  Select the visual and then \\texttt{Create\\ Collision}.\n\\item\n  Select the object and then \\texttt{Create\\ Inertials}.\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Here we need to manually enter our mass, should check if that can be\n    adjusted somehow.\n  \\end{itemize}\n\\item\n  Save and export.\n\\item\n  Then we need to move around the resulting files so they’re structured\n  in the way Gazebo wants them, i.e.:\n\\end{itemize}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{model}\n\\NormalTok{├── meshes}\n\\NormalTok{│   └── filename.dae}\n\\NormalTok{├── model.config}\n\\NormalTok{└── model.sdf}\n\\end{Highlighting}\n\\end{Shaded}\n\nIn order to accomplish this we’ll have to create the model.config file,\nhowever this is relatively simple as it doesn’t contain any unique data\nbetween different models aside from the model name.\n\nExample of a successful build:\n\n\\begin{verbatim}\nsimulation/raw_models$ ./build_models.sh\n\n../simlan_gazebo_environment/models/aruco/materials/textures/0.png\n../simlan_gazebo_environment/models/aruco/materials/textures/1.png\n../simlan_gazebo_environment/models/aruco/materials/textures/2.png\n../simlan_gazebo_environment/models/aruco/materials/textures/3.png\n\n\n\nColor management: using fallback mode for management\nColor management: Error could not find role data role.\nBlender 3.0.1\nRead prefs: [HOME]/.config/blender/3.0/config/userpref.blend\nColor management: scene view \"Filmic\" not found, setting default \"Standard\".\n/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\nChecking requirements:\nensurepip is disabled in Debian/Ubuntu for the system python.\n\nPython modules for the system python are usually handled by dpkg and apt-get.\n\n    apt install python3-<module name>\n\nInstall the python3-pip package to use pip itself.  Using pip together\nwith the system python might have unexpected results for any system installed\nmodule, so use it on your own risk, or make sure to only use it in virtual\nenvironments.\n\nWARNING: We couldn't do ensurepip, we try to continue anyways\n  Checking yaml\n  Checking numpy\n  Checking scipy\n  Checking collada\n  Checking pydot\n  Checking lxml\n  Checking networkx\n  Checking trimesh\n  Checking PIL\nImporting phobos\nIMPORT:  phobos.blender.defs\nParsing definitions from: [HOME]/.config/blender/3.0/scripts/addons/phobos/data/blender/definitions\n  defaultControllers.yml\n  defaultSensors.yml\n  defaultMaterials.yml\n  defaultJoints.yml\n  defaultSubmechanisms.yml\n  defaultMotors.yml\nCreating new definition type: joints\nCreating new definition type: motors\nIMPORT:  phobos.blender.display\nIMPORT:  phobos.blender.io\nRELOAD:  phobos.blender.model\nIMPORT:  phobos.blender.operators\nRELOAD:  phobos.blender.phobosgui\nRELOAD:  phobos.blender.phoboslog\nRELOAD:  phobos.blender.phobossystem\nRELOAD:  phobos.blender.reserved_keys\nRELOAD:  phobos.blender.utils\nRegistering operators.selection...\nRegistering operators.io...\nRegistering operators.editing...\nTypeError: EnumProperty(..., default='mechanism'): not found in enum members\nValueError: bpy_struct \"PHOBOS_OT_define_submodel\" registration error: 'submodeltype' EnumProperty could not register (see previous error)\nRegistering operators.naming...\nRegistering operators.misc...\n\nRegistering phobosgui...\n  ... successful.\n+-- Collada Import parameters------\n| input file      : ./objects/meshes/eur-pallet.dae\n| use units       : no\n| autoconnect     : yes\n+-- Armature Import parameters ----\n| find bone chains: yes\n| min chain len   : 0\n| fix orientation : yes\n| keep bind info  : no\nIOR of negative value is not allowed for materials (using Blender default value instead)+-- Import Scene --------\n| NODE  id='node0', name='node0'\n+----------------------------------\n| Collada Import : OK\n+----------------------------------\nError in sys.excepthook:\n\nOriginal exception was:\nFile \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blender/operators/editing.py\", line 1048, in toggleVisual\nError in sys.excepthook:\n\nOriginal exception was:\nFile \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blender/operators/editing.py\", line 1051, in toggleCollision\n[20231211_08:52:53] WARNING No text file README.md found. (phobos/blender/utils/blender.py - readTextFile (l259))\nCollada export to: [PATH]simulation/raw_models/phobos_out/unnamed/meshes/dae/Body.dae\nInfo: Exported 1 Objects\nInfo: Exported 1 Objects\nCollada export to: [PATH]simulation/raw_models/phobos_out/unnamed/meshes/dae/Body.dae\nInfo: Exported 1 Objects\nInfo: Exported 1 Objects\nInfo: Phobos exported to: phobos_out/unnamed\nInfo: Export successful.\nInfo: Phobos exported to: phobos_out/unnamed\nInfo: Export successful.\n\n----------------------------------------------------------------------------------------------------\nUnregistering Phobos...\nUnregistering phobosgui...\nUnregistering display...\nUnregistering icons...\nUnregistering classes...\nUnregistering manuals...\n  ... successful.\n\nBlender quit\nError: Not freed memory blocks: 14, total unfreed memory 0.002426 MB\n\\end{verbatim}\n\n\\subsection{Blueprint}\\label{blueprint}\n\nThis document contains explanations and motivations for the measurements\nas well as names for variables that should be used when designing the\nobjects. The categories are mostly self explanatory, the one that might\nneed more of an explanation is the color red. This refers to loose\nobjects such as pallets, barrels, boxes and things that will be placed\ndirectly on the ground.\n\n\\textbf{Measurements:}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.1818}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.1970}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.3788}}\n  >{\\raggedleft\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.2424}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nCategory\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nPart / Object\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nVariable Name\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedleft\nValue {[}unit{]}\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\nShelf & Load Beam & beam\\_length & 2.7 {[}m{]} \\\\\nShelf & Load Beam & beam\\_depth & 0.05 {[}m{]} \\\\\nShelf & Load Beam & beam\\_height & 0.14 {[}m{]} \\\\\nShelf & Load Beam & beam\\_weight & 15.2 {[}kg{]} \\\\\nShelf & Footplate & footplate\\_length & 0.111 {[}m{]} \\\\\nShelf & Footplate & footplate\\_width & 0.1 {[}m{]} \\\\\nShelf & Footplate & footplate\\_height & 0.004 {[}m{]} \\\\\nShelf & Stand / Pole & stand\\_length & 0.07 {[}m{]} \\\\\nShelf & Stand / Pole & stand\\_width & 0.08 {[}m{]} \\\\\nShelf & Stand / Pole & stand\\_height & 3 {[}m{]} \\\\\nShelf & Stand / Pole & stand\\_weight & 8.5 {[}kg{]} \\\\\nShelf & Cross Brace & brace\\_length & 0.96 {[}m{]} \\\\\nShelf & Cross Brace & brace\\_width & 0.01 {[}m{]} \\\\\nShelf & Cross Brace & brace\\_height & 0.02 {[}m{]} \\\\\nShelf & Cross Brace & brace\\_weight & 1 {[}kg{]} \\\\\nLoose Object & EUR-Pallet & EUR\\_pallet\\_length & 1.2 {[}m{]} \\\\\nLoose Object & EUR-Pallet & EUR\\_pallet\\_width & 0.8 {[}m{]} \\\\\nLoose Object & EUR-Pallet & EUR\\_pallet\\_height & 0.144 {[}m{]} \\\\\nLoose Object & EUR-Pallet & EUR\\_pallet\\_weight & 25 {[}kg{]} \\\\\nLoose Object & Steel Drum & steel\\_drum\\_radius & 0.3 {[}m{]} \\\\\nLoose Object & Steel Drum & steel\\_drum\\_height & 0.9 {[}m{]} \\\\\nLoose Object & Steel Drum & full\\_steel\\_drum\\_weight & 188 {[}kg{]} \\\\\nLoose Object & Steel Drum & empty\\_steel\\_drum\\_weight & 15 {[}kg{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_radius & 0.22 {[}m{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_angle & -10\n{[}degrees{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_total\\_height & 1\n{[}m{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_base\\_length & 0.52\n{[}m{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_base\\_width & 0.52\n{[}m{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_base\\_height & 0.03\n{[}m{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_base\\_angle & -20\n{[}degrees{]} \\\\\nLoose Object & Traffic Cone & traffic\\_cone\\_weight & 6.5 {[}kg{]} \\\\\nLoose Object & Box & box\\_length & Varies {[}m{]} \\\\\nLoose Object & Box & box\\_width & Varies {[}m{]} \\\\\nLoose Object & Box & box\\_height & Varies {[}m{]} \\\\\nLoose Object & Box & box\\_weight & Varies {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_length & 0.3 {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_width & 0.3 {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_hole\\_side\\_length & 0.27 {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_hole\\_side\\_width & 0.13 {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_height & 6 {[}m{]} \\\\\nWarehouse & Support Pole & pole\\_weight & Undefined {[}kg{]} \\\\\n\\end{longtable}\n}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}c@{}}\n\\toprule\\noalign{}\n{EUR-pallet} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\emph{EUR-pallet Measurements} \\\\\n\\end{longtable}\n}\n\n\\subsection{AMR}\\label{amr-1}\n\n{AMR}\n\nIt is defined in XY plane and the center of the AMR is on x,y=0,0 and\nthe bottom of the robot is on z=0.\n\nDefine \\textbf{scale} , \\textbf{pos} and collision in these files:\n\nWe write our AMR description in\n\\texttt{simlan\\_gazebo\\_environment/urdf} and use \\texttt{xacro} to\ncreate a \\texttt{urdf} file with gazebo tags (so not a pure urdf file)\nthat can be used both by \\texttt{state\\_publisher} and \\texttt{gazebo}\n(unlike 2 separate files \\texttt{model.sdf} that is used for Gazebo and\n\\texttt{turtlebot.urf} that is used for state\\_publisher in original\nTurtlebot\\_simulation git project.\n\nThere are two actual diffdrive wheels that are named \\texttt{left} and\n\\texttt{right} and four supporting wheel to balance the robot that are\nnamed \\texttt{front\\_left}, \\texttt{front\\_right} and\n\\texttt{back\\_left} and \\texttt{back\\_right} (they have no friction and\ncan be moved to different position) with the radius of 0.98 of the main\nwheels.\n\n\\textbf{Note}: The reason for the shake is difference between the radius\nof the real wheels and caster wheels\n\n\\subsubsection{Infobot AMR\nspecification}\\label{infobot-amr-specification}\n\nOrientation:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  x : forward\n\\item\n  y: left\n\\item\n  z: up\n\\end{itemize}\n\n\\subsection{Objects Modeled in\nFreeCAD}\\label{objects-modeled-in-freecad}\n\nAll the objects are located in \\texttt{objects}. Below follows a list of\nthe objects currently available, models created in FreeCAD.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  EUR-pallet\n\\item\n  Shelf\n\\item\n  Modular Shelf - a stackable shelf part that can create shelves of\n  varying size\n\\item\n  Steel Drum\n\\item\n  Traffic Cone\n\\item\n  Support Pole\n\\item\n  Boxes with measurements in mm {[}Box-Length x Width x Height{]}\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Box-160x130x70\n  \\item\n    Box-185x185x75\n  \\item\n    Box-185x185x185\n  \\item\n    Box-210x180x130\n  \\item\n    Box-230x160x85\n  \\item\n    Box-250x195x160\n  \\item\n    Box-430x250x260\n  \\item\n    Box-440x320x175\n  \\item\n    Box-570x380x380\n  \\item\n    Box-1185x785x1010\n  \\item\n    Box-600x800x400 (2 per level on EUR-Pallet)\n  \\item\n    Box-600x400x400 (4 per level on EUR-Pallet)\n  \\item\n    Box-300x400x400 (8 per level on EUR-pallet)\n  \\end{itemize}\n\\end{itemize}\n\n\\subsection{AMR camera}\\label{amr-camera}\n\n{Camera}\n\nInspired by\n\\href{https://sz-camera.en.made-in-china.com/productimage/OxfRauwdhIcY-2f1j00jPcbKhZkSIoC/China-3G-SDI-HDMI-Simultaneous-Output-1080-60-50-30-25p-1080-60-50I-HD-Digital-Camera-6-12mm-Manual-Lens-Live-Broadcast-Camera.html}{CCTV\nCamera 3G-SDI}\n\nIn the model: camera base height(70mm) + camera lense height(50mm) =\n120mm\n\n\\subsection{Resources}\\label{resources}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\href{https://www.cisco-eagle.com/category/3051/selective-rack-configuration}{Pallet\n  Rack Specification \\& Configuration Guide}\n\\item\n  \\href{https://webtools.cisco-eagle.com/rack/}{Pallet Rack Estimator}\n\\item\n  \\href{https://www.topregal.com/en/pallet-racks/configurator/}{Pallet\n  rack configurator}\n\\item\n  \\href{https://app.gazebosim.org/search;q=Pallet}{pallet}\n\\item\n  Shelf typical measurements:\n  \\href{https://arkerwarehouse.com/standard-upright-sizes/\\#:~:text=The\\%20most\\%20common\\%20upright\\%20depth,is\\%208}{Shelf\n  Measurements}\n\\item\n  Forklift height which influences Shelf height:\n  \\href{https://www.bigrentz.com/blog/dimensions-of-forklift\\#:~:text=Forklift\\%20heights\\%20can\\%20span\\%20anywhere,is\\%20about\\%2013.5\\%2D14.5\\%20feet.}{Forklift\n  Height}\n\\item\n  EUR-pallet:\n  \\href{https://www.svenskttra.se/bygg-med-tra/traforpackningar/val-av-emballagetyp/lastpallar/\\#:~:text=EUR\\%2Dpallen\\%20med\\%20m\\%C3\\%A5tten\\%20800,lastpallen\\%20\\%C3\\%B6verstiga\\%205\\%20500\\%20kg.}{EUR-pallet}\n\\item\n  Shelf design:\n  \\href{https://www.topregal.com/en/pallet-racks/configurator/}{Shelf\n  design}\n\\item\n  Shelf exact measurements:\n  \\href{https://www.topregal.com/out/media/29386_tdb_INT_PR9000.pdf}{Shelf\n  exact measurement}\n\\item\n  Examples of boxes:\n  \\href{https://wulffsupplies.se/produkter/emballage/emballage/wellador-och-kartonger/}{Boxes\n  Examples}\n\\item\n  Measurement for steel drum:\n  \\href{https://eshop-best-chemical.com/products/210-litres-tight-head-steel-drum-with-pe-gasket-grey}{Steel\n  Drum}\n\\item\n  Full Steel drum weight is based on the oil density of 825kg/m\\^{}3 and\n  the drum fits 210 liters.\n\\item\n  Some values helping in constructing the traffic cone:\n  \\href{https://www.roadware.co.uk/starlite-1-meter-road-traffic-cones/}{Traffic\n  Cone}\n\\end{itemize}\n\n\\subsection{Blueprint}\\label{blueprint-1}\n\nThis document contains explanations and motivations for the measurements\nas well as names for variables that should be used when designing the\nobjects. The categories are mostly self explanatory, the one that might\nneed more of an explanation is the color red. This refers to loose\nobjects such as pallets, barrels, boxes and things that will be placed\ndirectly on the ground.\n\n\\textbf{Measurements:}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.1429}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.2063}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.4286}}\n  >{\\raggedleft\\arraybackslash}p{(\\linewidth - 6\\tabcolsep) * \\real{0.2222}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nCategory\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nPart / Object\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nVariable Name\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedleft\nValue {[}unit{]}\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\nWarehouse & Walls & warehouse\\_length & 23.2 {[}m{]} \\\\\nWarehouse & Walls & warehouse\\_width & 18 {[}m{]} \\\\\nWarehouse & Walls & warehouse\\_height & 6 {[}m{]} \\\\\nWarehouse & Aisle & aisle\\_width & 3.7 {[}m{]} \\\\\nWarehouse & Door & door\\_height & 4 {[}m{]} \\\\\nWarehouse & Door & door\\_width & 3 {[}m{]} \\\\\nWarehouse & Warehouse & door\\_distance\\_to\\_wall & 2 {[}m{]} \\\\\nWarehouse & Shelf & shelf\\_distance\\_side\\_side & 0 {[}m{]} \\\\\nWarehouse & Shelf & single\\_shelf\\_wall\\_distance & 0.1 {[}m{]} \\\\\nWarehouse & Shelf & double\\_shelf\\_depth\\_distance & 0.2 {[}m{]} \\\\\nWarehouse & Shelf & shelf\\_total\\_length & 2.88 {[}m{]} \\\\\nWarehouse & Shelf & shelf\\_total\\_depth & 1.1 {[}m{]} \\\\\nWarehouse & Shelf & shelf\\_total\\_height & 3 {[}m{]} \\\\\n\\end{longtable}\n}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}c@{}}\n\\toprule\\noalign{}\n{blueprint} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\emph{The storage blueprint} \\\\\n\\end{longtable}\n}\n\n\\subsection{Install instruction for BIM and Arch\nworkbench}\\label{install-instruction-for-bim-and-arch-workbench}\n\nThe warehouse was created in FreeCAD’s BIM Workbench. This workbench\nisn’t available by default but can easily be acquired by:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Installing \\texttt{pip3\\ install\\ gitpython}\n\\item\n  Activating \\texttt{Tools} -\\textgreater{} \\texttt{Addon\\ Manager}\n  -\\textgreater{} \\texttt{BIM} -\\textgreater{}\n  \\texttt{Install/update\\ Selected}\n\\end{itemize}\n\nUsing the measurements found in the blueprint in the documentation\nfolder I drew four lines and turned them into walls (line tool and wall\ntool respectively). By default the wall will be created around the line,\nso that the line is in the middle of the wall. This can be changed in\nthe wall properties so that it ends up entirely on one side of the line.\nAs the blueprint lacked walls I used the dimensions specified there as\nthe inner measurements, meaning that the origin point is located at the\ninner bottom left corner of the wall. All the inner space is in positive\nx and y coordinates, while the two of the walls are in negative\ncoordinate space. I used the Aligned Dimension tool from the Annotation\ntools to confirm that the inner measurements matched those of the\nblueprint.\n\nWhile the BIM Workbench has support for door objects, they tend to act\nas solids when imported into gazebo, so the door is just a hole in the\nwall. This hole was created by adding a cube object\n(\\texttt{3D/BIM\\ -\\textgreater{}\\ Cube}) and having it intersect the\nwall where the door should be located. Then you select the cube and the\nwall (in that order) in the tree view and press\n\\texttt{Modify\\ -\\textgreater{}\\ Remove\\ Component}. This should remove\nthe cube object and create a hole where the cube and wall overlapped.\nThe hole didn’t appear in the right place, but it was possible to edit\nthe position of the hole in its properties. I measured the location of\nthe hole using Aligned Dimension to make sure it ended up in the right\nspot.\n\nGoing to the top view, I created a new rectangle object covering the\nwhole warehouse. Then I turned it into a slab with the slab tool to\ncreate a floor for the warehouse.\n\nEverything was added to a level object (note: by default this level\nobject is named “Floor”, but don’t confuse it with the slab that\nconstitutes the physical floor) so that it’s grouped together. If we set\nthe wall heights to 0 they will automatically inherit the height of the\nLevel object, so we can change all the walls easily by changing the\nheight of the level. Textures for the floor and walls can later be added\nin Blender.\n\nFinally I exported the project as a Collada file (.dae) and added it\ninto a simple .world file to see if it loaded properly in Gazebo, and\nthe results seemed correct.\n\nSince the warehouse will be static we shouldn’t need to define any\nadditional parameters like mass or inertia, visuals and collision should\nbe enough. Textures might need some improvement as currently they’re\njust basic colors but it should be possible to add those in FreeCAD and\nhave them included in the .dae file so we can load them visually in\nGazebo later.\n\nI also added windows for slightly better visibility.\n\n\\subsection{Add warehouse to\nworld-file}\\label{add-warehouse-to-world-file-1}\n\nThe floor of the warehouse goes below z=0 so the ground plane was\nlowered by 0.2 so that the warehouse still rests on top of it. As our\nsimulations will mainly take place inside the warehouse the warehouse\nfloor replaces the ground plane at z=0. The warehouse itself was placed\nin the models directory and loaded into the world with an\n\\texttt{\\textless{}include\\textgreater{}} tag. Additionally the maze in\nthe stage4 world was moved away from the origin so that it is fully\ncontained inside the warehouse, though in the future it should be\nremoved altogether.\n\n\\subsection{Resources}\\label{resources-1}\n\nWarehouse Aisle width:\n\\href{https://www.conger.com/forklift-width/\\#:~:text=As\\%20you\\%20may\\%20recall\\%20from,standard\\%2048-inch\\%20pallets.}{Aisle\nWidth}\n\n\\section{forklift\\_robot}\\label{forklift_robot}\n\nA simple Forklift Robot URDF and PROTO (for webots).\n\nAdd it to your catkin workspace and run \\texttt{catkin\\ build}\n\n\\subsection{URDF}\\label{urdf}\n\nOne can see the URDF by running:\n\\texttt{roslaunch\\ urdf\\_tutorial\\ display.launch\\ model:=\\textquotesingle{}\\$(find\\ forklift\\_robot\\_description)/urdf/forklift\\_simple.urdf\\textquotesingle{}}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{    \\textless{}}\\KeywordTok{physics} \\OtherTok{type=}\\StringTok{\"ode\"}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{ode}\\NormalTok{\\textgreater{}}\n\\NormalTok{        \\textless{}}\\KeywordTok{solver}\\NormalTok{\\textgreater{}}\n\\NormalTok{          \\textless{}}\\KeywordTok{type}\\NormalTok{\\textgreater{}world\\textless{}/}\\KeywordTok{type}\\NormalTok{\\textgreater{}}\n\\NormalTok{        \\textless{}/}\\KeywordTok{solver}\\NormalTok{\\textgreater{}}\n\\NormalTok{        \\textless{}}\\KeywordTok{constraints}\\NormalTok{\\textgreater{}}\n\\NormalTok{          \\textless{}}\\KeywordTok{contact\\_max\\_correcting\\_vel}\\NormalTok{\\textgreater{}0.1\\textless{}/}\\KeywordTok{contact\\_max\\_correcting\\_vel}\\NormalTok{\\textgreater{}}\n\\NormalTok{          \\textless{}}\\KeywordTok{contact\\_surface\\_layer}\\NormalTok{\\textgreater{}0.0001\\textless{}/}\\KeywordTok{contact\\_surface\\_layer}\\NormalTok{\\textgreater{}}\n\\NormalTok{        \\textless{}/}\\KeywordTok{constraints}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}/}\\KeywordTok{ode}\\NormalTok{\\textgreater{}}\n\\NormalTok{      \\textless{}}\\KeywordTok{max\\_step\\_size}\\NormalTok{\\textgreater{}0.001\\textless{}/}\\KeywordTok{max\\_step\\_size}\\NormalTok{\\textgreater{}}\n\\NormalTok{    \\textless{}/}\\KeywordTok{physics}\\NormalTok{\\textgreater{}}\n\\end{Highlighting}\n\\end{Shaded}\n\nTwo solvers: world step gives an accurate solution if it is able to\nsolve the problem, while quick step depends on the number of iterations\nto reach an accurate enough solution.\n\n\\subsubsection{contact/collision\nparameters}\\label{contactcollision-parameters}\n\ndampingFactor double Exponential velocity decay of the link velocity -\ntakes the value and multiplies the previous link velocity by\n(1-dampingFactor). maxVel double maximum contact correction velocity\ntruncation term. minDepth double minimum allowable depth before contact\ncorrection impulse is applied maxContacts int Maximum number of contacts\nallowed between two entities. This value overrides the max\\_contacts\nelement defined in physics.\n\ncontact\\_max\\_correcting\\_vel : contact\\_max\\_correcting\\_vel This is\nthe same parameter as the max\\_vel under\ncollision-\\textgreater surface-\\textgreater contact.\ncontact\\_max\\_correcting\\_vel sets max\\_vel globally.\ncontact\\_surface\\_layer : contact\\_surface\\_layer This is the same\nparameter as the min\\_depth under\ncollision-\\textgreater surface-\\textgreater contact.\n\n\\emph{Note}: We had issue getting global settings\n(\\texttt{contact\\_max\\_correcting\\_vel} and\n\\texttt{contact\\_surface\\_layer}) working. We therefore define object\nlevel \\texttt{minDepth} and \\texttt{maxVel} for each object\n\n“quick” solver parameters min\\_step\\_size The minimum time duration\nwhich advances with each time step of a variable time step solver. iters\nThe number of iterations for the solver to run for each time step.\n\n\\subsubsection{objects:}\\label{objects}\n\nAs of now there are many objects in the world file nad if you want to\nmove them all it’s quite cumbersome. Therefore the move\\_objects.py was\nadded to be able to increment the poses by x amount if needed. See\nmove\\_objects.py\n\n\\subsubsection{reference:}\\label{reference}\n\nhttps://classic.gazebosim.org/tutorials?tut=physics\\_params\\&cat=physics\nhttp://sdformat.org/spec\n\n\\section{Static\\_agent\\_launcher}\\label{static_agent_launcher}\n\nThis package launches all the static agents i.e.~the cameras in the\nsimulation.\n\nWhen the workspace is built, the \\texttt{camera\\_config.xacro} file is\nupdated with camera\\_ids and their corresponding intrinsic and extrinsic\nvalues. This can be seen in the \\texttt{build}function in\n\\texttt{control.sh}.\n\nThe \\texttt{camera\\_config.xacro} is then sent to the\nrobot\\_state\\_publisher node and published to the\n/static\\_agent/robot\\_description topic. Then the ros\\_gz\\_sim package\nwith the “create” executable spawns the static\\_agents by subscribing to\nthe /static\\_agent/robot\\_description topic and spawning each agent.\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsubsection{gz\\_bridge for cameras}\\label{gz_bridge-for-cameras}\n\ndifferent configurations of the gz\\_bridge node were tested and\nevaluated against the simulated RTF (real time factor). In the earlier\nsetups, a gz\\_bridge node was setup for each camera\\_stream (image,\ndepth ,semantic) for each camera\\_id. 3 configurations were tested where\ndifferent amount of nodes were setup and their corresponding RTF was\ncaptured and averaged over 5 tries.\n\nSN=single node for all cameras, 1NPC=1 node per camera\\_id, 1NPSPC = 1\nnode per stream per camera\\_id\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}lllll@{}}\n\\toprule\\noalign{}\nnode setup & number of cameras & number of nodes & camera streams & avg\nRTF \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\nSN & 9 & 1 & image & 17,9\\% \\\\\n1NPC & 9 & 9 & image & 16,7\\% \\\\\nSN & 9 & 1 & image depth semantic & 5,14\\% \\\\\n1NPC & 9 & 9 & image depth semantic & 5,2\\% \\\\\n1NPS & 9 & 81 & image depth semantic & 4,7\\% \\\\\n\\end{longtable}\n}\n\ndoesn’t seem like a big difference so will stick with one node i.e.~SN.\n\nIn the future it can be decided wether to keep the gz\\_bridge node as is\nor to create a generate gz\\_brige\\_camera.yaml file as the other\ngeneration scripts \\texttt{/home/ros/src/config\\_generation}\n\n\\section{bird-eye-view package}\\label{bird-eye-view-package}\n\nThis package aims to contain projection functionality which originates\nfrom \\href{../../camera_utility/projection.ipynb}{projection.ipynb}\nnotebook.\n\nThis package features being able to select areas of your choosing and\ncreate a bird-eye-view of that area by using available cameras, viewing\nthat area.\n\nCommand to run birdeye launch file:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ birdeye}\n\\end{Highlighting}\n\\end{Shaded}\n\nScreenshots:\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={bird eye view}]{/tmp/media-e0c46393b624552d/6ab7e32c3ba9fa7057408343cfe4f032b465a356.png}}\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={bird eye view gazebo}]{/tmp/media-e0c46393b624552d/9bfca26e6273a37f17835a52ff91641525f0ff54.png}}\n\n\\section{SIMLAN bringup}\\label{simlan-bringup}\n\nThis package is responsible for launching all things related to the\nsimulation. The launch files in the package calls launch files in all\nother packages to start everything up with the following command\n\n\\texttt{ros2\\ launch\\ simlan\\_bringup\\ full\\_sim.launch.py}\n\n\\subsection{Launch arguments}\\label{launch-arguments}\n\nThere are different launch arguments that can be changed to launch the\nsimulation in different states. These can either be called from the\nterminal by appending the argument to the launch command above.\n\n\\texttt{rviz:=\\textquotesingle{}True\\textquotesingle{}}\n\nAnother way to edit what is launched it to change the \\emph{default\nvalue} in \\href{launch/full_sim.launch.py}{\\emph{full\\_sim.launch.py}}.\n\n\\texttt{launch\\_rviz\\_launch\\_argument\\ =\\ DeclareLaunchArgument(\\ \\ \\ \\ \\ \\ \\ \\ \\ \"rviz\",\\ \\ \\ \\ \\ \\ \\ \\ \\ default\\_value=\"False\",\\ \\ \\ \\ \\ \\ \\ \\ \\ description=\"To\\ launch\\ rviz\")}\n\nThe launch arguments are then either added as a condition straight to a\nNode:\n\n\\texttt{condition=IfCondition(rviz)}\n\nor passed downward to the launch file being called from the top level\nlaunch file:\n\n\\texttt{launch\\_arguments=\\{\"jackal\\_manual\\_control\":jackal\\_manual\\_control,\\}.items()}\n\nIf you use a specific argument configuration often it is best to create\na new launch file, on top of\n\\href{launch/full_sim.launch.py}{\\emph{full\\_sim.launch.py}}. It can\nhave the correct default values for all arguments and then just call on\n\\href{launch/full_sim.launch.py}{\\emph{full\\_sim.launch.py}}.\n\n\\subsection{Diagram of launch\nstructure}\\label{diagram-of-launch-structure}\n\nThis diagram is made in DrawIO and the png contains the xml code. Drop\nit into \\href{https://app.diagrams.net/}{drawio} to make changes and add\nback to this readme. {launch\\_structure}\n\n\\section{pallet\\_truck}\\label{pallet_truck}\n\nCommon packages for pallet\\_truck, including messages and robot\ndescription. These are packages relevant to all pallet\\_truck\nworkspaces, whether simulation, desktop, or on the robot’s own headless\nPC.\n\n\\section{SIMLAN project}\\label{simlan-project}\n\n\\texttt{prefix} is used to publishing unique base link names of each\nrobot agent to \\texttt{/tf}. This way they all visible in rviz and\nprobably it is used for odometry done by aruco localisation.\\\\\n\\texttt{namespace} is used to separate nodes and topic related to each\nrobot agent. This way we can control each robot separately and run a\nseparate nav2 stack.\n\n\\textbf{Have in mind that the value of \\texttt{namespace} is used for\n\\texttt{prefix}} but they are different concept and usecases.\n\n\\subsection{Pallet Truck bringup.}\\label{pallet-truck-bringup.}\n\nThis package handles initilization and status of spawned robots.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\href{launch/gazebo.launch.py}{gazebo.launch.py} - Spawns robot,\n  handles robot\\_state\\_publisher, robot\\_description\n\\item\n  \\href{launch/keyboard_steering.launch.py}{keyboard\\_steering.launch.py}\n  - keyboard steering.\n\\item\n  \\href{launch/multiple_robot_spawn.launch.py}{multiple\\_robot\\_spawn.launch.py}\n  - contains configurable list of robots you spawn in the sim.\n\\item\n  \\href{launch/sim.launch.py}{sim.launch.py} - main launch file for\n  single robot. Make sure gazebo is running, control, twist\\_mux,\n  keyboard\\_steering as all launched.\n\\item\n  \\href{launch/rviz.launch.py}{rviz.launch.py} - runs rviz\n\\end{itemize}\n\nThe package focuses on pallet\\_truck for now but could be made modular\nto spawn other types of robots.\n\n\\subsection{Configuring and spawning robots inside the\nsim.}\\label{configuring-and-spawning-robots-inside-the-sim.}\n\nBelow is the structure which we use to spawn robots inside of the sim.\nPlease read these notes before setting up a new or editing a robot.\n\nAttributes for spawning a robot: \\textbar{} Attribute \\textbar{}\nDescription \\textbar{} Example \\textbar{}\n\\textbar——————\\textbar——————————————————————————————————-\\textbar———————\\textbar{}\n\\textbar{} \\texttt{namespace} \\textbar{} Used to differentiate between\nmultiple robots. Follows the format \\texttt{robot\\_agent\\_N}, where\n\\texttt{N} is the robot ID. \\textbar{} \\texttt{\"robot\\_agent\\_1\"}\n\\textbar{} \\textbar{} \\texttt{initial\\_pose\\_x} \\textbar{} The robot’s\ninitial x-coordinate position. Float value wrapped as a string.\n\\textbar{} \\texttt{\"10.0\"} \\textbar{} \\textbar{}\n\\texttt{initial\\_pose\\_y} \\textbar{} The robot’s initial y-coordinate\nposition. Float value wrapped as a string. \\textbar{} \\texttt{\"1.0\"}\n\\textbar{} \\textbar{} \\texttt{robot\\_type} \\textbar{} Selects the robot\nmesh or appearance. Options are \\texttt{\"pallet\\_truck\"} or\n\\texttt{\"forklift\"}. \\textbar{} \\texttt{\"pallet\\_truck\"} \\textbar{}\n\\textbar{} \\texttt{aruco\\_id} \\textbar{} Sets the ID shown on the\nrobot’s ArUco marker. Must match the ID in the \\texttt{namespace}.\n\\textbar{} \\texttt{\"1\"} if namespace ID is \\texttt{1} \\textbar{}\n\n\\begin{verbatim}\nExample robot setup:\n{\n    \"namespace\": \"robot_agent_1\", \n    \"initial_pose_x\":\"10.0\", \n    \"initial_pose_y\":\"1.0\", \n    \"robot_type\":\"pallet_truck\", \n    \"aruco_id\":\"1\"\n}\n\\end{verbatim}\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsection{automatically generated parameter\nfiles:}\\label{automatically-generated-parameter-files-1}\n\nSome parameter files are automatically generated for the\npallet\\_truck\\_bringup package. The generation scripts can be found in\nthe \\textasciitilde/src/config\\_generation/ directory. The automatically\ngenerated files include the \\texttt{nav2\\_params.yaml},\n\\texttt{gz\\_bridge.yaml} and more. To look at all the automatically\ngenerated files, build the workspace and the generated files will be\nprinted in the terminal or look manually in the\n\\textasciitilde/src/config\\_generation/ directory.\n\n\\subsection{Pallet\\_truck\\_control}\\label{pallet_truck_control}\n\nThe pallet\\_pallet\\_truck\\_control package includes all nodes necessary\nfor the control of the robots. These include the following:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\textbf{node}: description\n\\item\n  \\textbf{twist\\_mux}: Takes in velocity topics and orders them in order\n  of relevance. from highest to lowest: /key\\_vel, /safety\\_vel, /\n  scenario\\_vel, /nav\\_vel, /cmd\\_vel\n\\item\n  \\textbf{twist\\_stamper}: As of ros2 jazzy the ros2\\_controllers need\n  the twist messages to be stamped, therefore the stamper was introduced\n\\item\n  \\textbf{ros2\\_control\\_node}: Main node which uses the control.yaml\n  file and maps “hardware” to controller actions.\n\\item\n  \\textbf{spawner-joint\\_state\\_broadcaster}: Publishes the joint\\_state\n  so the robot moves in gazebo and rviz.\n\\item\n  \\textbf{spawner-velocity\\_controller}: Accepts and publishes velocity\n  commands\n\\end{itemize}\n\nWith this setup, the robot\\_agents can be controlled by running the\nteleop command in control.sh.\n\n\\section{pallet\\_truck Description}\\label{pallet_truck-description}\n\nThis packages contains the meshes and URDF of the pallet\\_truck robot,\nits supported sensors, and their supported mounts.\n\n\\subsection{Sensors}\\label{sensors}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\textbf{GPS:} Novatel Smart6 and Smart7\n\\item\n  \\textbf{2D LiDAR:} SICK LMS1xx\n\\item\n  \\textbf{2D LiDAR:} Hokuyo UST-10\n\\item\n  \\textbf{3D LiDAR:} Velodyne VLP16 and HDL-32E\n\\item\n  \\textbf{Camera:} Flir/Pointgrey Flea3 and Flea3 Stereo\n\\item\n  \\textbf{Camera:} Flir/Pointgrey Bumbleebee2\n\\item\n  \\textbf{Camera:} Flir/Pointgrey BlackflyS\n\\end{itemize}\n\n\\subsection{documentation on\npallet\\_truck\\_description}\\label{documentation-on-pallet_truck_description}\n\nIn addition to the change\\_log, this description is added to give vital\ninformation that may help other developers in the future to debug or\nupdate features faster.\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsection{Additions:}\\label{additions}\n\nHere additions to the urdf.xacro files are mentioned\n\n\\subsubsection{Collision sensor}\\label{collision-sensor}\n\nA collision\\_sensor was added and linked to the mesh tag of the\npallet\\_trucks. This is integrated in the pallet\\_truck.urdf.xacro.\n\nTo visualize the topic subscribe to: /namespace/collision\ne.g.~/robot\\_agent\\_1/contact.\n\nThe topic publishes information about the position, torque and which\nmodels are in contact with each other.\n\nThe topic name is defined by the automatically generated gz\\_bridge()\nwhich can be found in\n/home/ros/src/simulation/pallet\\_truck/pallet\\_truck\\_bringup/launch/generate\\_gz\\_bridge.py\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsection{Old Bugs}\\label{old-bugs}\n\nHere is some information of old bugs which may be useful to know for\nfuture development\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsubsection{xacro/urdf/sdf files}\\label{xacrourdfsdf-files}\n\nGazebo only reads sdf files and if .xacro or .urdf files are used, they\nare later parsed to .sdf’s before being used by Gazebo.\n\nA “bug” for Gazebo harmonic using ros2 jazzy was that when adding the\ncollision sensor for the pallet\\_trucks, Gazebo was unable to find the\ncollision tag for the mesh that we were using.\n\nAfter investigation it was found that when the .xacro file was parsed to\nan .sdf file, the name of the collision tag was updated by the parse\nplugin. Therefore this lumped renaming of the collision tag was “hard\ncoded” instead of using its original name which is in the\npallet\\_truck.urdf.xacro.\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\noriginal: “\\$(arg prefix)/chassis\\_link::collision”\n\nhard coded:\n“\\$\\{prefix\\}\\_base\\_link\\_fixed\\_joint\\_lump\\_\\_collision\\_collision”\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\nWhen adding sensors in the xacro file, make sure the plugins are also\nloaded. There are different world and robot plugins so if system plugins\nare used they should most likely be added to the .world file\n\n\\subsubsection{Map server}\\label{map-server}\n\nInstead of starting with an empty map, to get the general layout of the\nenvironment and detect the static object in the environment (walls,\ncooridors and hallways) you can \\textbf{optionally} build a map. To\nstart mapping (otherwise known as cartography), you can use\n\\texttt{cartography.launch.py}. It requires a lidar to be mounted on the\n\\texttt{robot\\_agent} and \\texttt{odometry} to exist, which can be\nactivated from the \\texttt{camera\\_utility/aruco\\_localization} package.\n\nLaunch the following package, run gazebo, rviz, aruco\\_localization, and\nstart moving around the simulation with the robot\\_agent. When you are\nfinished you need to save it using this command:\n\\texttt{ros2\\ run\\ nav2\\_map\\_server\\ map\\_saver\\_cli\\ -f\\ simulation/pallet\\_truck/pallet\\_truck\\_navigation/maps/YOUR\\_MAP\\_NAME}.\nKeep in mind that this step needs to be done only once and the map\nassumed to be static.\n\nWe only have one map for all navigation stack. This simplify making\nobstacle and other robot agent to all other robot agents.\n\n\\begin{verbatim}\nNode(  # Manually setting the joint between map and odom to 0 0 0, i.e. identical to each other. map -> odom\n  package=\"tf2_ros\",\n  executable=\"static_transform_publisher\",\n  name=\"static_world_to_map\",\n  arguments=[\"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"world\", \"map\"],\n  ...\n)\n\\end{verbatim}\n\n\\subsubsection{Robot\\_agent navigation}\\label{robot_agent-navigation}\n\nThis package covers the functionality of mapping, localizing, and\nnavigation for the robot\\_agent. Each package is built using code from\nthe nav2 packages, thus you are able to modify the launch files but to\nchange the node’s behaviour you need to modify the config files. The\ncode is tailored for the robot\\_agent and using the\n\\texttt{aruco\\_detection} package that supplies \\texttt{/TF} chain for\nthe truck.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  The \\texttt{aruco\\_localization} package runs the aruco localisation.\n\\item\n  The \\texttt{map\\_server.py} creates a map for each agent\n\\item\n  The \\texttt{nav2.launch.py} uses the localisation (from the previous\n  steps) for the navigation of the robot\\_agent.\n\\end{itemize}\n\nKeep in mind that the same namespace has to be used when launching the\nnavigation stack which is done automatically:\n\\texttt{ros2\\ launch\\ pallet\\_truck\\_navigation\\ nav2.launch.py\\ robots:=ROBOTS}\n\nFor navigation to be able to automatically find the robot agent, we have\nto set a namespace that specified when launching the robot\\_agent. (see\nabove)\n\nEach robot has it own navigation configuration in\n\\texttt{nav2\\_params.yaml} which is dynamically generated on build based\non the \\texttt{ROBOTS} variable in config.sh. the pallet\\_trucks and\nforklifts also have an individual\n\\texttt{navigate\\_w\\_replaning\\_and\\_recovery\\_robot\\_agent\\_x.xml}\nwhich is supposed to stop the navigation of the agents if their\naruco\\_markers are not detected. The topic which publishes the “seen”\naruco\\_markers is called \\texttt{/aruco\\_marker\\_seen} and can be\nvisualized after running gpss and nav.\n\nWe use following \\texttt{/TF} structure:\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={view\\_frames.png}]{/tmp/media-e0c46393b624552d/view_frames.png}}\n\n\\textbf{Note} that \\texttt{world} and \\texttt{map} are static at the\nsame position. \\texttt{robot\\_agent\\_X/odom} is static at the position\nfrom where the robots are spawned and the new position of the robots are\nthen determined by \\texttt{robot\\_agent\\_X/base\\_link} which is a\ndynamic transform from \\texttt{robot\\_agent\\_X/odom}.\n\nGood video to watch for multi agent navigation:\nhttps://www.youtube.com/watch?v=cGUueuIAFgw\n\n\\subsubsection{Humanoid\\_navigation}\\label{humanoid_navigation}\n\nThe humanoid navigation is implemented in the same way as for the\nrobot\\_agents with the difference of calling the function\n\\texttt{./control.sh\\ nav\\ HUMANOIDS}. Then the same principles apply\nbut with a different nav2\\_parameter file being used as an argument to\nnav2 nodes. At the moment there is an issue with the actual TF values in\nrvis and simulation in gazebo not matching which is described in\n\\texttt{simulation/humanoid\\_support\\_moveit\\_config/README.md} under\nbugs. When this is fixed, the navigation should work.\n\nThere is one major difference between the navigation of the humanoids\nand the robot\\_agents. The robot \\_agents get their \\texttt{odom} frame\nfrom the aruco\\_localization pkg which find aruco\\_markers and publishes\ntheir orientation and position. The humanoids on the other hand get\ntheir \\texttt{odom} frame from the ros2\\_controller\n\\texttt{simulation/humanoid\\_support\\_moveit\\_config/launch/launch\\_controllers.launch.py}.\nThis means the robot\\_agents get their odom frame from what the cameras\ncan see and the humanoids get their odom frame from what the ros2\ncontroller publishes.\n\n\\subsection{Obstacles detection\n(update\\_map\\_node)}\\label{obstacles-detection-update_map_node}\n\nWe have static objects in the map and initially we updated that single\nmap with dynamic obstacles (Robot\\_agents). The problem with this single\nmap was that nav2 navigation stack of robot\\_agent\\_1 sees itself within\nthe obstacle created for robot\\_agent\\_1 (\\textbf{itself}). Therefore it\nis decided that each robot\\_agent has its own map that has everything\nexcept itself. So this is a node to create a map with dynamic obstacles\naround all \\textbf{other} existing robot\\_agents in the simulation. Each\nrobot is assigned a map\\_server and this node sends an updated map with\nall other robots\\_agents as obstacle to the correct namespaced\nmap\\_server.\n\nThe node is launched in\n\\texttt{pallet\\_truck/pallet\\_truck\\_navigation/launch/nav2.launch.py}\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\nThe \\texttt{/map\\_updater/update\\_map\\_node.py} node works as following:\n\nFirst it makes a copy of the \\texttt{warehouse.pgm} map which is a long\narray of pixel values ranging from (0-255) and saves it as\n\\texttt{original\\_array}. Since the map nav2 needs has a different setup\nthan the \\texttt{.pgm} file, a conversion is needed.\n\nThe .pgm file has these pixels ranges\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}ll@{}}\n\\toprule\\noalign{}\nvalue & meaning \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n0 & black obstacle \\\\\n255 & White Free space \\\\\n1-254 & ranges of gray, not defined at the moment \\\\\n\\end{longtable}\n}\n\nThe map nav2 needs is set up with pixels ranging from (-1-100) where\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}ll@{}}\n\\toprule\\noalign{}\nvalue & meaning \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n-1 & Unknown \\\\\n0 & Free space \\\\\n100 & obstacle \\\\\n1-99 & probabilistic occupancy \\\\\n\\end{longtable}\n}\n\ntherefore this has to be parsed to match by doing the following:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{current\\_array }\\OperatorTok{=} \\VariableTok{self}\\NormalTok{.original\\_array.copy()}\n\\NormalTok{occupancy\\_array }\\OperatorTok{=}\\NormalTok{ np.zeros(current\\_array.shape, dtype}\\OperatorTok{=}\\NormalTok{np.uint8)}\n\\NormalTok{occupancy\\_array[current\\_array.copy()}\\OperatorTok{\\textless{}}\\DecValTok{100}\\NormalTok{] }\\OperatorTok{=} \\DecValTok{100}\n\\end{Highlighting}\n\\end{Shaded}\n\nSo everything that is supposed to be a wall in the .pgm file is parsed\nas a wall in the map context\n\nThe map is a 2D array, typically stored row-major from bottom-left, but\nmany implementations flip it vertically ({[}::-1{]}) to match how image\nviewers treat top-left as (0,0). and therefore the following is done\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{occupancy\\_array }\\OperatorTok{=}\\NormalTok{ occupancy\\_array[::}\\OperatorTok{{-}}\\DecValTok{1}\\NormalTok{, :]}\n\\end{Highlighting}\n\\end{Shaded}\n\nThen the position of all other robot\\_agents are found by their\ntransforms between robot\\_agent\\_x/base\\_link and world and an obstacle\nis set at their position which is updated with 10Hz to continuously\nupdate their positions.\n\nThis concept is repeated for all namespaces sent through the\n./control.sh nav function.\n\n\\textbf{How often the new path the pallet\\_trucks can take be update}\nadd a speed limiter instead of obstacle, in those cases the robot will\nslow down instead of replanning and avoiding completely update slower\ncould probably mix with the inflation radius’s of the costmaps to make\nrobot take wider turns\n\n\\textbf{Collision} Two robots that are approaching each other (from left\nand right) don’t know where each one is planning to go and they can make\nthe decision to pick the path on top lane instead of one going above and\none from bottom.\n\nPossible solution: block future path on every other robots map!\n\n\\subsubsection{}\\label{section}\n\nPackage created based on this\n\\href{https://docs.ros.org/en/jazzy/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html}{tutorial}\\\\\nNote that only the human with mesh model is installed in the package,\nsee /model/CMakeLists.txt for how to install the non-mesh models.\n\nIn the URDF, the fixed links and joints are (mostly) named {[}muscle\nname{]}\\_{[}location{]}, for example BicBrac\\_RUA = biceps\nbrachii\\_right upper arm. In humanSubjectWithMesh\\_simplified.urdf all\nfixed joints have been removed, only the skeleton joints remain.\n\nTo open Rviz with the human model:\n\n\\texttt{ros2\\ launch\\ urdf\\_tutorial\\ display.launch.py\\ model:=/home/ros/src/simulation/humanoid\\_robot/model/human-gazebo/humanSubjectWithMeshes/humanSubjectWithMesh\\_simplified.urdf}\n\n\\section{human-gazebo}\\label{human-gazebo}\n\nThis repository contains the human gazebo models that are used with\n\\href{https://github.com/robotology/human-dynamics-estimation}{Human\nDynamics Estimation} software suite. The files are generated using\n\\href{https://www.xsens.com/}{xsens motion capture} data and\n\\href{https://github.com/ami-iit/mvnx-to-urdf}{mvnx-to-urdf}. The human\nmodel links are made of several simple rigid bodies as shown in the\nfigure below:\n\n{Human model image}\n\nThe measurements of each of the human subject are available from the\ntable. Please refer to the human subject data pdf file to know how these\nmeasurements are taken. The urdf models are generated from xsens mvnx\nfile generated through xsens mvn studio software suite. The code to\ngenerate the model is available\n\\href{https://github.com/dic-iit/human-model-generator}{here}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.1100}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0600}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.1100}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}\n  >{\\centering\\arraybackslash}p{(\\linewidth - 22\\tabcolsep) * \\real{0.0800}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\centering\nSubject\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nMass {[}kg{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nHeight {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nFoot size {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nArm span {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nAnkle height {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nHip height {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nHip width {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nKnee height {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nShoulder width {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nShoulder height {[}cm{]}\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\centering\nSole height {[}cm{]}\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n1 & 62.2 & 168 & 24 & 163 & 8 & 91 & 25 & 48.5 & 35.4 & 140 & - \\\\\n2 & 79.4 & 176 & 26 & 169 & 8 & 94 & 33 & 48 & 40 & 140 & - \\\\\n3 & 75.4 & 180 & 27 & 190 & 8 & 102 & 28 & 58 & 43 & 148 & - \\\\\n4 & 72.7 & 182 & 26 & 197 & 8 & 102 & 29 & 56 & 42 & 150 & - \\\\\n5 & 55 & 168 & 24 & 168 & 8 & 98 & 25 & 52 & 38 & 139 & - \\\\\n6 & 71.2 & 179 & 29 & 180 & 8 & 100 & 31 & 49 & 43 & 147 & - \\\\\n7 & 78.9 & 178 & 28 & 192 & 8 & 102 & 30 & 52 & 44 & 148 & - \\\\\n8 & 55.2 & 166 & 25 & 170 & 8 & 90 & 28 & 45 & 37 & 139 & - \\\\\n\\end{longtable}\n}\n\nCurrently, the legacy directory contains files related to joint motor\ncontrol boards based on\n\\href{https://github.com/robotology/gazebo-yarp-plugins}{gazebo-yarp-plugins}\nand other configuration files needed to control the human joints.\n\n\\subsection{Human subject with meshes}\\label{human-subject-with-meshes}\n\nIn the folder \\href{./humanSubjectWithMeshes}{humanSubjectWithMeshes}\nthere is a \\texttt{urdf} model of a human subject generated using the\ncode in\n\\href{https://github.com/ami-iit/human-model-generator}{human-model-generator}\nwith meshes under CC-BY\\_SA license\n(https://creativecommons.org/licenses/by-sa/2.0/deed.en); all the meshes\nwere trimmed, morphed and totally or partially reconstructed to reach\nthe desired shape and topology. The model is shown in the following\nfigure:\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={humanSubjectWithMesh}]{/tmp/media-e0c46393b624552d/84e6c124fb61591f0124067dab47039400628e2c.png}}\n\n\\subsection{Mantainers}\\label{mantainers}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Davide Gorbani\n  (\\href{https://github.com/davidegorbani}{@davidegorbani})\n\\item\n  Carlotta Sartore\n  (\\href{https://github.com/CarlottaSartore}{@CarlottaSartore})\n\\end{itemize}\n\nThe meshes in this folder have been derived from\nhttps://blendswap.com/blend/11604.\n\nThis module is for the control of the human model in gazebo.\n\n\\section{aruco\\_localization package}\\label{aruco_localization-package}\n\nThis is the \\texttt{aruco\\_localization} package, which runs a ros2 node\nthat takes images from camera topics \\texttt{CAMERA\\_X/camera\\_info} and\n\\texttt{CAMERA\\_X/image\\_raw}, process the aruco code, and publishes the\nresult in publishes the \\texttt{/TF} of the detected ArUco marker,\nmimicking Volvo’s logic for tracking robot positions and generating\nnavigation routes. A launch file is provided to run multiple nodes, with\neach node dedicated and assigned to a single camera.\n\\texttt{camera\\_enabled\\_ids} variable found in \\texttt{src/control.sh}\nis used to control which cameras are enabled.\n\n\\textbf{Note:} The marker link is named based on the camera. For\nexample, if camera \\texttt{164} detects an ArUco marker with ID of\n\\texttt{12}, the marker link in \\texttt{/tf} is named\n\\texttt{camera\\_164\\_marker\\_12}. This is not the final link that is\nused. The result from different cameras are accumulated and merged as a\nsingle frame with parent as \\texttt{robot\\_agent\\_12\\_odom} and child\n\\texttt{robot\\_agent\\_12\\_baselink}.\n\n\\textbf{Note:} The marker ID is tightly linked with the name for the\nrobots, meaning an aruco with marker\\_ID=1 will detect the robot with\nname: \\{namespace\\}\\_\\{marker\\_ID\\}. For example ‘robot\\_agent\\_1’\nCurrently the namespace is hardcoded into the package and can be made\nmore abstract.\n\n\\subsection{Important points to pay attention\nto:}\\label{important-points-to-pay-attention-to}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  If two cameras are pointed at the same ArUco code, the system does not\n  alternate between them, but instead shows the midpoint between the two\n  detections.\n\\item\n  Inside the aruco\\_node, a callback logs the relative position of the\n  newly created \\texttt{aruco\\_link} from the \\texttt{base\\_link}.\n\\item\n  Multiple cameras can be linked to the same ArUco code simultaneously.\n\\end{itemize}\n\n\\subsection{Important launch files}\\label{important-launch-files}\n\n\\begin{itemize}\n\\item\n  \\texttt{aruco\\_detection\\_node.py}: Handles ArUco detection and\n  publishes the TF between the camera and marker.\n  (e.g.~\\texttt{camera\\_164\\_marker\\_12})\n\\item\n  \\texttt{aruco\\_pose\\_pub.py}: A new node that listens to all\n  transforms of \\texttt{camera\\_164\\_marker\\_12} as input, and outputs\n  the transform to either TF or ODOM as \\texttt{robot\\_agent\\_12\\_odom}\n  and child \\texttt{robot\\_agent\\_12\\_baselink}.\n\\item\n  \\texttt{multi\\_detection.launch.py}: Launch file for the new node.\n\\end{itemize}\n\n\\subsection{Odom}\\label{odom}\n\nThese has to be valid for both humanoid and pallet trucks\n\n\\begin{itemize}\n\\tightlist\n\\item\n  world : is the origin (0,0,0)\n\\item\n  odom : should not be in the world frame but where the robot is spawned\n\\item\n  base\\_link: tracks the movement of the robots relative to the odom\n\\end{itemize}\n\n{Coordinate}\n\n\\section{FAILSAFE for the navigation of pallet\ntrucks}\\label{failsafe-for-the-navigation-of-pallet-trucks}\n\nThe SIMLAN systems support a failsafe and geo-fencing mechanism for the\npallet trucks navigation. The main idea is that the pallet trucks should\nstop the navigation as soon as a dangerous situation below are detected:\n\nIn this approach for a new Behavior Tree \\textbf{condition node} named\n\\href{simulation/bt_failsafe/include/bt_failsafe/stop_robot.hpp}{\\texttt{StopRobotCondition}}\nis defined that can be triggered when a safety issue is occuured. We\nthen added a\n\\href{simulation/bt_failsafe/bt_failsafe_plugins.xml}{Behavior Tree\nplugging} that when this condition is triggered, a standard action\ncalled\n\\href{https://docs.nav2.org/configuration/packages/bt-plugins/actions/CancelControl.html}{CancelControl}\n.\n\nCurrently these safety controlled triggers \\texttt{StopRobotCondition}:\n\n\\subsubsection{Activation of collision\nsensor}\\label{activation-of-collision-sensor}\n\nWhen the collision is detected by the simulator, the collision’s\nphysical properties (such as the force and the object that pallet truck\ncollided) are published in the pallet trucks \\texttt{/contact} topic.\n\n\\subsubsection{Loss of Observability}\\label{loss-of-observability}\n\nTo implement geofencing and the safety situation in which a pallet truck\nis not observable in any camera. \\texttt{aruco\\_localization} pkg under\n\\texttt{aruco\\_localization/aruco\\_pose\\_pub.py} continuously published\nthe list of pallet truck that are not observable in\n\\texttt{/aruco\\_marker\\_lost} topic.\n\n\\subsection{Behavior tree and direct implementation in\naruco\\_localization\npkg}\\label{behavior-tree-and-direct-implementation-in-aruco_localization-pkg}\n\nAt first we define a custom \\texttt{behavior\\_tree.xml} in\n\\texttt{src/simulation/pallet\\_truck/pallet\\_truck\\_navigation/config/navigate\\_w\\_replanning\\_and\\_recovery\\_robot\\_agent\\_X.xml}.\nThis xml files defines which bt plugins we want to use during the\nnavigation and which are ran continously during the navigation. In this\nxml-file the \\texttt{StopRobotCondition} and \\texttt{CancelControl}\nplugins are defined in a fallback function. A fallback function works as\nits run the first stated plugin, and when that plugin fails it moves\nover to the second one an executes that plugin. So in this case we firs\nrun the \\texttt{StopRobotCondition} plugin until the robot is out of\nbounds and the plugin fail. And then the \\texttt{CancelControl} plugin\nexecutes and stops the pallet truck.\n\nIn order to know whether a pallet truck is out of bounds or not is\ndetermined by looking at the aruco marker on the pallet truck and decide\nif its seen by any of the cameras or not. This is implemented in the\n\\texttt{aruco\\_localization} pkg under\n\\texttt{aruco\\_localization/aruco\\_pose\\_pub.py}. As soon as the aruco\nmarker on the pallet truck isn’t seen by any of the cameras the node\npublishes the robot namespace in a list to the topic\n\\texttt{/aruco\\_marker\\_lost}.\n\nSame for the collision sensor. It publishes to the topic\n\\texttt{/robot\\_agent\\_X/contact} when the pallet trucks collide with\nsomething.\n\nStep two in the failsafe is to stop the pallet truck when it gets out of\nbounds or collide with something. This is done by a custom made behavior\ntree plugin StopRobotCondition which is find in\n\\texttt{SIMLAN/simulation/bt\\_failsafe/src/stop\\_robot.cpp}. This plugin\nlisten to the \\texttt{/aruco\\_marker\\_lost} and\n\\texttt{/robot\\_agent\\_X/contact} topic and as soon it publishes it\nfails and the \\texttt{CancelControl} behavior tree starts, which finally\nstops the pallet truck. The \\texttt{CancelControl} plugin is a existing\nbuilt in plugin in Nav2.\n\n\\subsubsection{Why Nav2 behavior tree plugins was not\nsuitable}\\label{why-nav2-behavior-tree-plugins-was-not-suitable}\n\nWe tried to use only built in plugins which most likely is the most\nrobust and secure way to do it on as the plugins is updated accordingly\nto Ros2 and Nav2.\n\nWe tried to use several plugins to detect if the pallet trucks are out\nof bounds, but non of them really suits this project and purpose.\n\nThe first one we tried to use is the \\texttt{TransformAvailable} plugin\n(https://github.com/ros-navigation/navigation2/blob/main/nav2\\_behavior\\_tree/plugins/condition/transform\\_available\\_condition.cpp).\nThis plugin checks if a sertain tf exists and if its missing the plugin\nreturns \\texttt{FAILURE}. So in this case we thought we could look at\nthe TFs between the cameras and the aruco marker, and if non of them\nexists it should fail and stop the pallet truck. Unfortunately we\ncouldn’t use this plugin because it only look at the tf from the very\nbeginning of the navigation. And if it exists from the beginning it will\nalways succeed and will never return \\texttt{FAILURE}. Therefore it cant\nbe use in our case because we have TF from the beginning, and our TF\ndisappears after some time during the navigation. You could probably\nmodify the plugin to work for our case as well, but that isn’t a way we\nwanted to go with this.\n\nThe second plugin we tried is the \\texttt{IsStuckCondition}\n(https://github.com/ros-navigation/navigation2/blob/main/nav2\\_behavior\\_tree/plugins/condition/is\\_stuck\\_condition.cpp)\nThis plugin checks if the robot is stuck by calculating the\ndeacceleration of the robot. If the deacceleration is to big it returns\n\\texttt{FAILURE}. This wasn’t anything we could use because the\nacceleration is set to zero as soon as the robot get out of bounds. So\nthis is probably not suitable at all for a case like ours.\n\n\\section{Humanoid}\\label{humanoid}\n\nIn this file, the basics of the humanoid structure will be described. In\nthe future all nodes will be namespaced to add the functionality of\nspawning and controlling multiple humanoids.\n\n\\subsubsection{Moveit}\\label{moveit}\n\nFor moveit to work 3 component must have correct information:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  URDF link names\n\\item\n  SRDF joint definitions\n\\item\n  TF frames published by robot\\_state\\_publisher\n\\end{itemize}\n\nThere was an issue when trying to add namespaces to the humanoid\nproject. Since the humanoid is made of 40+ links, it was decided to add\nthe \\texttt{\"frame\\_prefix\":\\ f\"\\{namespace\\}\"} in the\nrobot\\_state\\_publisher node. This however made a conflict since the\nURDF, SRDF and TF frames no longer matched. This was solved by adding\n\\texttt{base\\_link} in between the world and namespace/base\\_link frames\nand creating a static transform between them. \\textbf{This means that\nall further humanoids will be spawned under `base\\_link frame.}\n(otherwise the warning below again appears)\n\n\\subsubsection{Dynamically updated\nurdfs}\\label{dynamically-updated-urdfs}\n\nto make the nultiple\\_humanoid\\_spawn work we need to be able to launch\ndifferent namespaces in the robot\\_description. this is done by running:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\NormalTok{moveit\\_config }\\OperatorTok{=}\\NormalTok{ (}\n\\NormalTok{    MoveItConfigsBuilder(}\\StringTok{\"human\\_support\"}\\NormalTok{, package\\_name}\\OperatorTok{=}\\StringTok{\"humanoid\\_support\\_moveit\\_config\"}\\NormalTok{)}\n\\NormalTok{    .robot\\_description(}\n\\NormalTok{        file\\_path}\\OperatorTok{=}\\StringTok{\"config/human\\_support.urdf.xacro\"}\\NormalTok{, mappings}\\OperatorTok{=}\\NormalTok{\\{}\\StringTok{\"namespace\"}\\NormalTok{: namespace\\}}\n\\NormalTok{    )}\n\\NormalTok{    .to\\_moveit\\_configs()}\n\\NormalTok{)}\n\\end{Highlighting}\n\\end{Shaded}\n\nthis updates the \\texttt{namespace} argument inside the .xacro files\n\n\\subsubsection{Planning scene monitor}\\label{planning-scene-monitor}\n\nWhen working with the moveit package, some bugs or undesired features\nwere found. When moveit is launched, the PlanningSceneMonitor and\nPlanningFrame subscribes to all TF\\_frames that exists and assumes it\ncan transform any known object or sensor data into its planning frame\nwhich is base\\_link in this case. If this cannot be done it will throw a\nwarning saying the following:\n\n\\begin{verbatim}\n[WARN] [humanoid.moveit.moveit.ros.planning_scene_monitor] [id]: Unable to transform object from frame 'unconnected_frame' to planning frame 'base_link' (Could not find a connection between 'base_link' and 'unconnected_frame' because they are not part of the same tree. TF has two or more unconnected trees)\n\\end{verbatim}\n\nto limit this a wait function was added:\n\\texttt{ld.add\\_action(TimerAction(period=5.0,\\ actions={[}rsp\\_node{]}))}\nto make sure the transform is published before the rsp\\_node starts\n\n\\subsubsection{Figures}\\label{figures}\n\n{My Robot Diagram} \\emph{Figure 1: Humanoid frames visualization}\n\n\\subsection{Rviz2 visualization}\\label{rviz2-visualization}\n\nIf you want to visualize the movement in rviz you need to configure the\n\\texttt{config/moveit.rviz} file and change all\n\\texttt{/humanoid\\_X}instances to the namespace you want to visualize.\n\n\\subsection{Bugs}\\label{bugs}\n\n\\subsubsection{TF visualization and gazebo simulation not\nmatching}\\label{tf-visualization-and-gazebo-simulation-not-matching}\n\nWhen visualizing and comparing the actual TF data and simulated\nlocations of the humanoids when doing navigation nad teleoping it can be\nseen that these do not match. This is a major issue since that means the\nlocation of where the humanoids think they are in the map and the\nlocation of where the humanoids actual are in gazebo will be different.\nThis can be visualized by turning the humanoid 360 degrees in gazebo\nwith the \\texttt{./control.sh\\ teleop\\ humanoid\\_1} command and\ncomparing to rviz. There the humanoid has turned closer to 300 degrees.\n\nThis problem probably comes from some urdf descriptions not matching the\nactual geometry or specifications the humanoid has in\n\\texttt{/home/ros/src/simulation/humanoid\\_support\\_moveit\\_config/config/human\\_support\\_wheels.urdf.xacro}.\nBy tuning the \\texttt{mass}, \\texttt{mu} and \\texttt{inertial} values in\nthe\n\\texttt{\\textless{}xacro:macro\\ name=\"wheel\"\\ params=\"wheel\\_prefix\\ *joint\\_pose\"\\textgreater{}}\nxacro tag it was possible to tune the degree mismatch.\n\nFor proper navigation and control this needs to be fixed!\n\n\\subsection{Preparing Data}\\label{preparing-data}\n\n\\subsubsection{First build the package}\\label{first-build-the-package}\n\nfor example with:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{colcon}\\NormalTok{ build }\\AttributeTok{{-}{-}merge{-}install} \\AttributeTok{{-}{-}symlink{-}install} \\AttributeTok{{-}{-}packages{-}select}\\NormalTok{ visualize\\_real\\_data}\n\\end{Highlighting}\n\\end{Shaded}\n\nAfter that, you can add the required data into the \\texttt{share/}\nfolder that is created during the build process.\n\nIf everything has been built correctly you should find the following\nfolder-structure:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{install/}\n\\ExtensionTok{└──}\\NormalTok{ share/}\n    \\ExtensionTok{└──}\\NormalTok{ visualize\\_real\\_data/}\n        \\ExtensionTok{└──}\\NormalTok{ data/}\n            \\ExtensionTok{├──}\\NormalTok{ images/}\n            \\ExtensionTok{│}\\NormalTok{   └── images}\n            \\ExtensionTok{└──}\\NormalTok{ data}\n\\end{Highlighting}\n\\end{Shaded}\n\nThe empty \\texttt{data} and \\texttt{images} placeholder files ensure\nthat ROS 2 recognizes and preserves the folder structure during the\nbuild and should \\textbf{not} be removed.\n\nIf you have already built the package before there might be another\ndirectory inside the \\texttt{data/} folder called \\texttt{rosbags}. More\non that folder later.\n\n\\subsubsection{Add the data after\nbuilding}\\label{add-the-data-after-building}\n\nAfter the build completes, you can add your data files to the generated\n\\texttt{share/} folder inside your package.\n\nBy default the package expects to find the trajectory data inside the\n\\texttt{data/} folder as \\texttt{.json} and the images inside the\n\\texttt{images/} folder as \\texttt{.jpg}. Like this:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{install/}\n\\ExtensionTok{└──}\\NormalTok{ share/}\n    \\ExtensionTok{└──}\\NormalTok{ visualize\\_real\\_data/}\n        \\ExtensionTok{└──}\\NormalTok{ data/}\n            \\ExtensionTok{├──}\\NormalTok{ images/}\n            \\ExtensionTok{│}\\NormalTok{   ├── image1.jpg}\n            \\ExtensionTok{│}\\NormalTok{   └── image2.jpg}\n            \\ExtensionTok{└──}\\NormalTok{ window\\_2012\\_1746008869618\\_1746008890118.json}\n\\end{Highlighting}\n\\end{Shaded}\n\nNotes:\n\n\\begin{itemize}\n\\item\n  The \\textbf{folder-names are configurable}, as long as the settings in\n  \\texttt{params.yaml} match.\n\\item\n  You can:\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Rename the \\texttt{images/} folder to something else.\n  \\item\n    Rename the trajectory JSON file to any other valid filename.\n  \\end{itemize}\n\\item\n  Just be sure to update the corresponding fields\n  (\\texttt{images\\_folder}, \\texttt{json\\_file\\_name}) in\n  \\texttt{params.yaml}.\n\\end{itemize}\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsubsection{Important Notes}\\label{important-notes}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  You do \\emph{not} need to rebuild the package after adding or\n  modifying data in \\texttt{share/}.\n\\item\n  In fact, \\textbf{rebuilding the package could overwrite or remove any\n  manually added files} in the \\texttt{share/} folder, so avoid\n  rebuilding once your data is in place.\n\\end{itemize}\n\n\\subsection{Config file}\\label{config-file}\n\nWhen your data is in place, you may want to review the config parameters\nin \\texttt{params.yaml}. This step is often optional, as default\nsettings typically work well.\n\n\\subsubsection{\\texorpdfstring{\\texttt{params.yaml}\nOverview}{params.yaml Overview}}\\label{params.yaml-overview}\n\n\\paragraph{\\texorpdfstring{\\texttt{prepare\\_data}\nsection:}{prepare\\_data section:}}\\label{prepare_data-section}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  The Parameters here have to be set before \\texttt{prepare.launch.py}\n  is run. Changes made afterwards will not effect the preparation\n  process (image-\\textgreater PointCloud2).\n\\end{itemize}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.1387}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.7153}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.1460}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nParameter\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDescription\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDefault Value\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{pointcloud\\_topic} & Topic to publish the \\texttt{PointCloud2}\n(image data). & \\texttt{pointcloud\\_topic} \\\\\n\\texttt{images\\_folder} & Name of the folder containing images. &\n\\texttt{images} \\\\\n\\texttt{image\\_scale} & Resize factor for \\texttt{.jpg} images (useful\nfor RViz display). & \\texttt{0.04} \\\\\n\\texttt{set\\_frames} & If \\texttt{true}, limits processing to\n\\texttt{frames\\_to\\_process}; otherwise, all available images will be\nused. & \\texttt{false} \\\\\n\\texttt{frames\\_to\\_process} & Number of frames to process if\n\\texttt{set\\_frames} is \\texttt{true}. & \\texttt{1} \\\\\n\\texttt{preprocess\\_all\\_data} & If \\texttt{true}, preprocesses all\navailable data before playback. May not work for extremely large\nrecording windows. & \\texttt{true} \\\\\n\\texttt{fake\\_orientation} & If \\texttt{true}, automatically fakes\nobject orientations during data preparation (used by the scenario\nreplayer). & \\texttt{true} \\\\\n\\end{longtable}\n}\n\n\\paragraph{\\texorpdfstring{\\texttt{send\\_data}\nsection:}{send\\_data section:}}\\label{send_data-section}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Parameters here can be changed after the prepare-stage to alter the\n  playback. \\emph{You do not need to rebuild the package or re-run\n  prepare.launch.py} if you change something here.\n\\end{itemize}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.1509}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.7264}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.1226}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nParameter\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDescription\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDefault Value\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{playback\\_rate} & Controls playback speed. Default is \\texttt{1}\n(real-time based on \\texttt{extracted\\_fps}). & \\texttt{1} \\\\\n\\texttt{frame\\_position} & \\texttt{x},\\texttt{y},\\texttt{z} coordinates\nfor visualization frame. & \\texttt{x:\\ 15.35,\\ y:\\ 6.5,\\ z:\\ -0.2} \\\\\n\\texttt{bag\\_name} & Name of the rosbag to play. If empty, the most\nrecent one is used. & \\emph{(empty)} \\\\\n\\end{longtable}\n}\n\n\\paragraph{\\texorpdfstring{\\texttt{scenario\\_replayer}\nsection:}{scenario\\_replayer section:}}\\label{scenario_replayer-section}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.2069}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.5517}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.2414}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nParameter\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDescription\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDefault Value\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{gazebo\\_teleport\\_service} & Service name for teleporting robots\nin Gazebo. & \\texttt{/world/default/set\\_pose} \\\\\n\\texttt{frame\\_id} & Frame in which entities are visualized. &\n\\texttt{real\\_data} \\\\\n\\texttt{use\\_cmd\\_vel} & If \\texttt{true}, robots are driven with\nvelocity commands; otherwise, teleportation is used to reenact the\nscenario. When set to \\texttt{true} it is important the simulation runs\nclose to 100\\% real-time. & \\texttt{true} \\\\\n\\end{longtable}\n}\n\n\\paragraph{\\texorpdfstring{\\texttt{shared}\nsection:}{shared section:}}\\label{shared-section}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Parameters here have to be set at the prepare-stage and can’t be\n  changed afterwards.\n\\end{itemize}\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.1716}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.7313}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.0970}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nParameter\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDescription\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDefault Value\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\n\\texttt{frame\\_id} & Name of the frame in which all data is displayed. &\n\\texttt{real\\_data} \\\\\n\\texttt{namespace} & Namespace used for the node. &\n\\texttt{visualize\\_real\\_data} \\\\\n\\texttt{entity\\_topic} & Topic to publish the \\texttt{MarkerArray}\n(trajectory data). & \\texttt{entity\\_topic} \\\\\n\\texttt{json\\_file\\_name} & Name of the file containing trajectory data.\n& (empty) \\\\\n\\texttt{extracted\\_fps} & FPS of the extracted data for playback. &\n\\texttt{10.0} \\\\\n\\texttt{processing\\_time\\_limit} & Max time allowed per frame for\nconsistent playback. If exceeded, a warning appears. & \\texttt{0.8} \\\\\n\\end{longtable}\n}\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsubsection{Launching the Processing\nStep}\\label{launching-the-processing-step}\n\nOnce configured, run:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ launch visualize\\_real\\_data prepare.launch.py}\n\\end{Highlighting}\n\\end{Shaded}\n\nThis will first start the \\texttt{orientation\\_fixer} node which adds an\norientation to the data based on the angle between points in the\ntrajectory. Afterwards the data processing is started and generates a\nrosbag file stored in a \\texttt{rosbags/} folder inside the package’s\n\\texttt{share/} directory. \\textgreater{} \\textbf{NOTE:} If orientation\nis already given, change\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Rosbags are named using the name of the JSON file used and timestamps\n  (e.g., \\texttt{my\\_recording\\_20250722\\_153045} if the JSON file is\n  named \\texttt{my\\_recording.json}).\n\\item\n  Existing rosbags \\textbf{are never overwritten}.\n\\item\n  You can delete old rosbags manually from the \\texttt{rosbags/} folder\n  if needed.\n\\end{itemize}\n\n\\subsection{Sending Data}\\label{sending-data}\n\nAfter processing the data you can send it to RViz:\n\n\\begin{enumerate}\n\\def\\labelenumi{\\arabic{enumi}.}\n\\item\n  Make sure you’ve added the following displays to RViz:\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\texttt{PointCloud2}\n  \\item\n    \\texttt{MarkerArray}\n  \\end{itemize}\n\\item\n  Run:\n\\end{enumerate}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ launch visualize\\_real\\_data send.launch.py}\n\\end{Highlighting}\n\\end{Shaded}\n\nThis command sends the most \\textbf{recently created rosbag} to the\ntopics defined in \\texttt{params.yaml}.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  To play an earlier dataset, you must manually delete newer rosbags as\n  the latest one (by timestamp) is always selected automatically.\n\\end{itemize}\n\n\\subsubsection{Adjusting Playback Speed}\\label{adjusting-playback-speed}\n\nYou can modify the \\texttt{playback\\_rate} parameter in\n\\texttt{params.yaml} to control how quickly the rosbag is replayed.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  A value of \\texttt{1} reflects real-time playback based on extracted\n  timestamps.\n\\item\n  Slower or faster playback is supported, but \\emph{extreme values\n  haven’t been tested}.\n\\end{itemize}\n\n\\subsubsection{Fixing RViz}\\label{fixing-rviz}\n\n\\begin{itemize}\n\\item\n  Usually the displays in RViz have to be configured to subscribe to the\n  correct topics, and the PointCloud2 displays size have to match the\n  image\\_scale defined in the \\texttt{params.yaml} config file to look\n  right.\n\\item\n  You can also change \\texttt{Alpha} in the PointCloud display to see\n  through the image.\n\\item\n  If the images aren’t showing up, sometimes the\n  \\texttt{QOS\\ (Quality\\ of\\ Service)} settings might be mismatched\n  between the \\texttt{rosbag\\ player} and \\texttt{RViz}. The intended\n  \\texttt{QOS\\ settings} can be found in the \\texttt{recorder\\_qos.yaml}\n  file in the \\texttt{config} folder together with the\n  \\texttt{params.yaml} file. These are the settings that the rosbag\n  player uses, and the easiest fix is to make sure that RViz mirrors\n  these settings for the respective displays.\n\\end{itemize}\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsection{Summary}\\label{summary}\n\n\\begin{enumerate}\n\\def\\labelenumi{\\arabic{enumi}.}\n\\tightlist\n\\item\n  Build package using \\texttt{CTRL\\ +\\ SHIFT\\ +\\ B} VS Code task.\n\\item\n  Add the data you want to show in RViz in the package’s \\texttt{share/}\n  folder\n\\item\n  Configure parameters under ‘prepare\\_data’, ‘shared’, and/or\n  ‘scenario\\_replayer’ \\emph{(optional)}\n\\item\n  Run \\texttt{prepare.launch.py}\n\\item\n  Open RViz2 and add the displays \\texttt{PointCloud2} and\n  \\texttt{MarkerArray}\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    Make sure the QOS-settings match between the rosbag player and the\n    displays\n  \\end{itemize}\n\\item\n  Configure parameters under ‘send\\_data’ \\emph{(optional)}\n\\item\n  Run \\texttt{send.launch.py}\n\\item\n  Subscribe to the relevant topics (as defined in \\texttt{params.yaml})\n  in RViz2\n\\end{enumerate}\n\nNow the data should be visualized.\n\n\\begin{center}\\rule{0.5\\linewidth}{0.5pt}\\end{center}\n\n\\subsubsection{Warnings and Errors from the\nnode}\\label{warnings-and-errors-from-the-node}\n\nWarnings and Errors thrown by this package are intended to inform you\nwhen something unexpected occurs during execution. In most cases, the\nprocess can continue without interruption, although the output may be\naffected.\n\nIt is strongly recommended to resolve the underlying issue based on the\nwarning/error message and then \\textbf{re-run the process} to ensure\nreliable and consistent output.\n\n\\section{🚀 Scenario Manager}\\label{scenario-manager}\n\n\\subsection{📌 Overview}\\label{overview}\n\nThe \\texttt{scenario\\_manager} package is a ROS2 package designed to\nmanage and execute various robot scenarios involving teleportation,\nspeed setting, and collision simulations. It provides action servers to\ncontrol robot behavior and a tool for calculating Time to Collision\n(TTC).\n\n\\subsection{🚦 Launching the Scenario\nManager}\\label{launching-the-scenario-manager}\n\nTo start the \\texttt{scenario\\_manager}, launch it using the following\ncommand:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ launch scenario\\_manager scenario\\_manager.launch.py}\n\\end{Highlighting}\n\\end{Shaded}\n\nThis initializes three action servers: - \\textbf{🚀\nteleport\\_action\\_server}: Handles teleportation of robots. - \\textbf{⚡\nset\\_speed\\_action\\_server}: Controls robot speed. - \\textbf{💥\ncollision\\_action\\_server}: Configures scenarios where robots collide\n(only applicable to \\texttt{jackal} and \\texttt{pallet\\_truck}).\n\n\\subsection{🔄 Collision Action Server}\\label{collision-action-server}\n\nThe \\textbf{collision\\_action\\_server} configures collisions by setting\nspeeds and initial positions for two robots to ensure a collision\noccurs. It requires: - \\textbf{📐 Angle}: The approach angle. -\n\\textbf{🏎️ Speed of pallet\\_truck}: The movement speed of the pallet\ntruck. - \\textbf{💠 Collision Type}: An enum from the\n\\texttt{simlan\\_custom\\_msg} package specifying the type of collision.\n\n\\subsubsection{💥 Collision Types}\\label{collision-types}\n\nThere are three predefined collision types:\n\n{\\def\\LTcaptype{none} % do not increment counter\n\\begin{longtable}[]{@{}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.3684}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.2895}}\n  >{\\raggedright\\arraybackslash}p{(\\linewidth - 4\\tabcolsep) * \\real{0.3421}}@{}}\n\\toprule\\noalign{}\n\\begin{minipage}[b]{\\linewidth}\\raggedright\nCollision Type\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nEnum Value\n\\end{minipage} & \\begin{minipage}[b]{\\linewidth}\\raggedright\nDescription\n\\end{minipage} \\\\\n\\midrule\\noalign{}\n\\endhead\n\\bottomrule\\noalign{}\n\\endlastfoot\nHEAD\\_ON & \\texttt{0} & Robots collide head-on. \\\\\nPALLET\\_TRUCK\\_SIDE & \\texttt{1} & Pallet truck collides into the side\nof Jackal. \\\\\nJACKAL\\_SIDE & \\texttt{2} & Jackal collides into the side of the pallet\ntruck. \\\\\n\\end{longtable}\n}\n\nBelow are images illustrating the different collision types:\n\nLeft: Head-On Collision \\textbar{} Middle: Pallet Truck Side Collision\n\\textbar{} Right: Jackal Side Collision\n\n\\subsection{🎬 Running a Scenario}\\label{running-a-scenario}\n\nTo execute a scenario, use the following command:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ launch scenario\\_execution\\_ros scenario\\_launch.py scenario:=}\\OperatorTok{\\textless{}}\\NormalTok{scenario\\_file}\\OperatorTok{\\textgreater{}}\n\\end{Highlighting}\n\\end{Shaded}\n\nReplace \\texttt{\\textless{}scenario\\_file\\textgreater{}} with a specific\nscenario file, such as:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ launch scenario\\_execution\\_ros scenario\\_launch.py scenario:=simulation/scenario\\_manager/scenarios/case1.osc}\n\\end{Highlighting}\n\\end{Shaded}\n\nThis runs a collision action client, executing multiple collision\nsimulations with varying angles and speeds.\n\n\\subsection{⏳ Time to Collision (TTC)\nCalculation}\\label{time-to-collision-ttc-calculation}\n\nThe package includes a \\textbf{TTC node} that logs the \\textbf{Time to\nCollision (TTC)} and \\textbf{Closest Point of Arrival (CPA)} for two\nrobots assuming constant speed and direction.\n\n\\subsubsection{▶️ Running the TTC Node}\\label{running-the-ttc-node}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{ros2}\\NormalTok{ run scenario\\_manager ttc}\n\\end{Highlighting}\n\\end{Shaded}\n\nThis node calculates and logs: - \\textbf{⏱️ TTC}: The time at which the\nclosest approach occurs. - \\textbf{📍 CPA}: The closest distance between\nthe two robots assuming constant speed and trajectory.\n\n📌 \\emph{Note:} As of version \\textbf{1.0.6 (February 2025)}, the TTC\nnode logs data but does not publish it elsewhere.\n\n\\subsection{Moveit Panda robot}\\label{moveit-panda-robot}\n\nThis package contains code for a robot called\n\\href{https://github.com/moveit/moveit_resources}{“Panda”} which\nincludes a description/urdf’s (see \\texttt{panda\\_description/}). Inside\nthe \\texttt{panda\\_moveit\\_config/} exists all code and config files\nthat allow you to spawn a panda robot in gazebo and be able to plan and\nexecute motions. Inside \\texttt{config/} the are several \\texttt{*.yaml}\nfiles which acts as configurations, and many\n\\texttt{*.srdf,\\ *.urdfs\\ *.xacro} files. These are all related to the\nsame panda robot. The main description file is\n\\texttt{panda.urdf.xacro}.\n\nTo run our package make sure that gazebo simulator is running. Then we\ncan run the \\texttt{panda\\_moveit\\_config/launch/demo.launch.py} which\nwill do the following:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Spawn a panda robot in gz and publish its \\texttt{robot\\_description}.\n\\item\n  Start rviz with a preset moveit config\n\\item\n  Start the \\texttt{move\\_group\\_node} which handles all planning and\n  executing of motions.\n\\item\n  Load all controllers for panda so that it can be controlled in Gazebo\n\\end{itemize}\n\n\\subsection{Moveit motion planner using Python\nAPI}\\label{moveit-motion-planner-using-python-api}\n\nThe\nfolder\\href{https://moveit.picknik.ai/main/doc/examples/motion_planning_python_api/motion_planning_python_api_tutorial.html}{\\texttt{custom\\_motion\\_planning\\_python\\_api}}\nhas scripting files that plans and executes motions for a panda robot.\nIt uses the official moveit2 python API to achieve this. In this\npackage’s \\texttt{scripts/} folder exists these python files. Look at\nthe demo scripts for inspiration. To run any of the scripts you run the\nlaunch file: -\n\\texttt{motion\\_planning\\_python\\_api\\_planning\\_scene.py} is an\noriginal demo from moveit2 -\n\\texttt{motion\\_planning\\_python\\_api\\_tutorial.py} is an original demo\nfrom moveit2 - \\texttt{demo\\_pick\\_and\\_place.py} is custom made.\n\n\\texttt{moveit2\\_py} package is not currently available for Humble but\nJazzy supports it. The pre-requisites to run a motion planner script is\nto run these in parallel terminals:\n\\texttt{gazebo\\ sim\\ \\&\\ panda\\_moveit\\_config/launch/demo.launch.py}.\nWhen these to are finished initializing, run the motion script with:\n\\texttt{motion\\_planning\\_python\\_api\\_tutorial.launch.py}\n\n\\section{MoveIt Resources}\\label{moveit-resources}\n\nThis repository includes various resources (URDFs, meshes,\nmoveit\\_config packages) needed for MoveIt testing.\n\nGitHub Actions:\n\\href{https://github.com/ros-planning/moveit_resources/actions/workflows/format.yml?query=branch\\%3Aros2}{\\pandocbounded{\\includegraphics[keepaspectratio,alt={Formatting (pre-commit))}]{/tmp/media-e0c46393b624552d/72cda7deeb1ec2ecd61fc3d07af1ba7abd3c2a00.pdf}}}\n\\href{https://github.com/ros-planning/moveit_resources/actions/workflows/industrial_ci_action.yml?query=branch\\%3Aros2}{\\pandocbounded{\\includegraphics[keepaspectratio,alt={Build and Test}]{/tmp/media-e0c46393b624552d/ff203949bacb8315370680941bbf95172a9c7737.pdf}}}\n\n\\subsection{Included Robots}\\label{included-robots}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  PR2\n\\item\n  Fanuc M-10iA\n\\item\n  Franka Emika Panda\n\\end{itemize}\n\n\\subsection{Notes}\\label{notes}\n\nThe benchmarking resources have been moved to\nhttps://github.com/ros-planning/moveit\\_benchmark\\_resources.\n\n\\section{panda\\_description}\\label{panda_description}\n\n\\begin{quote}\nNote: This package contains a panda.urdf and a newer panda.urdf.xacro.\nThe XACRO has been created to support finding package resource files\ndynamically which is needed for Gazebo. The URDF is still needed by\n\\href{https://github.com/ros-planning/moveit2/blob/main/moveit_core/utils/src/robot_model_test_utils.cpp\\#L75}{RobotModelTestUtils}\nwhich doesn’t support xacro yet.\n\\end{quote}\n\nThe URDF model and meshes contained in this package were copied from the\nfrankaemika \\texttt{franka\\_ros} package and adapted for use with\n\\texttt{moveit\\_resources}.\n\nAll imported files were released under the Apache-2.0 license.\n\n\\subsection{MoveIt Resources for testing: Franka Emika\nPanda}\\label{moveit-resources-for-testing-franka-emika-panda}\n\nA project-internal moveit configuration for testing in MoveIt.\n\nUse the official panda\\_moveit\\_config if you actually want to work with\nthe robot!\n\nDyno-robotics/Infotiv delivery\n\nSetting \\texttt{self.MODE\\ =\\ \"abnormal/normal\"} in the main script\ncauses the object movement to deviate from the normal distribution\nspecified above.\n\nTo reproduce\n\n\\begin{verbatim}\ngit checkout ....\n# In three separate terminals:\n./control.sh clean ; ./control.sh build ; ./control.sh sim\n./control.sh move_object\n./control.sh camera_dump\n\\end{verbatim}\n\n\\subsection{Random, In Distribution Objects Movement (normal\nmode)}\\label{random-in-distribution-objects-movement-normal-mode}\n\nData collection from cameras according to\n\\href{resources/20240522-req.png}{requirements}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Random self.objects are placed within the position range self.grid\\_x,\n  self.grid\\_y: REQ.ID.1\n\\item\n  Random rotation along the z axis.\n\\item\n  You can use \\texttt{camera\\_config\\ ID.xacro} for placement of several\n  cameras in the intersection. You can alternatively use\n  \\texttt{camera\\_config\\ ID\\_noise.xacro} to slightly changes the\n  camera settings (REQ.ID.2) as below:\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    at most +-10 degree (+-0.1) rotation around one of the axis\n  \\item\n    at most +-10cm (+-0.1) change in x,y,z coordinates\n  \\end{itemize}\n\\end{itemize}\n\n\\subsection{Random, Out of Distribution Objects Movement (abnormal\nmode)}\\label{random-out-of-distribution-objects-movement-abnormal-mode}\n\nData collection from cameras according to\n\\href{resources/20240610-req.png}{requirements}.\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Addition of other objects (spotlight, support pole, traffic cone):\n  REQ.OD.1, REQ.OD.2.\n\\item\n  With some probability, the objects don’t leave the scene and may\n  coexist and collide with new objects: REQ.OD.3.\n\\item\n  Objects are at least rotated by π/4 (45 degrees, upside-down object):\n  REQ.OD.3, REQ.OD.4.\n\\item\n  The spotlight is tilted by π/6 (30 degrees): REQ.OD.1.\n\\item\n  Objects are not placed on the ground and instead are dropped from a\n  height of 2-3 meters: REQ.OD.4.\n\\end{itemize}\n\n\\subsubsection{Deterministic, Disentanglement One-parameter Object\nMovements (one\\_object\\_deterministic\nmode)}\\label{deterministic-disentanglement-one-parameter-object-movements-one_object_deterministic-mode}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Object: forklift\n\\item\n  Camera: 1\n\\item\n  (\\#Parameter: orientation of forklift)\n\\item\n  Annotation: Position and rotation of the forklift. Annotation in\n  filename.\n\\item\n  256x256 RGB non compression\n\\end{itemize}\n\n./control.sh sim ./control.sh move\\_object ./control.sh camera\\_dump\n\n\\section{Humanoid Motion Capture}\\label{humanoid-motion-capture}\n\nThis project develops a system for translating human pose detection to\nhumanoid robot motion in simulation environments. Using Google MediaPipe\nfor pose landmark detection from camera input, the system maps detected\nhuman poses to corresponding joint movements executed by a humanoid\nrobot in Gazebo simulator. The implementation leverages ROS2 Ignition\nand MoveIt2 for motion planning and control, with a data generation\npipeline that creates training pairs of pose landmarks and robot joint\nconfigurations. This approach provides a foundation for safety\nmonitoring applications in industrial simulation (SIMLAN), where human\npose analysis can be integrated for workplace incident detection. The\nwork is based on master thesis “Human Motion Replay on a Simulated\nHumanoid Robot Using Pose Estimation” by Tove Casparsson and Siyu Yi,\nSupervised by Hamid Ebadi, June 2025.\n\n{Pose translation}\n\n\\subsection{Terminology:}\\label{terminology}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\textbf{Forward Kinematics (FK)}: The process of calculating the\n  position and orientation of a robot’s links given the values of its\n  joint parameters (e.g., angles or displacements). In other words, FK\n  answers the question: “Where is the robot’s hand if I know all the\n  joint values? (usually have one answer)”\n\\item\n  \\textbf{Inverse Kinematics (IK)}: The process of determining the joint\n  parameters (e.g., angles or displacements) required to achieve a\n  desired position and orientation of the robot’s links. In other words,\n  IK answers the question: “What joint values will place the robot’s\n  hand here? (usually have many answers)”\n\\item\n  \\textbf{Pose} : 3D pose landmarks (MediaPipe) extracted by Mediapipe\n  from an 2D image of human posture\n\\item\n  \\textbf{Motion} : A kinematic instruction (joint parameters) sent to\n  the robot (via MoveIt) for execution. While “kinematic instruction”\n  would be a more accurate term, we continue to use “motion” for\n  historical reasons (used in the word motion-capture), even though ,\n  “motion” often refers to the difference/movement between two postures\n  (e.g., posture2 - posture1).\n\\item\n  \\textbf{Motion Capture}: Here it means using 2D images to find the\n  motion(kinematic instruction/joint parameters) to instruct a humanoid\n  robot to mimic the human posture.\n\\end{itemize}\n\n\\subsection{Dataset}\\label{dataset}\n\nTo find the implementation of how the dataset is created, go to\n\\href{./pre_processing/}{pre\\_prossessing/ directory}. We have two\ndataformats for multi and single camera prediction.\n\nFor the single-camera dataset, each row in the CSV file represents\n\\textbf{one pose} sample and its corresponding robot motion from a\nspecific camera. - The first columns are the 3D coordinates (x, y, z)\nfor each of the 33 MediaPipe pose landmarks, named like\n\\texttt{cam500\\_0\\_x,\\ cam500\\_0\\_y,\\ cam500\\_0\\_z,...}. - The remaining\ncolumns are the robot joint positions (motion targets) for that sample,\nwith names like \\texttt{jRightShoulder\\_rotx},\n\\texttt{jLeftElbow\\_roty}, etc.\n\nFor the multi-camera dataset, each row in the CSV file represents\n\\textbf{multiple poses} samples \\textbf{from each camera} and its\ncorresponding robot motion. - the first columns are the 3D coordinates\n(x, y, z) for each of the 33 MediaPipe pose landmarks and \\textbf{for\neach camera}, named like\n\\texttt{cam500\\_0\\_x,\\ cam501\\_0\\_x,\\ cam502\\_0\\_x,\\ cam503\\_0\\_x,\\ cam500\\_0\\_y,\\ cam501\\_0\\_y,\\ cam502\\_0\\_y,\\ cam503\\_0\\_y,\\ cam500\\_0\\_z,\\ cam501\\_0\\_z,\\ cam502\\_0\\_z,\\ cam503\\_0\\_z...}.\n- The remaining columns are the robot joint positions (motion targets)\nfor that sample, with names like jRightShoulder\\_rotx, jLeftElbow\\_roty,\netc.\n\n\\subsubsection{Translation of a detected pose to humanoid motion\ncommand\\hspace{0pt}}\\label{translation-of-a-detected-pose-to-humanoid-motion-command}\n\nThis project employs a deep neural network to learn the mapping between\nhuman pose and humanoid robot motion. The model takes 33 MediaPipe pose\nlandmarks as input and predicts corresponding robot joint positions.\n\n\\subsubsection{Neural network design}\\label{neural-network-design}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Input Layer: 33 MediaPipe pose landmarks for each camera (x, y, z\n  coordinates).\n\\item\n  Hidden Layers: Multi-layer perceptron with pose normalization\n  preprocessing\n\\item\n  Output Layer: Robot joint position sequences for humanoid motion\n  control, this results in a total of 47 joints to be outputed.\n\\item\n  Training: Supervised learning on pose-motion paired datasets.\n\\end{itemize}\n\n\\subsection{Project Structure:}\\label{project-structure}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\href{humanoid_ml_requirements.txt}{\\texttt{humanoid\\_ml\\_requirements.txt}}:\n  Contains the humanoid machine learning requirements\n\\item\n  \\href{input}{\\texttt{input/}} : This folder has the pose data to be\n  predicted\n\\item\n  \\href{output}{\\texttt{output/}} : This folder saves the predicted\n  motion data and intermediate results\n\\item\n  \\href{DATASET_RAW/TRAIN}{\\texttt{/DATASET\\_RAW/TRAIN}}: Contains\n  motion, pose and image files generated by\n  \\texttt{./control.sh\\ dataset\\ TRAIN}\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\texttt{motion\\_data} : Corresponding random motion (request)\n  \\item\n    \\texttt{camera/pose\\_data} : Mediapipe pose (result) for each camera\n  \\item\n    \\texttt{camera/pose\\_images}: Mediapipe annotated images and\n    original images for each camera\n  \\end{itemize}\n\\item\n  \\href{DATASET_RAW/EVAL}{\\texttt{/DATASET\\_RAW/EVAL}}: Contains motion,\n  pose and image files generated by \\texttt{./control.sh\\ dataset\\ EVAL}\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\texttt{motion\\_data} : Corresponding random motion (request)\n  \\item\n    \\texttt{camera/pose\\_data} : Mediapipe pose (result) for each camera\n  \\item\n    \\texttt{camera/pose\\_images}: Mediapipe annotated images and\n    original images for each camera\n  \\end{itemize}\n\\item\n  \\href{pre_processing}{\\texttt{pre\\_processing/}}: contains all\n  pre-processing files, used to convert the JSON data into tabular data.\n  This will be the input of the model.\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\href{mp_detection.py}{\\texttt{mp\\_detection.py}}: Handles pose\n    detection from actual images or videos using MediaPipe\n  \\item\n    \\href{load_json_data.py}{\\texttt{load\\_json\\_data.py}}: Build a csv\n    file that contains both pose and motion data from the json files and\n    outputs a default csv format.\\\\\n  \\item\n    \\href{csvtowide.py}{\\texttt{csvtowide.py}}: Convert the default csv\n    format into single and -multi camera csv files. (this data is the\n    actual model input).\n  \\end{itemize}\n\\item\n  \\href{pose_to_motion}{\\texttt{pose\\_to\\_motion/}}: Contains the ML\n  training pipeline for pose-to-motion prediction\n\n  \\begin{itemize}\n  \\tightlist\n  \\item\n    \\href{pose_to_motion/autogluon}{\\texttt{autogluon/}}: directory\n    containing model implementation for autogluon model. Handles\n    training, evaluation, and predicting motions.\n\n    \\begin{itemize}\n    \\tightlist\n    \\item\n      \\href{pose_to_motion/autogluon/model.py}{\\texttt{model.py}}: Main\n      file, contains the implementation for train, evaluation, and\n      prediction.\n    \\item\n      \\href{pose_to_motion/autogluon/utils.py}{\\texttt{utils.py}}: Utils\n      file, contains helper methods, and model definition. The\n      \\texttt{model.py} use this.\n    \\item\n      \\href{pose_to_motion/autogluon/output}{\\texttt{output/}}: Contain\n      reports of ran sessions and saved model states. Saved models will\n      be found here\n\n      \\begin{itemize}\n      \\tightlist\n      \\item\n        \\href{pose_to_motion/autogluon/output/saved_model_states}{\\texttt{saved\\_model\\_states/}}:\n        Saved autogluon models are stored here\\\\\n      \\item\n        \\href{pose_to_motion/autogluon/output/reports}{\\texttt{reports/}}:\n        Manually generated reports file containing training/evaluation\n        run information. Good for reprodusability. The reports are\n        generated by \\texttt{generate\\_report.py} and the new report row\n        is saved in \\texttt{train\\_report.csv} or\n        \\texttt{eval\\_report.csv}\n      \\end{itemize}\n    \\end{itemize}\n  \\item\n    \\href{pose_to_motion/pytorch}{\\texttt{pytorch/}}: directory\n    containing model implementation for pytorch model. Handles training,\n    evaluation, and predicting motions.\n\n    \\begin{itemize}\n    \\tightlist\n    \\item\n      \\href{pose_to_motion/pytorch/model.py}{\\texttt{model.py}}: Main\n      file, contains the implementation for train, evaluation, and\n      prediction.\n    \\item\n      \\href{pose_to_motion/pytorch/utils.py}{\\texttt{utils.py}}: Utils\n      file, contains helper methods, and model definition. The\n      \\texttt{model.py} use this.\n    \\item\n      \\href{pose_to_motion/pytorch/output}{\\texttt{output/}}: Contain\n      reports of ran sessions and saved model states. Saved models will\n      be found here\n\n      \\begin{itemize}\n      \\tightlist\n      \\item\n        \\href{pose_to_motion/pytorch/output/saved_model_states}{\\texttt{saved\\_model\\_states/}}:\n        Saved autogluon models are stored here\\\\\n      \\item\n        \\href{pose_to_motion/pytorch/output/reports}{\\texttt{reports/}}:\n        Manually generated reports file containing training/evaluation\n        run information. Good for reprodusability. The reports are\n        generated by \\texttt{generate\\_report.py} and the new report row\n        is saved in \\texttt{train\\_report.csv} or\n        \\texttt{eval\\_report.csv}\n      \\item\n        \\href{pose_to_motion/pytorch/output/optuna_studies}{\\texttt{optuna\\_studies/}}:\n        Specific for pytorch. Optuna studies are stored at this folder.\n        See \\hyperref[optuna]{optuna section} for more information about\n        Optuna.\n      \\end{itemize}\n    \\end{itemize}\n  \\item\n    \\href{pose_to_motion/generate_report.py}{\\texttt{generate\\_report.py}}:\n    Contains methods to generate report files, used after a training or\n    evaluation session has been done for any selected model. These\n    generated reports contain information for reproducing runs and how a\n    model performed against metrics. A new report is generated every\n    time we run train or eval on a model and every report is saved in a\n    single CSV file where every row is a report. The files are named:\n    \\texttt{train\\_report.csv} or \\texttt{eval\\_report.csv}.\n  \\item\n    \\href{pose_to_motion/metrics.py}{\\texttt{metrics.py}}: Contains all\n    functions for calculating metrics for models for any selected model.\n  \\item\n    \\href{pose_to_motion/humanoid_config.py}{\\texttt{humanoid\\_config.py}}:\n    it contains the humanoid configuration like the number of joints and\n    the number of pose landmarks.\n  \\end{itemize}\n\\end{itemize}\n\n\\subsection{Dataset generation}\\label{dataset-generation}\n\nThe below image describes how the dataset generation system works.\n\n{Dataset generation overview}\n\nTo create a humanoid dataset ( paired pose data, motion data and\nreference images) in the \\texttt{DATASET\\_RAW/TRAIN} directory:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ dataset TRAIN/}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\subsection{Dataset preprocessing}\\label{dataset-preprocessing}\n\nThe diagram below shows the overall workflow of this project. Pose and\nmotion data are first collected from JSON files and combined into a\nsingle CSV file. These processed csv files are ready to be fed into a\nmodel of your choice, Autogluon or pytorch. See below to find more\ninformation about the dataset or more about the\n\\hyperref[models]{models}.\n\n{Overall workflow}\n\n\\begin{quote}\nThe dataset, input and outputs are in\n\\texttt{humanoid\\_utility/DATASET\\_RAW/} directory.\n\\end{quote}\n\nThe resulting files are stored as parallel \\texttt{.json} files in\nmulti-camera folders \\texttt{camera\\_*/pose\\_data},\n\\texttt{camera\\_*/motion\\_data}, \\texttt{camera\\_*/pose\\_images}. To\navoid creation of \\texttt{pose\\_images} that are only used as the ground\ntruth and debugging (specially if you are building your training data),\ncomment out then call to \\texttt{self.save\\_pose\\_image()} in\n\\texttt{camera\\_viewer.py}.\n\nFinally to merge them all in tabular \\texttt{.csv} file run the\nfollowing command.\n\n\\begin{verbatim}\n./control.sh convert2csv\n\\end{verbatim}\n\nResults in merging:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\texttt{DATASET\\_PROCESSED/train.csv} to\n  \\texttt{DATASET\\_PROCESSED/TRAIN/single\\_train\\_cam501.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/train.csv} to\n  \\texttt{DATASET\\_PROCESSED/TRAIN/single\\_train\\_cam502.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/train.csv} to\n  \\texttt{DATASET\\_PROCESSED/TRAIN/single\\_train\\_cam500.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/train.csv} to\n  \\texttt{DATASET\\_PROCESSED/TRAIN/single\\_train\\_cam503.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/train.csv} to\n  \\texttt{DATASET\\_PROCESSED/TRAIN/multi\\_train.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/eval.csv} to\n  \\texttt{DATASET\\_PROCESSED/EVAL/single\\_eval\\_cam500.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/eval.csv} to\n  \\texttt{DATASET\\_PROCESSED/EVAL/single\\_eval\\_cam501.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/eval.csv} to\n  \\texttt{DATASET\\_PROCESSED/EVAL/single\\_eval\\_cam502.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/eval.csv} to\n  \\texttt{DATASET\\_PROCESSED/EVAL/single\\_eval\\_cam503.csv}\n\\item\n  \\texttt{DATASET\\_PROCESSED/eval.csv} to\n  \\texttt{DATASET\\_PROCESSED/EVAL/multi\\_eval.csv}\n\\end{itemize}\n\nYou can replay\\_motion each motion data separately:\n\\texttt{./control.sh\\ replay\\_motion\\ DATASET\\_PROCESSED/EVAL/motion\\_data/AAAAAAA\\_motion.json}\n\n\\subsection{Model Training}\\label{model-training}\n\n\\subsubsection{Autogluon}\\label{autogluon}\n\nWe use\n\\href{https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html}{Autogluon\ntabular predictor}. This model is trained as an ensemble (collection) of\nmodels where each separate model aims to predict a single joint given\nthe complete input poses. The result from each model is then merged\ntogether and becomes a predicted list for each target joint.\n\n\\subsubsection{Pytorch}\\label{pytorch}\n\nWe have more control over the Pytorch model. It has its own\nimplementation of its dataset and model definition, located inside of\n\\href{./pose_to_motion/pytorch/utils.py}{its utils dir} folder. What is\nspecific about using the pytorch is the possibility to use optuna as a\nhyperparameter optimization tool. This tools help find the best suitable\nset of hyperparams given its training data. Autogluon has its own\ninternal optimization thus we only use this for pytorch.\n\n\\subsection{Optuna}\\label{optuna}\n\nOptuna is a hyperparameter optimization framework available as a python\nlibrary. It acts as a wrapper around an existing training framework\nwhere it uses the same setup of dataset, train\\_loop and\nhyperparameters, so it has the same context as when you would run it\nyourself. Optuna starts by defining an objective function. The goal of\nthe objective function is either to minimize or maximize a value. You\nspecify this value yourself, for this setup we have typically used the\nvalidation MSE to use as a goal to minimize. We also need to define the\nscope of values for the hyperparameters. We define for every\nhyperparameter, a range of values which Optuna is allowed to select\nfrom. i.e.~BATCHSIZE being in range(4,128). When we have done this for\nevery param we want to find the optimal value for, we start the start\noptuna by running a “study”. Optuna runs N number of training sessions,\neach independent and uses internal algorithms to find the best set of\nvalues for the list of hyperparameters. In the end we get the training\nsession that scored the best and can use its hyperparameters.\n\nNote: We only use this for pytorch since autogluon has its own\nhyperparameter optimization. This is why we only see studies inside\n\\texttt{pytorch/optuna\\_studies/}.\n\n\\subsubsection{Commands}\\label{commands}\n\n\\begin{quote}\nKeep in mind that we use a separate virtual environment to install\nmachine learning related pip packages called \\texttt{mlenv} with a\nseparate\n\\href{pose_to_motion/MLrequirements.txt}{\\texttt{requirements.txt}}.\nBuild the environment first using \\texttt{./control.sh\\ mlenv}\n\\end{quote}\n\nRunning \\texttt{control.sh\\ single\\_train} or\n\\texttt{control.sh\\ multi\\_train} in the terminal runs the training\npipeline. Single train expects data from 1 camera source whereas multi\ntrain can use unlimited amount of camera input. Both models use 1 target\nset of joints.\n\nThe interface to modify the runtime arguments, you modify variables\ninside of \\texttt{config.sh}. The runtime variables you can change are\nthese: - \\textbf{model\\_type}. Possible selections: pytorch, autogluon -\n\\textbf{pose\\_to\\_motion\\_model\\_name}. If you want to reuse a model,\nspecify its name here. Keep blank if you dont want to save. -\n\\textbf{pose\\_to\\_motion\\_session\\_name}. Optional if you want to\ndescribe your session.\n\nAfter a training run is complete, the model is saved inside of\n\\texttt{pose\\_to\\_motion/\\{\\$model\\_type\\}/output/saved\\_model\\_states}.\nA summary report of the session is also generated and will be saved\ninside\n\\texttt{pose\\_to\\_motion/\\{\\$model\\_type\\}/output/train\\_report.csv}\n\nThere are two options for using the data and training a model. The\nresulting model is saved in\n\\texttt{\\{\\$model\\_type\\}/output/saved\\_model\\_states}. Training a model\nusing 1 camera source, reads data from\n\\texttt{DATASET\\_PROCESSED/TRAIN/single\\_train\\_cam5XX.csv} and trains\nour model.\n\n\\begin{verbatim}\n./control.sh single_train\n\\end{verbatim}\n\nTraining a model using multiple camera sources, reads data from\n\\texttt{DATASET\\_PROCESSED/TRAIN/multi\\_train.csv} and trains our model:\n\n\\begin{verbatim}\n./control.sh multi_train\n\\end{verbatim}\n\n\\subsection{Model Evaluation}\\label{model-evaluation}\n\nRunning \\texttt{control.sh\\ eval} in the terminal runs the evaluation\npipeline. This will trigger the selected \\texttt{model\\_type}’s\nevaluation pipeline. The same run time variables found in\n\\texttt{config.sh}, used for training is used for evaluation where the\nkey variables \\textbf{model\\_type} and\n\\textbf{pose\\_to\\_motion\\_model\\_name}.\n\nThe evaluation will run metrics defined inside of\n\\href{./pose_to_motion/metrics.py}{metrics.py}, currently MSE and MAE\nwill be calculated. The results is then saved in a summary report\nlocalted in\n\\texttt{pose\\_to\\_motion/\\{\\$model\\_type\\}/outputs/eval\\_report.csv}.\n\nTo evaluate a trained model, there is a command that evaluates based on\na set of metric:\n\n\\begin{verbatim}\n./control.sh eval\n\\end{verbatim}\n\n\\subsection{Model Prediction}\\label{model-prediction}\n\nRunning \\texttt{control.sh\\ predict} will run input all poses for each\ncamera, in JSON format and for each pose\\_data, output a predicted\nmotion, which is replayable in RViz along with a ground truth\npose\\_image.\n\nThe following command uses MediaPipe to create pose data from an image\nor a video in \\texttt{input/} to populate \\texttt{output/} with\nmediapipe landmark pose and images.\n\n\\begin{verbatim}\n./control.sh image_pipeline\n./control.sh video_pipeline\n\\end{verbatim}\n\nTo use the model on each generated pose, run the following command to\ngenerate predicted motions which will be saved inside\n\\texttt{predict\\_data/}, inside of the input folder.\n\n\\begin{verbatim}\n./control.sh single_prediction output\n\\end{verbatim}\n\nTo use the model on each pose inside of any \\texttt{DATASET\\_RAW}\ndirectory for example:\n\\texttt{DATASET\\_RAW/EVAL/camera\\_500/pose\\_data}, run the following\ncommand below for single camera using the /EVAL dataset and camera 500\nas input:\n\n\\begin{verbatim}\n./control.sh single_prediction DATASET_RAW/EVAL\n\\end{verbatim}\n\nThis will save the predicted motions to\n\\texttt{DATASET\\_RAW/EVAL/predict\\_data}. Afterwards it opens up a image\nviewer with the ground truth mediapipe detection as well to quickly\ncheck the performance of our ml model:\n\nTo use it for multi camera use the command below to predict motions.\nThis works the same as \\texttt{single\\_prediction} but instead use\nmulti-camera datasets.\n\n\\begin{verbatim}\n./control.sh multi_prediction DATASET_RAW/EVAL\n\\end{verbatim}\n\n\\subsection{Misc. (IGNORE WHAT COMES\nNEXT)}\\label{misc.-ignore-what-comes-next}\n\n\\subsubsection{Notes}\\label{notes-1}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  It is a “feature” (not a bug) that some cameras cannot detect the pose\n  (NaN values). It helps to be still able to detect pose when a part of\n  body is masked.\n\\item\n  Mediapipe cannot reliable detect the depth, back and front\n\\item\n  Experiment different options for NaN values (average of other rows,\n  zero, etc)\n\\end{itemize}\n\n\\section{Preprocessing}\\label{preprocessing}\n\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={pose\\_landmarks\\_index.png}]{/tmp/media-e0c46393b624552d/resources/pose_landmarks_index.png}}\n\nhttps://ai.google.dev/edge/mediapipe/solutions/vision/pose\\_landmarker\n\nThree steps of normalization (feature engineer) of mediapipe landmarks:\n- Position normalization - Scale normalization - Rotation normalization\n\n{normalization.png}\n\n\\subsection{Issues and Future Works}\\label{issues-and-future-works}\n\n\\subsubsection{Current Performance\nMetrics}\\label{current-performance-metrics}\n\nThe upgraded multi-camera system demonstrates the following evaluation\nresults: - \\textbf{Mean Squared Error (MSE)}: 0.206 - \\textbf{Root Mean\nSquared Error (RMSE)}: 0.454\n\n\\subsubsection{Known Limitations}\\label{known-limitations}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  MediaPipe exhibits difficulty distinguishing between front and back\n  orientations, leading to potential left/right body side confusion in\n  pose detection\n\\item\n  Current preprocessing includes normalization for single-camera data\n  (using hip midpoint as origin), but multi-camera normalization\n  requires further development\n\\item\n  Depth estimation reliability remains limited in MediaPipe’s 2D-to-3D\n  pose conversion\n\\end{itemize}\n\n\\subsubsection{Future Development Areas}\\label{future-development-areas}\n\n\\begin{itemize}\n\\tightlist\n\\item\n  Enhance multi-camera data preprocessing with normalization, also\n  probably replace the \\texttt{pose\\_landmarks} into\n  \\texttt{pose\\_world\\_landmarks} in \\texttt{camera\\_viewer.py}\n\\item\n  Replace pre-processing with pose-processing, and pay attention to\n  whether Mediapipe’s \\texttt{static\\ mode} is enabled.\n\\item\n  Consider applying feature engineering to enable the model to gain a\n  deeper and more accurate understanding of the data.\n\\end{itemize}\n\n\\subsection{The Theory}\\label{the-theory}\n\n\\begin{itemize}\n\\tightlist\n\\item\n\\item\n  \\texttt{I} : an image. (\\texttt{I\\_s}: from simulator, \\texttt{I\\_r}\n  from real world)\n\\item\n  \\texttt{P} : a pose (mediapipe output)\n\\item\n  \\texttt{M} : a motion (moveit2)\n\\end{itemize}\n\nthen - \\texttt{SIM(M)\\ -\\textgreater{}\\ I} : Simulator(gazebo) using\ninverse kinematics(moveit2) to convert the motion \\texttt{M} to create\nimage \\texttt{I} - \\texttt{PE(I)\\ -\\textgreater{}\\ P} : Pose\nestimator(mediapipe) takes the image \\texttt{I}, to find human pose\n\\texttt{P} - \\texttt{Q(P)\\ -\\textgreater{}\\ M} : machine learning model\n\\texttt{Q}, takes pose \\texttt{P} and tries to replicate that pose\nestimator(mediapipe) pose using motion (moveit) \\texttt{M}\n\nAssumption: Pose estimator(mediapipe) performs good enough that it can\ndetect human poses from both simulator and real-world domains: -\n\\texttt{PE(I\\_r)\\ -\\textgreater{}\\ P\\_r} -\n\\texttt{PE(I\\_s)\\ -\\textgreater{}\\ P\\_s}\n\nOur goal is to - pass random M to build the dataset of pairs :\n\\texttt{\\textless{}M,PE(SIM(M))\\textgreater{}\\ =\\ \\textless{}M,P\\textgreater{}}\n- Use the dataset above to find \\texttt{Q()} which is the inverse of\nthis \\texttt{PE(SIM())}\n\nNo we can do motion capture (replicate real human movements) by\n\\texttt{Q(PE(I\\_r))}\n\n\\section{Autogluon Model\nconfiguration}\\label{autogluon-model-configuration}\n\nThis section describes how AutoGluon is configured for a multi-label\nregression problem in our current setup.\n\nTo use AutoGluon for multi-label regression problem, first we need to\ncreate a MultilabelPredictor by setting - \\textbf{labels}: the labels\nthat we want to predict. - \\textbf{problem\\_types}: the problem type for\neach TabularPredictor. - \\textbf{path}: path to directory where models\nand intermediate outputs should be saved. -\n\\textbf{consider\\_labels\\_correlation}: Whether the predictions of\nmultiple labels should account for label correlations or predict each\nlabel independently of the others.\n\nFor \\textbf{consider\\_labels\\_correlation}, we set it to FALSE in order\nto disable using one label as feature for another. The reasons for this\nis: - Each joint has its own degree of freedom and control and it is\nindependent from the rest of joints - Training stability without error\npropagation - When set to False, the training will be faster - more\ngeneral and simple model\n\nFor training the model, we should take into consideration the following\nhyperparameters related to : - Stacking: which is an ensemble technique\nwhere multiple models are trained and then a “meta-model” learns how to\ncombine their predictions. If we use dynamic Stacking, it will\nautomatically determines the optimal number of stacking layers and which\nmodels to include. - Bagging: multiple training versions of the same\nmodel on different subsets of data and combining their predictions. -\npreset: which condense the complex hyperparameter setups. For example,\nWe can use a small model size by using medium\\_quality which will lead\nto a faster training but with less prediction quality. Or we can use\nlarge model by setting preset to best\\_quality which will lead to a\nbetter performance but much longer training time.\n\nThe current autogluon uses the following hyperparameters: -\n\\textbf{dynamic\\_stacking=False}: Disables the automatic stacking\noptimization. - \\textbf{num\\_stack\\_levels=0}: no stacking level. -\n\\textbf{auto\\_stack=False}: Disables automatic ensemble stacking. -\n\\textbf{num\\_bag\\_folds = 0} and num\\_bag\\_sets = 1 which meaning no\nbagging.\n\nSo here is the current training flow for each joint : - Train NN\\_TORCH,\nGBM and XGB models - No bagging: Each model trains on full dataset once,\nno multiple training versions of the same model on different subsets of\ndata and combining their predictions. - No stacking: No meta-models\ncombining predictions - Best model selection: Choose best performing\nmodel per joint\n\n\\textbf{Eliminating Dynamic stacking and multi-level stacking will lead\nto 50\\% to 70\\% time saving.}\n\nOverall, this configuration prioritizes training speed and stability\nover ensemble complexity, making it suitable for fast iteration and\nindependent joint predictions.\n\n\\section{Hyperparameter Tuning}\\label{hyperparameter-tuning}\n\nIn The current AutoGluon model, we are training NN\\_TORCH, GBM and XGB\nmodels by using their default built-in hyperparameter settings. The next\nstep for performance improvement is to add the\n\\textbf{hyperparameter\\_tune\\_kwargs argument} to enable AutoGluon’s\ninternal hyperparameter optimization. This will allow AutoGluon to\nautomatically search for the best hyperparameters for each model type,\nbalancing training time and prediction quality.\n\n\\subsection{gazebo\\_ros2\\_control}\\label{gazebo_ros2_control}\n\n\\begin{verbatim}\n[gzserver-1] [ERROR] [1727951819.671190014] [jackal.gazebo_ros2_control]: controller manager doesn't have an update_rate parameter\n\\end{verbatim}\n\nNo solution\n\n\\subsection{OpenAL}\\label{openal}\n\n\\begin{verbatim}\n[gzserver-1] [Err] [OpenAL.cc:84] Unable to open audio device[default]\n\\end{verbatim}\n\nRelated to support for audio inside docker container. It will not be\nresolved\n\n\\subsection{Command failed: docker\ncompose}\\label{command-failed-docker-compose}\n\nIf you have any issue with docker incompatibility\n(e.g.~\\texttt{Error:\\ Command\\ failed:\\ docker\\ compose\\ ...}), make\nsure that \\texttt{docker\\ compose} or \\texttt{docker-compose} is set\ncorrectly in the setting.\n\\pandocbounded{\\includegraphics[keepaspectratio,alt={dev container in vscode}]{/tmp/media-e0c46393b624552d/resources/dev-container-config.png}}\n\nIn \\texttt{docker-compose.yaml}, uncomment the\n\\texttt{factory\\_simulation\\_nvidia} section:\n\n\\begin{verbatim}\n  factory_simulation_nvidia:\n    <<: *research-base\n    container_name: factory_simulation_nvidia\n    runtime: nvidia\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: \"all\"\n              capabilities: [compute,utility,graphics,display]\n\\end{verbatim}\n\nand update \\texttt{.devcontainer/devcontainer.json}:\n\n\\begin{verbatim}\n{\n    \"name\": \"ROS2 RESEARCH CONTAINER\",\n    \"dockerComposeFile\": \"../docker-compose.yaml\",\n    \"service\": \"factory_simulation_nvidia\n...\n\\end{verbatim}\n\n\\subsection{Missing nvidia docker\nruntime}\\label{missing-nvidia-docker-runtime}\n\nSolution:\nhttps://stackoverflow.com/questions/59008295/add-nvidia-runtime-to-docker-runtimes\n\n\\subsection{Docker nvidia-container-cli: requirement\nerror}\\label{docker-nvidia-container-cli-requirement-error}\n\nIf you get this error when building the docker container:\n\n\\begin{verbatim}\nnvidia-container-cli: requirement error: unsatisfied condition: cuda>=12.6, please update your driver to a newer version, or use an earlier cuda container: unknown\n\\end{verbatim}\n\nA solution to try is first: re-install nvidia-container-toolkit. Or if\nthat does not work, update your nvidia-drivers.\n\n\\subsection{GLIBC\\_2 issue}\\label{glibc_2-issue}\n\nSometimes the wrong \\texttt{nvidia-container-toolkit} results this issue\nbelow:\n\n\\begin{verbatim}\n$/usr/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.38' not found (required by /usr/lib/x86_64-linux-gnu/libGLdispatch.so.0)\n$/usr/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.38' not found (required by /usr/lib/x86_64-linux-gnu/libGLX.so.0)\n\\end{verbatim}\n\nIf so, try downgrading \\texttt{nvidia-container-\\ toolkit}. You can use\nthese commands:\n\n\\begin{verbatim}\n$sudo apt-get remove --purge nvidia-container-toolkit nvidia-container-toolkit-base libnvidia-container*\n$sudo apt-get update\n$sudo apt-get install nvidia-container-toolkit=1.17.4-1 nvidia-container-toolkit-base=1.17.4-1 libnvidia-container1=1.17.4-1 libnvidia-container-tools=1.17.4-1\n\\end{verbatim}\n\n\\subsection{docker issues}\\label{docker-issues}\n\nMake sure docker is installed correctly by following these two\ninstructions:\n\n\\begin{itemize}\n\\tightlist\n\\item\n  \\href{https://docs.docker.com/engine/install/ubuntu/\\#install-using-the-convenience-script}{Install\n  docker using the convenience script}\n\\item\n  \\href{https://docs.docker.com/engine/install/linux-postinstall/}{Linux\n  post-installation steps for Docker Engine}\n\\end{itemize}\n\n\\subsection{Advanced options:}\\label{advanced-options-1}\n\nTo record camera images for available cameras we use a simple python\ncode \\url{./camera_utility/camera_subscriber.py} that continuously\nrecord camera images in \\texttt{camera\\_utility/camera\\_data/} :\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ cam\\_dump}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\subsection{Advanced features}\\label{advanced-features}\n\n\\subsubsection{Running ROS2 commands:}\\label{running-ros2-commands}\n\nTo avoid conflict between ros nodes in the same network, after each\nbuild a new random ROS2 domain is created. This means that you need to\nadjust this random domain before running any ros2 commands. For\nconvenience you can use\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ cmd YOUR\\_ROS2\\_COMMANDS}\n\\end{Highlighting}\n\\end{Shaded}\n\nHere is an example of extracting tf2 hierarchy\n\n\\begin{verbatim}\n./control.sh cmd ros2 run tf2_tools view_frames\n\\end{verbatim}\n\nThese features and commands are under development and not fully\nsupported yet and therefore are subject to change.\n\n\\textbf{Cartographer}: With both Gazebo and rviz running you can start\ncreating a map of a robots surroundings\n\nTo start: \\texttt{./control.sh\\ cartographer}\n\nThe jackal can then be controlled with the computer keyboard by running:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ teleop\\_jackal}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo record one screenshot after use:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ screenshot 164}\n\\end{Highlighting}\n\\end{Shaded}\n\nThe result will be stored in \\texttt{./camera\\_utility/camera\\_data/}.\n\nTo record ros messages in ROS bag files to replay the scenario later:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ ros\\_record}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo replay the last rosbag recording:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ ros\\_replay}\n\\end{Highlighting}\n\\end{Shaded}\n\nTo test the unit tests before pushing new codes:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ test}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\subsection{Jackal}\\label{jackal}\n\nIf you want to control the Jackal you add the following lines into the\ncontrol.sh:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ControlFlowTok{elif} \\KeywordTok{[[} \\StringTok{\"}\\VariableTok{$*}\\StringTok{\"} \\OtherTok{==} \\PreprocessorTok{*}\\StringTok{\"jackal\\_teleop\"}\\PreprocessorTok{*} \\KeywordTok{]]}\n\\ControlFlowTok{then}\n    \\ExtensionTok{ros2}\\NormalTok{ launch dyno\\_jackal\\_bringup keyboard\\_steering.launch.py}\n\\end{Highlighting}\n\\end{Shaded}\n\nAnd then run:\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ExtensionTok{./control.sh}\\NormalTok{ jackal\\_teleop}\n\\end{Highlighting}\n\\end{Shaded}\n\nThese ones did not work so we put it here in issues\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ControlFlowTok{elif} \\KeywordTok{[[} \\StringTok{\"}\\VariableTok{$*}\\StringTok{\"} \\OtherTok{==} \\PreprocessorTok{*}\\StringTok{\"move\\_object\"}\\PreprocessorTok{*} \\KeywordTok{]]}\n\\ControlFlowTok{then}\n    \\ExtensionTok{ros2}\\NormalTok{ run object\\_mover move\\_object}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\begin{Shaded}\n\\begin{Highlighting}[]\n\\ControlFlowTok{elif} \\KeywordTok{[[} \\StringTok{\"}\\VariableTok{$*}\\StringTok{\"} \\OtherTok{==} \\PreprocessorTok{*}\\StringTok{\"scenario\"}\\PreprocessorTok{*} \\KeywordTok{]]}\n\\ControlFlowTok{then}\n    \\ExtensionTok{ros2}\\NormalTok{ launch scenario\\_execution\\_ros scenario\\_launch.py scenario:=simulation/scenario\\_manager/scenarios/test.osc}\n\\end{Highlighting}\n\\end{Shaded}\n\n\\subsubsection{high-level\\_diagram\\_SIMLAN.drawio}\\label{high-level_diagram_simlan.drawio}\n\n{“high-level\\_diagram\\_SIMLAN.drawio.png”} \\#\\#\\#\nHumanoid\\_mocap\\_flow.drawio {“Humanoid\\_mocap\\_flow.drawio.png”} \\#\\#\\#\nlegend.drawio {“legend.drawio.png”} \\#\\#\\# ros2 launch\naruco\\_localization multi\\_detection.launch.py.drawio {“ros2 launch\naruco\\_localization multi\\_detection.launch.py.drawio.png”} \\#\\#\\# ros2\nlaunch camera\\_bird\\_eye\\_view bird\\_eye\\_view.launch.py.drawio {“ros2\nlaunch camera\\_bird\\_eye\\_view bird\\_eye\\_view.launch.py.drawio.png”}\n\\#\\#\\# ros2 launch moveit\\_resources\\_panda\\_moveit\\_config\ndemo.launch.py.drawio {“ros2 launch\nmoveit\\_resources\\_panda\\_moveit\\_config demo.launch.py.drawio.png”}\n\\#\\#\\# ros2 launch pallet\\_truck\\_bringup\nmultiple\\_robot\\_spawn.launch.py.drawio {“ros2 launch\npallet\\_truck\\_bringup multiple\\_robot\\_spawn.launch.py.drawio.png”}\n\\#\\#\\# ros2 launch pallet\\_truck\\_navigation\nmap\\_server.launch.py.drawio {“ros2 launch pallet\\_truck\\_navigation\nmap\\_server.launch.py.drawio.png”} \\#\\#\\# ros2 launch\npallet\\_truck\\_navigation nav2.launch.py.drawio {“ros2 launch\npallet\\_truck\\_navigation nav2.launch.py.drawio.png”} \\#\\#\\# ros2 launch\nsimlan\\_bringup sim.launch.py.drawio {“ros2 launch simlan\\_bringup\nsim.launch.py.drawio.png”} \\#\\#\\# ros2 launch static\\_agent\\_launcher\nstatic-agent.launch.py.drawio {“ros2 launch static\\_agent\\_launcher\nstatic-agent.launch.py.drawio.png”} \\#\\#\\# ros2 launch\nvisualize\\_real\\_data scenario\\_replayer.launch.py.drawio {“ros2 launch\nvisualize\\_real\\_data scenario\\_replayer.launch.py.drawio.png”} \\#\\#\\#\nSIMLAN\\_DIAGRAM.drawio {“SIMLAN\\_DIAGRAM.drawio.png”}\n\n\\subsection{Licenses and Credits}\\label{licenses-and-credits}\n\nThe majority of code for the pallet truck comes from these\n\\href{https://github.com/ROBOTIS-GIT/turtlebot3.git}{turtlebot3} and\n\\href{https://github.com/ROBOTIS-GIT/turtlebot3_simulations}{turtlebot3\\_simulations}\nrepositories (in \\texttt{humble-devel} branch) with\n\\href{LICENSE}{\\emph{Apache-2.0 license}} and we continue using the same\nlicense: The Turtlebot3 robot project belongs to\n\\href{http://turtlebot3.robotis.com}{robotis.com} and accessible in\n\\href{https://github.com/ROBOTIS-GIT/}{git repository}. The authors and\nmaintainers of the original packages that all credits go to are: -\n\\href{thlim@robotis.com}{Darby Lim} - \\href{pyo@robotis.com}{Pyo} -\n\\href{willson@robotis.com}{Will Son} - Ryan Shim In October 2023,\n\\href{hamid.ebadi@gmail.com}{Hamid Ebadi} renamed the\n\\href{package.xml}{package owner information and name} for turtlebot3\nprojects to avoid dependency issues any naming confusion with the\noriginal packages and created independent packages for activities within\nthe research project. We also got inspired and used the skeleton code\nfrom these open source project and courses: -\nhttps://github.com/ros-controls/gazebo\\_ros2\\_control -\nhttps://github.com/renan028/forklift\\_robot -\nhttps://github.com/ROBOTIS-GIT/ - http://turtlebot3.robotis.com -\n\\href{https://www.youtube.com/@ArticulatedRobotics}{Articulated\nRobotics} -\n\\href{https://www.udemy.com/course/ros2-tf-urdf-rviz-gazebo/}{“ROS2 for\nBeginners Level 2 - TF \\textbar{} URDF \\textbar{} RViz \\textbar{}\nGazebo” Udemy course} -\n\\href{https://www.udemy.com/course/ros2-tf-urdf-rviz-gazebo/}{“ROS2 Nav2\n{[}Navigation 2 Stack{]} - with SLAM and Navigation” Udemy course} -\n\\href{https://github.com/nlamprian/grobot}{Visual Servoing in Gazebo\ngrobot} - The modification of\n\\href{https://github.com/robotology/human-gazebo}{Human-Gazebo} in\n\\url{/src/humanoid_robot/model/human-gazebo} is licensed under LGPL-2.1.\n- \\href{https://github.com/moveit/moveit2}{Moveit2} is licensed under\nBSD-3-Clause license. \\#\\# Resources -\n\\href{https://www.youtube.com/watch?v=48TX-XJ14Gs&list=PL6FI-gIL5jiEd4Hv-NIAuO2Cbbs27UpAM&index=1}{Gazebo\nofficial video playlist} -\n\\href{https://www.youtube.com/watch?v=2lIV3dRvHmQ&list=PLunhqkrRNRhYYCaSTVP-qJnyUPkTxJnBt}{Getting\nReady to Build Robots with ROS} -\n\\href{https://www.udemy.com/course/ros2-tf-urdf-rviz-gazebo}{Udemy\ncourse on ROS2 and Gazebo} -\n\\href{https://www.classcentral.com/course/youtube-simulating-robots-with-gazebo-and-ros-getting-ready-to-build-robots-with-ros-8-153333}{classcentral\ncourse} -\n\\href{https://www.theconstructsim.com/robotigniteacademy_learnros/ros-courses-library/mastering-gazebo-simulator-online-course/}{theconstructsim\ncourse} - \\href{https://articulatedrobotics.xyz/}{Articulated Robotics}\n- \\href{http://wiki.ros.org/urdf/XML}{ROS URDF} -\n\\href{https://studio.foxglove.dev}{FoxGlove studio (rviz alternative)} -\n\\href{https://docs.ros.org/en/humble/Tutorials.html}{ROS2 Tutorials} -\n\\href{https://github.com/aws-robotics/aws-robomaker-small-warehouse-world}{aws-robomaker}\n-\n\\href{https://app.gazebosim.org/OpenRobotics/fuel/models/Mecanum\\%20lift}{model\nfor factory} -\n\\href{https://app.gazebosim.org/Kavya/fuel/worlds/Tugbot\\%20in\\%20Warehouse}{Tugbot\nin Warehouse} -\n\\href{https://github.com/belal-ibrahim/dynamic_logistics_warehouse}{logistics\nin warehouse} -\n\\href{https://aws.amazon.com/blogs/robotics/fleet-and-multi-robot-simulations-in-aws-robomaker}{aws-robomaker}\n-\n\\href{https://dev.px4.io/v1.11_noredirect/en/simulation/gazebo_worlds.html\\#warehouse}{gazebo\\_worlds}\n- \\href{https://app.gazebosim.org/MovAi}{warehouse} -\n\\href{https://github.com/renan028/forklift_robot}{forklift} -\n\\href{https://docs.docker.com/engine/install/}{Docker install guide} -\n\\href{https://app.gazebosim.org/MovAi/fuel/worlds/tugbot_warehouse}{Hazard\nstripes taken from Tugbot warehouse} -\n\\href{https://www.cs.fsu.edu/~liux/courses/cop5611/notes/deadlock.html}{Deadlock\nimage}\n\nOther solutions: -\n\\href{https://www.youtube.com/watch?v=JIYOndxW9hc}{Kollmorgen: How does\nan AGV navigate?} -\n\\href{https://www.swisslog.com/en-us/products-systems-solutions/asrs-automated-storage-retrieval-systems/boxes-cartons-small-parts-items/carrypick-storage-and-picking-system}{SwissLog\nCarryPick} -\n\\href{https://toyota-forklifts.se/automatiserade-losningar/}{Toyota\nforklifts} - \\href{https://iliad-project.eu/}{ILIAD Project} -\n\\href{https://www.mobile-robots.de/87/fahrerlose-transportsysteme/amr-fuer-palettentransport?&wslanguage=en}{GoPal}\n- \\href{https://github.com/aeksiri/forklift}{navigation\\_oru navigation\nstack by Örebro University}\n\nSpecification of items: -\n\\href{https://saintechrobotics.com/product/slam-navigation-compact-pallet-mover-nature-navigation-mini-forklift-with-payload-1000kg/}{SLAM\nNavigation Compact Pallet Mover Nature Navigation Mini Forklift with\nPayload 1000KG} -\n\\href{https://www.agilox.net/en/product/agilox-one/}{Driverless Lifting\nSystem: Single \\& Double Scissor Lift \\textbar{} AGILOX} -\n\\href{https://cnviboo.en.made-in-china.com/product/jZNfqtkUAypA/China-Wholesale-Pallet-Agv-Trucks-Jack-Automated-Autonomous-Forklift.html}{Wholesale\nPallet Agv Trucks Jack Automated Autonomous Forklift} -\n\\href{https://www.volvogroup.com/content/dam/volvo-group/markets/master/suppliers/useful-links-and-documents-for-existing-suppliers/logistics-solutions/volvo-group-packaging-system/Wooden-Packaging_Pallets-Frames-and-Lids.pdf}{Volvo\nmodular containers} -\n\\href{https://www.volvogroup.com/content/dam/volvo-group/markets/master/suppliers/useful-links-and-documents-for-existing-suppliers/logistics-solutions/volvo-group-packaging-system/Volvo-group-packaging-specifications_2015.pdf}{Volvo\nEmballage Specifications Volvo Group Packaging System} -\n\\href{https://www.freecad.org/}{Freecad} -\n\\href{https://www.blender.org/}{Blender} -\n\\href{https://github.com/gazebosim/gz-sim/tree/main/examples/worlds}{example\nworlds} - \\href{http://sdformat.org/tutorials}{SDF format} -\n\\href{https://github.com/gazebosim/sdf_tutorials}{SDF tutorial} -\n\\href{https://github.com/maidenone/RobotCreator}{FreeCAD RobotCreator\nWorkbench}\n\nCoordinates: -\n\\href{https://automaticaddison.com/understanding-coordinate-transformations-for-navigation/}{odom}\n\nCamera projection: -\nhttps://github.com/polygon-software/python-visual-odometry/blob/master/Chapter\\%203\\%20-\\%20Camera\\%20Projection.ipynb\n- https://classic.gazebosim.org/tutorials?tut=camera\\_distortion -\nhttps://learnopencv.com/rotation-matrix-to-euler-angles/ -\nhttps://www.geeksforgeeks.org/calibratecamera-opencv-in-python/ -\nhttps://docs.opencv.org/4.x/dc/dbb/tutorial\\_py\\_calibration.html -\nhttp://sdformat.org/tutorials?tut=specify\\_pose\n\nJackal Robot: The Clearpath Jackal Robot code is forked by Dyno Robotics\nfrom Clearpaths \\href{https://github.com/jackal/jackal}{jackal} Github.\nBranch foxy-devel is ported to dyno\\_humble, where changes for\nnamespacing and a bringup package is added. - To improve collaboration\nin development environment we use vscode and docker as explained in\n\\href{https://www.allisonthackston.com/articles/docker-development.html}{this\ninstruction} using these\n\\href{https://github.com/athackst/dockerfiles}{docker files}. For\nproduction environment follow installation procedure used in\n\\url{.devcontainer/Dockerfile} to install dependencies. - The Docker\nsetup is added by Christoffer Johanesson (Dyno Robotics), based on Dyno\nexperience working with Docker. \\#\\# Licenses Imu\\_tools is the one with\nseveral licenses, using BSD-3, GPLv3, GNU v3, but as we don’t change the\ncode so we believe there is no license conflict with the current project\nlicense. The dependency wireless\n(https://github.com/clearpathrobotics/wireless.git) from Clearpath\nrobotics is the without a separate license file. There are license names\nwithin files, referencing BSD so we believe there is no license conflict\nwith the current project license. \\#\\# Docker and VS Code setup The\nDocker setup added by \\href{christoffer@dynorobotics.se}{Christoffer\nJohanesson (Dyno Robotics)}, based on Dyno experience working with\nDocker. \\#\\# Project maintainer This project is currently maintained by\n\\href{hamid.ebadi@gmail.com}{Hamid Ebadi}.\n\n\\end{document}\n",
        "description": "Source:"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "",
        "description": "LaTeX run number 1"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "This is XeTeX, Version 3.141592653-2.6-0.999997 (TeX Live 2025) (preloaded format=xelatex)\n restricted \\write18 enabled.\nentering extended mode\n(/tmp/media-e0c46393b624552d/input.tex\nLaTeX2e <2025-11-01>\nL3 programming layer <2025-10-24>\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2025/01/22 v1.4n Standard LaTeX document class\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/size10.clo))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/xcolor.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-def/xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/dvipsnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/svgnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/x11nam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/geometry/geometry.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/keyval.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/ifvtex.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/iftex.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsmath.sty\nFor additional information on amsmath, use the `?' option.\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amstext.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsgen.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsopn.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amssymb.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3kernel/expl3.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3backend/l3backend-xetex.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/xparse/xparse.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/l3keys2e/l3keys2e.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fontenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fix-cm.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/ts1enc.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-table.tex))\n) (/opt/texlive/texdir/texmf-dist/tex/latex/lm/lmodern.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/upquote/upquote.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/textcomp.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype-xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.cfg))\n(/opt/texlive/texdir/texmf-dist/tex/latex/parskip/parskip.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvoptions/kvoptions.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/framed/framed.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/longtable.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/booktabs/booktabs.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/array.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/calc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/footnotehyper/footnotehyper.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphicx.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphics.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/trig.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bookmark.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hyperref.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdfescape/pdfescape.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/infwarerr/infwarerr.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hycolor/hycolor.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/nameref.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/refcount/refcount.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty))\n (/opt/texlive/texdir/texmf-dist/tex/generic/stringenc/stringenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/pd1enc.def)\n(/opt/texlive/texdir/texmf-dist/tex/generic/intcalc/intcalc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/puenc.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/url/url.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/bitset/bitset.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hxetex.def\n(/opt/texlive/texdir/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bkm-dvipdfm.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xurl/xurl.sty)\nNo file input.aux.\n*geometry* driver: auto-detecting\n*geometry* detected driver: xetex\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-LatinModernRoman.cfg)\n\nPackage hyperref Warning: Rerun to get /PageLabels entry.\n\nNo file input.toc.\n(/opt/texlive/texdir/texmf-dist/tex/latex/lm/omllmm.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsa.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msa.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsb.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msb.cfg) [1]\n\nLaTeX Font Warning: Font shape `TU/lmtt/bx/it' in size <10> not available\n(Font)              Font shape `TU/lmtt/b/sl' tried instead on input line 285.\n\n[2] [3]\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 1 on input line 454.\n\n[4] [5] [6]\nOverfull \\hbox (219.22499pt too wide) in paragraph at lines 876--876\n[]\\TU/lmtt/m/n/10 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgke\ny | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.\ngpg \\[] \n\nOverfull \\hbox (9.22499pt too wide) in paragraph at lines 876--876\n[]  \\TU/lmtt/m/n/10 && curl -s -L https://nvidia.github.io/libnvidia-container/\nstable/deb/nvidia-container-toolkit.list | \\[] \n\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 876--876\n[]    \\TU/lmtt/m/n/10 sed []s#deb https://#deb [signed-by=/usr/share/keyrings/n\nvidia-container-toolkit-keyring.gpg] https://#g[] | \\[] \n[7]\nOverfull \\hbox (67.62201pt too wide) in paragraph at lines 899--901\n[]\\TU/lmr/m/n/10 To get the docker container up and running, download and insta\nll Docker Desktop for your system: https://www.docker.com/products/docker-\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☐ (U+2610) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\n[8] [9]\nOverfull \\hbox (122.597pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 It is possible to adjust the level fidelity for a world in \\TU/l\nmtt/m/n/10 config.sh\\TU/lmr/m/n/10 , there the \\TU/lmtt/m/n/10 world_setup \\TU/\nlmr/m/n/10 is sent to - \\TU/lmtt/m/n/10 simulation/simlan_bringup/launch/sim.la\nunch.py\\TU/lmr/m/n/10 .\n\nOverfull \\hbox (269.67499pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 - \\TU/lmtt/m/n/10 simulation/simlan_gazebo_environment/launch/si\nmlan_factory.launch.py \\TU/lmr/m/n/10 (for world generation) - \\TU/lmtt/m/n/10 \nsimulation/simlan_gazebo_environment/launch/generate_world_file.py\n\nOverfull \\hbox (225.56703pt too wide) in paragraph at lines 1146--1154\n\\TU/lmr/m/n/10 Aruco codes and cameras are all attached to the same link in Gaz\nebo. To create new static agents, go to \\TU/lmtt/m/n/10 simulation/static_agent\n_launcher/description/agents.urdf.xacro\\TU/lmr/m/n/10 .\n[10] [11] [12] [13]\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n\nOverfull \\hbox (329.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 /usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWar\nning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciP\ny (detected version 1.26.2[] \n[14]\nOverfull \\hbox (182.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 ValueError: bpy_struct \"PHOBOS_OT_define_submodel\" registrati\non error: []submodeltype[] EnumProperty could not register (see previous error)\n[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 IOR of negative value is not allowed for materials (using Ble\nnder default value instead)+-- Import Scene --------[] \n\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1048, in toggleVisual[] \n\nOverfull \\hbox (61.72499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1051, in toggleCollision[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 [20231211_08:52:53] WARNING No text file README.md found. (ph\nobos/blender/utils/blender.py - readTextFile (l259))[] \n[15]\nignored error: Infinite glue shrinkage found in box being split [16]\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 5 on input line 1850.\n\n[17]\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 7 on input line 2067.\n\n[18]\nOverfull \\hbox (177.97891pt too wide) in paragraph at lines 2164--2166\n\\TU/lmr/m/n/10 One can see the URDF by running: \\TU/lmtt/m/n/10 roslaunch urdf_\ntutorial display.launch model:=[]$(find forklift_robot_description)/urdf/forkli\nft_simple.urdf[] \n[19]\nOverfull \\hbox (15.40501pt too wide) in paragraph at lines 2238--2243\n[]\\TU/lmr/m/n/10 The \\TU/lmtt/m/n/10 camera_config.xacro \\TU/lmr/m/n/10 is then\n sent to the robot_state_publisher node and published to the /static_agent/robo\nt_description\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 8 on input line 2272.\n\n[20]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2301--2303\n[][]\n[21]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2323--2324\n[]\\TU/lmtt/m/n/10 launch_rviz_launch_argument = DeclareLaunchArgument(         \n\"rviz\",         default_value=\"False\",\n[22] [23]\nOverfull \\hbox (267.79501pt too wide) in paragraph at lines 2521--2524\n[]\\TU/lmr/m/n/10 The topic name is defined by the automatically generated gz_br\nidge() which can be found in /home/ros/src/simulation/pallet_truck/pallet_truck\n_bringup/launch/generate_gz_bridge.py \n[24]\nOverfull \\hbox (24.97499pt too wide) in paragraph at lines 2590--2590\n[]\\TU/lmtt/m/n/10 Node(  # Manually setting the joint between map and odom to 0\n 0 0, i.e. identical to each other. map -> odom[] \n\nOverfull \\hbox (81.9339pt too wide) in paragraph at lines 2621--2630\n\\TU/lmtt/m/n/10 ROBOTS \\TU/lmr/m/n/10 variable in config.sh. the pallet_trucks \nand forklifts also have an individual \\TU/lmtt/m/n/10 navigate_w_replaning_and_\nrecovery_robot_agent_x.xml\n[25]\nOverfull \\hbox (175.485pt too wide) in paragraph at lines 2655--2664\n\\TU/lmr/m/n/10 manoids on the other hand get their \\TU/lmtt/m/n/10 odom \\TU/lmr\n/m/n/10 frame from the ros2_controller \\TU/lmtt/m/n/10 simulation/humanoid_supp\nort_moveit_config/launch/launch_controllers.launch.py\\TU/lmr/m/n/10 .\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 9 on input line 2704.\n\nignored error: Infinite glue shrinkage found in box being split [26]\n\nPackage longtable Warning: Column widths have changed\n(longtable)                in none 10 on input line 2721.\n\n\nOverfull \\hbox (345.22499pt too wide) in paragraph at lines 2782--2783\n[]\\TU/lmtt/m/n/10 ros2 launch urdf_tutorial display.launch.py model:=/home/ros/\nsrc/simulation/humanoid_robot/model/human-gazebo/humanSubjectWithMeshes/humanSu\nbjectWithMesh_simplified.urdf \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2837--2838\n []\\TU/lmr/m/n/10 Shoulder \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2839--2840\n []\\TU/lmr/m/n/10 Shoulder \n[27] [28]\nOverfull \\hbox (5.29701pt too wide) in paragraph at lines 2896--2905\n\\TU/lmr/m/n/10 This is the \\TU/lmtt/m/n/10 aruco_localization \\TU/lmr/m/n/10 pa\nckage, which runs a ros2 node that takes images from camera topics \\TU/lmtt/m/n\n/10 CAMERA_X/camera_info\n[29]\nOverfull \\hbox (0.38501pt too wide) in paragraph at lines 2996--3001\n\\TU/lmr/m/n/10 To implement geofencing and the safety situation in which a pall\net truck is not observable in any camera. \\TU/lmtt/m/n/10 aruco_localization\n\nOverfull \\hbox (258.045pt too wide) in paragraph at lines 3006--3017\n\\TU/lmr/m/n/10 At first we define a custom \\TU/lmtt/m/n/10 behavior_tree.xml \\T\nU/lmr/m/n/10 in \\TU/lmtt/m/n/10 src/simulation/pallet_truck/pallet_truck_naviga\ntion/config/navigate_w_replanning_and_recovery_robot_agent_X.xml\\TU/lmr/m/n/10 \n.\n\nOverfull \\hbox (330.03503pt too wide) in paragraph at lines 3051--3064\n[]\\TU/lmr/m/n/10 The first one we tried to use is the \\TU/lmtt/m/n/10 Transform\nAvailable \\TU/lmr/m/n/10 plugin (https://github.com/ros-navigation/navigation2/\nblob/main/nav2_behavior_tree/plugins/condition/transform_available_condition.cp\np).\n\nOverfull \\hbox (233.82503pt too wide) in paragraph at lines 3065--3072\n[]\\TU/lmr/m/n/10 The second plugin we tried is the \\TU/lmtt/m/n/10 IsStuckCondi\ntion \\TU/lmr/m/n/10 (https://github.com/ros-navigation/navigation2/blob/main/na\nv2_behavior_tree/plugins/condition/is_stuck_condition.cpp)\n[30]\nOverfull \\hbox (1069.72499pt too wide) in paragraph at lines 3134--3134\n[]\\TU/lmtt/m/n/10 [WARN] [humanoid.moveit.moveit.ros.planning_scene_monitor] [i\nd]: Unable to transform object from frame []unconnected_frame[] to planning fra\nme []base_link[] (Could not find a connection between []base_link[] and []uncon\nnected_frame[] because they are not part of the same tree. TF has two or more u\nnconnected trees)[] \n[31]\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n[32]\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3309--3309\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (8.37038pt too wide) in paragraph at lines 3310--3311\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (17.3987pt too wide) in paragraph at lines 3318--3318\n[]|\\TU/lmtt/m/n/10 frames_to_process|  \n\nOverfull \\hbox (27.8987pt too wide) in paragraph at lines 3320--3320\n[]|\\TU/lmtt/m/n/10 preprocess_all_data|  \n\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3323--3323\n[]|\\TU/lmtt/m/n/10 fake_orientation|  \n\nOverfull \\hbox (13.57378pt too wide) in paragraph at lines 3386--3386\n[]|\\TU/lmtt/m/n/10 gazebo_teleport_service|  \n\nOverfull \\hbox (49.50153pt too wide) in paragraph at lines 3427--3428\n[]|\\TU/lmtt/m/n/10 visualize_real_data|  \n\nOverfull \\hbox (12.75153pt too wide) in paragraph at lines 3429--3430\n[]|\\TU/lmtt/m/n/10 entity_topic|  \n\nOverfull \\hbox (21.35674pt too wide) in paragraph at lines 3434--3434\n[]|\\TU/lmtt/m/n/10 processing_time_limit|  \n[33] [34]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ⚡ (U+26A1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\n\nOverfull \\hbox (29.98172pt too wide) in paragraph at lines 3619--3624\n[]\\TU/lmr/m/n/10 This initializes three action servers: - \\TU/lmr/bx/n/10 🚀 tel\neport_action_server\\TU/lmr/m/n/10 : Handles teleportation of robots. - \\TU/lmr/\nbx/n/10 ⚡ set_speed_action_server\\TU/lmr/m/n/10 :\nMissing character: There is no 🔄 (U+1F504) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📐 (U+1F4D0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🏎 (U+1F3CE) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💠 (U+1F4A0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman12-bold]:mapping=tex-\ntext;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\n[35]\nMissing character: There is no ⏱ (U+23F1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 📍 (U+1F4CD) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\n\nOverfull \\hbox (36.725pt too wide) in paragraph at lines 3725--3728\n[]\\TU/lmr/m/n/10 To run our package make sure that gazebo simulator is running.\n Then we can run the \\TU/lmtt/m/n/10 panda_moveit_config/launch/demo.launch.py\n\nUnderfull \\hbox (badness 1231) in paragraph at lines 3745--3756\n\\TU/lmr/m/n/10 The folder[][]\\TU/lmtt/m/n/10 custom_motion_planning_python_api[\n][] \\TU/lmr/m/n/10 has scripting files that plans and executes motions for a pa\nnda\n\nOverfull \\hbox (37.46501pt too wide) in paragraph at lines 3745--3756\n\\TU/lmtt/m/n/10 motion_planning_python_api_planning_scene.py \\TU/lmr/m/n/10 is \nan original demo from moveit2 - \\TU/lmtt/m/n/10 motion_planning_python_api_tuto\nrial.py\n[36]\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\n\nUnderfull \\hbox (badness 1622) in paragraph at lines 3884--3884\n[]\\TU/lmr/bx/n/10 Deterministic, Disentanglement One-parameter Object Movements\n (one_object_deterministic\n[37]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4055--4059\n\n[38]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4092--4095\n\n\nUnderfull \\hbox (badness 10000) in paragraph at lines 4126--4129\n\n\nLaTeX Warning: Hyper reference `optuna' on page 39 undefined on input line 4138\n.\n\n\nLaTeX Warning: Hyper reference `models' on page 39 undefined on input line 4183\n.\n\n[39]\nOverfull \\hbox (113.24pt too wide) in paragraph at lines 4243--4245\n[]\\TU/lmr/m/n/10 You can replay_motion each motion data separately: \\TU/lmtt/m/\nn/10 ./control.sh replay_motion DATASET_PROCESSED/EVAL/motion_data/AAAAAAA_moti\non.json \n\nOverfull \\hbox (44.4639pt too wide) in paragraph at lines 4314--4319\n\\TU/lmr/m/n/10 A summary report of the session is also generated and will be sa\nved inside \\TU/lmtt/m/n/10 pose_to_motion/{$model_type}/output/train_report.csv\n \n\nOverfull \\hbox (64.365pt too wide) in paragraph at lines 4320--4326\n[]\\TU/lmr/m/n/10 There are two options for using the data and training a model.\n The resulting model is saved in \\TU/lmtt/m/n/10 {$model_type}/output/saved_mod\nel_states\\TU/lmr/m/n/10 .\n[40] [41] [42] [43]\nOverfull \\hbox (140.47499pt too wide) in paragraph at lines 4583--4583\n[]\\TU/lmtt/m/n/10 [gzserver-1] [ERROR] [1727951819.671190014] [jackal.gazebo_ro\ns2_control]: controller manager doesn[]t have an update_rate parameter[] \n\nOverfull \\hbox (289.36447pt too wide) in paragraph at lines 4599--4604\n\\TU/lmtt/m/n/10 docker compose \\TU/lmr/m/n/10 or \\TU/lmtt/m/n/10 docker-compose\n \\TU/lmr/m/n/10 is set correctly in the setting. [] \n[44] [45]\nOverfull \\hbox (313.72499pt too wide) in paragraph at lines 4645--4645\n[]\\TU/lmtt/m/n/10 nvidia-container-cli: requirement error: unsatisfied conditio\nn: cuda>=12.6, please update your driver to a newer version, or use an earlier \ncuda container: unknown[] \n\nOverfull \\hbox (124.72499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLdispatch.so.0)[] \n\nOverfull \\hbox (87.97499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLX.so.0)[] \n\nOverfull \\hbox (3.97499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get remove --purge nvidia-container-toolkit nvidia-\ncontainer-toolkit-base libnvidia-container*[] \n\nOverfull \\hbox (292.72499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get install nvidia-container-toolkit=1.17.4-1 nvidi\na-container-toolkit-base=1.17.4-1 libnvidia-container1=1.17.4-1 libnvidia-conta\niner-tools=1.17.4-1[] \n[46]\nUnderfull \\hbox (badness 1609) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “high-level_diagram_SIMLAN.drawio.png” ### Humanoid_mocap_flow.d\nrawio “Humanoid_mocap_flow.drawio.png”\n\nUnderfull \\hbox (badness 6461) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### legend.drawio “legend.drawio.png” ### ros2 launch aruco_loca\nlization multi_detection.launch.py.drawio\n\nUnderfull \\hbox (badness 4518) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “ros2 launch aruco_localization multi_detection.launch.py.drawio\n.png” ### ros2 launch camera_bird_eye_view\n\nOverfull \\hbox (8.435pt too wide) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 launch moveit_resources_panda_moveit_config demo.launch.py.drawi\no “ros2 launch moveit_resources_panda_moveit_config\n\nUnderfull \\hbox (badness 3229) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 demo.launch.py.drawio.png” ### ros2 launch pallet_truck_bringup \nmultiple_robot_spawn.launch.py.drawio “ros2\n\nUnderfull \\hbox (badness 5217) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### ros2 launch visualize_real_data scenario_replayer.launch.py.\ndrawio “ros2 launch visualize_real_data sce-\n[47]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4935--4942\n[]\\TU/lmr/m/n/10 Camera projection: - https://github.com/polygon-software/pytho\nn-visual-odometry/blob/master/Chapter%203%20-\n\nOverfull \\hbox (41.115pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 %20Camera%20Projection.ipynb - https://classic.gazebosim.org/tut\norials?tut=camera_distortion - https://learnopencv.com/rotation-\n\nOverfull \\hbox (160.00499pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 matrix-to-euler-angles/ - https://www.geeksforgeeks.org/calibrat\necamera-opencv-in-python/ - https://docs.opencv.org/4.x/dc/dbb/tutorial_py_cali\nbration.html\n\nPackage longtable Warning: Table widths have changed. Rerun LaTeX.\n\n[48] (/tmp/media-e0c46393b624552d/input.aux)\n\nLaTeX Warning: There were undefined references.\n\n\nLaTeX Warning: Label(s) may have changed. Rerun to get cross-references right.\n\n )\n(see the transcript file for additional information)\nOutput written on /tmp/media-e0c46393b624552d/input.pdf (48 pages).\nTranscript written on /tmp/media-e0c46393b624552d/input.log.\n",
        "description": "LaTeX output"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "Package hyperref Warning: Rerun to get /PageLabels entry.\nPackage longtable Warning: Table widths have changed. Rerun LaTeX.\nLaTeX Warning: Label(s) may have changed. Rerun to get cross-references right.\nTOC is present",
        "description": "Rerun needed"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "",
        "description": "LaTeX run number 2"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "This is XeTeX, Version 3.141592653-2.6-0.999997 (TeX Live 2025) (preloaded format=xelatex)\n restricted \\write18 enabled.\nentering extended mode\n(/tmp/media-e0c46393b624552d/input.tex\nLaTeX2e <2025-11-01>\nL3 programming layer <2025-10-24>\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2025/01/22 v1.4n Standard LaTeX document class\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/size10.clo))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/xcolor.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-def/xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/dvipsnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/svgnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/x11nam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/geometry/geometry.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/keyval.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/ifvtex.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/iftex.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsmath.sty\nFor additional information on amsmath, use the `?' option.\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amstext.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsgen.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsopn.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amssymb.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3kernel/expl3.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3backend/l3backend-xetex.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/xparse/xparse.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/l3keys2e/l3keys2e.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fontenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fix-cm.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/ts1enc.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-table.tex))\n) (/opt/texlive/texdir/texmf-dist/tex/latex/lm/lmodern.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/upquote/upquote.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/textcomp.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype-xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.cfg))\n(/opt/texlive/texdir/texmf-dist/tex/latex/parskip/parskip.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvoptions/kvoptions.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/framed/framed.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/longtable.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/booktabs/booktabs.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/array.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/calc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/footnotehyper/footnotehyper.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphicx.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphics.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/trig.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bookmark.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hyperref.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdfescape/pdfescape.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/infwarerr/infwarerr.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hycolor/hycolor.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/nameref.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/refcount/refcount.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty))\n (/opt/texlive/texdir/texmf-dist/tex/generic/stringenc/stringenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/pd1enc.def)\n(/opt/texlive/texdir/texmf-dist/tex/generic/intcalc/intcalc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/puenc.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/url/url.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/bitset/bitset.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hxetex.def\n(/opt/texlive/texdir/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bkm-dvipdfm.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xurl/xurl.sty)\n(/tmp/media-e0c46393b624552d/input.aux)\n*geometry* driver: auto-detecting\n*geometry* detected driver: xetex\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-LatinModernRoman.cfg)\n(/tmp/media-e0c46393b624552d/input.toc\n(/opt/texlive/texdir/texmf-dist/tex/latex/lm/omllmm.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsa.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msa.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsb.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msb.cfg) [1] [2]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\n[3]) [4] [5]\n\nLaTeX Font Warning: Font shape `TU/lmtt/bx/it' in size <10> not available\n(Font)              Font shape `TU/lmtt/b/sl' tried instead on input line 285.\n\n[6] [7] [8] [9]\nOverfull \\hbox (219.22499pt too wide) in paragraph at lines 876--876\n[]\\TU/lmtt/m/n/10 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgke\ny | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.\ngpg \\[] \n\nOverfull \\hbox (9.22499pt too wide) in paragraph at lines 876--876\n[]  \\TU/lmtt/m/n/10 && curl -s -L https://nvidia.github.io/libnvidia-container/\nstable/deb/nvidia-container-toolkit.list | \\[] \n\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 876--876\n[]    \\TU/lmtt/m/n/10 sed []s#deb https://#deb [signed-by=/usr/share/keyrings/n\nvidia-container-toolkit-keyring.gpg] https://#g[] | \\[] \n[10]\nOverfull \\hbox (67.62201pt too wide) in paragraph at lines 899--901\n[]\\TU/lmr/m/n/10 To get the docker container up and running, download and insta\nll Docker Desktop for your system: https://www.docker.com/products/docker-\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☐ (U+2610) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\n[11] [12]\nOverfull \\hbox (122.597pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 It is possible to adjust the level fidelity for a world in \\TU/l\nmtt/m/n/10 config.sh\\TU/lmr/m/n/10 , there the \\TU/lmtt/m/n/10 world_setup \\TU/\nlmr/m/n/10 is sent to - \\TU/lmtt/m/n/10 simulation/simlan_bringup/launch/sim.la\nunch.py\\TU/lmr/m/n/10 .\n\nOverfull \\hbox (269.67499pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 - \\TU/lmtt/m/n/10 simulation/simlan_gazebo_environment/launch/si\nmlan_factory.launch.py \\TU/lmr/m/n/10 (for world generation) - \\TU/lmtt/m/n/10 \nsimulation/simlan_gazebo_environment/launch/generate_world_file.py\n\nOverfull \\hbox (225.56703pt too wide) in paragraph at lines 1146--1154\n\\TU/lmr/m/n/10 Aruco codes and cameras are all attached to the same link in Gaz\nebo. To create new static agents, go to \\TU/lmtt/m/n/10 simulation/static_agent\n_launcher/description/agents.urdf.xacro\\TU/lmr/m/n/10 .\n[13] [14] [15] [16]\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n\nOverfull \\hbox (329.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 /usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWar\nning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciP\ny (detected version 1.26.2[] \n[17]\nOverfull \\hbox (182.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 ValueError: bpy_struct \"PHOBOS_OT_define_submodel\" registrati\non error: []submodeltype[] EnumProperty could not register (see previous error)\n[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 IOR of negative value is not allowed for materials (using Ble\nnder default value instead)+-- Import Scene --------[] \n[18]\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1048, in toggleVisual[] \n\nOverfull \\hbox (61.72499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1051, in toggleCollision[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 [20231211_08:52:53] WARNING No text file README.md found. (ph\nobos/blender/utils/blender.py - readTextFile (l259))[] \nignored error: Infinite glue shrinkage found in box being split [19] [20]\nignored error: Infinite glue shrinkage found in box being split [21] [22]\nOverfull \\hbox (177.97891pt too wide) in paragraph at lines 2164--2166\n\\TU/lmr/m/n/10 One can see the URDF by running: \\TU/lmtt/m/n/10 roslaunch urdf_\ntutorial display.launch model:=[]$(find forklift_robot_description)/urdf/forkli\nft_simple.urdf[] \n\nOverfull \\hbox (15.40501pt too wide) in paragraph at lines 2238--2243\n[]\\TU/lmr/m/n/10 The \\TU/lmtt/m/n/10 camera_config.xacro \\TU/lmr/m/n/10 is then\n sent to the robot_state_publisher node and published to the /static_agent/robo\nt_description\n[23]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2301--2303\n[][]\n[24]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2323--2324\n[]\\TU/lmtt/m/n/10 launch_rviz_launch_argument = DeclareLaunchArgument(         \n\"rviz\",         default_value=\"False\",\n[25] [26]\nOverfull \\hbox (267.79501pt too wide) in paragraph at lines 2521--2524\n[]\\TU/lmr/m/n/10 The topic name is defined by the automatically generated gz_br\nidge() which can be found in /home/ros/src/simulation/pallet_truck/pallet_truck\n_bringup/launch/generate_gz_bridge.py \n[27]\nOverfull \\hbox (24.97499pt too wide) in paragraph at lines 2590--2590\n[]\\TU/lmtt/m/n/10 Node(  # Manually setting the joint between map and odom to 0\n 0 0, i.e. identical to each other. map -> odom[] \n\nOverfull \\hbox (81.9339pt too wide) in paragraph at lines 2621--2630\n\\TU/lmtt/m/n/10 ROBOTS \\TU/lmr/m/n/10 variable in config.sh. the pallet_trucks \nand forklifts also have an individual \\TU/lmtt/m/n/10 navigate_w_replaning_and_\nrecovery_robot_agent_x.xml\n[28]\nOverfull \\hbox (175.485pt too wide) in paragraph at lines 2655--2664\n\\TU/lmr/m/n/10 manoids on the other hand get their \\TU/lmtt/m/n/10 odom \\TU/lmr\n/m/n/10 frame from the ros2_controller \\TU/lmtt/m/n/10 simulation/humanoid_supp\nort_moveit_config/launch/launch_controllers.launch.py\\TU/lmr/m/n/10 .\nignored error: Infinite glue shrinkage found in box being split [29]\nOverfull \\hbox (345.22499pt too wide) in paragraph at lines 2782--2783\n[]\\TU/lmtt/m/n/10 ros2 launch urdf_tutorial display.launch.py model:=/home/ros/\nsrc/simulation/humanoid_robot/model/human-gazebo/humanSubjectWithMeshes/humanSu\nbjectWithMesh_simplified.urdf \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2837--2838\n []\\TU/lmr/m/n/10 Shoulder \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2839--2840\n []\\TU/lmr/m/n/10 Shoulder \n[30] [31]\nOverfull \\hbox (5.29701pt too wide) in paragraph at lines 2896--2905\n\\TU/lmr/m/n/10 This is the \\TU/lmtt/m/n/10 aruco_localization \\TU/lmr/m/n/10 pa\nckage, which runs a ros2 node that takes images from camera topics \\TU/lmtt/m/n\n/10 CAMERA_X/camera_info\n[32]\nOverfull \\hbox (0.38501pt too wide) in paragraph at lines 2996--3001\n\\TU/lmr/m/n/10 To implement geofencing and the safety situation in which a pall\net truck is not observable in any camera. \\TU/lmtt/m/n/10 aruco_localization\n\nOverfull \\hbox (258.045pt too wide) in paragraph at lines 3006--3017\n\\TU/lmr/m/n/10 At first we define a custom \\TU/lmtt/m/n/10 behavior_tree.xml \\T\nU/lmr/m/n/10 in \\TU/lmtt/m/n/10 src/simulation/pallet_truck/pallet_truck_naviga\ntion/config/navigate_w_replanning_and_recovery_robot_agent_X.xml\\TU/lmr/m/n/10 \n.\n\nOverfull \\hbox (330.03503pt too wide) in paragraph at lines 3051--3064\n[]\\TU/lmr/m/n/10 The first one we tried to use is the \\TU/lmtt/m/n/10 Transform\nAvailable \\TU/lmr/m/n/10 plugin (https://github.com/ros-navigation/navigation2/\nblob/main/nav2_behavior_tree/plugins/condition/transform_available_condition.cp\np).\n\nOverfull \\hbox (233.82503pt too wide) in paragraph at lines 3065--3072\n[]\\TU/lmr/m/n/10 The second plugin we tried is the \\TU/lmtt/m/n/10 IsStuckCondi\ntion \\TU/lmr/m/n/10 (https://github.com/ros-navigation/navigation2/blob/main/na\nv2_behavior_tree/plugins/condition/is_stuck_condition.cpp)\n[33]\nOverfull \\hbox (1069.72499pt too wide) in paragraph at lines 3134--3134\n[]\\TU/lmtt/m/n/10 [WARN] [humanoid.moveit.moveit.ros.planning_scene_monitor] [i\nd]: Unable to transform object from frame []unconnected_frame[] to planning fra\nme []base_link[] (Could not find a connection between []base_link[] and []uncon\nnected_frame[] because they are not part of the same tree. TF has two or more u\nnconnected trees)[] \n[34]\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n[35]\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3309--3309\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (8.37038pt too wide) in paragraph at lines 3310--3311\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (17.3987pt too wide) in paragraph at lines 3318--3318\n[]|\\TU/lmtt/m/n/10 frames_to_process|  \n\nOverfull \\hbox (27.8987pt too wide) in paragraph at lines 3320--3320\n[]|\\TU/lmtt/m/n/10 preprocess_all_data|  \n\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3323--3323\n[]|\\TU/lmtt/m/n/10 fake_orientation|  \n\nOverfull \\hbox (13.57378pt too wide) in paragraph at lines 3386--3386\n[]|\\TU/lmtt/m/n/10 gazebo_teleport_service|  \n\nOverfull \\hbox (49.50153pt too wide) in paragraph at lines 3427--3428\n[]|\\TU/lmtt/m/n/10 visualize_real_data|  \n\nOverfull \\hbox (12.75153pt too wide) in paragraph at lines 3429--3430\n[]|\\TU/lmtt/m/n/10 entity_topic|  \n\nOverfull \\hbox (21.35674pt too wide) in paragraph at lines 3434--3434\n[]|\\TU/lmtt/m/n/10 processing_time_limit|  \n[36] [37]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ⚡ (U+26A1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\n\nOverfull \\hbox (29.98172pt too wide) in paragraph at lines 3619--3624\n[]\\TU/lmr/m/n/10 This initializes three action servers: - \\TU/lmr/bx/n/10 🚀 tel\neport_action_server\\TU/lmr/m/n/10 : Handles teleportation of robots. - \\TU/lmr/\nbx/n/10 ⚡ set_speed_action_server\\TU/lmr/m/n/10 :\nMissing character: There is no 🔄 (U+1F504) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📐 (U+1F4D0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🏎 (U+1F3CE) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💠 (U+1F4A0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman12-bold]:mapping=tex-\ntext;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\n[38]\nMissing character: There is no ⏱ (U+23F1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 📍 (U+1F4CD) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\n\nOverfull \\hbox (36.725pt too wide) in paragraph at lines 3725--3728\n[]\\TU/lmr/m/n/10 To run our package make sure that gazebo simulator is running.\n Then we can run the \\TU/lmtt/m/n/10 panda_moveit_config/launch/demo.launch.py\n\nUnderfull \\hbox (badness 1231) in paragraph at lines 3745--3756\n\\TU/lmr/m/n/10 The folder[][]\\TU/lmtt/m/n/10 custom_motion_planning_python_api[\n][] \\TU/lmr/m/n/10 has scripting files that plans and executes motions for a pa\nnda\n\nOverfull \\hbox (37.46501pt too wide) in paragraph at lines 3745--3756\n\\TU/lmtt/m/n/10 motion_planning_python_api_planning_scene.py \\TU/lmr/m/n/10 is \nan original demo from moveit2 - \\TU/lmtt/m/n/10 motion_planning_python_api_tuto\nrial.py\n[39]\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\n\nUnderfull \\hbox (badness 1622) in paragraph at lines 3884--3884\n[]\\TU/lmr/bx/n/10 Deterministic, Disentanglement One-parameter Object Movements\n (one_object_deterministic\n[40]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4055--4059\n\n[41]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4092--4095\n\n\nUnderfull \\hbox (badness 10000) in paragraph at lines 4126--4129\n\n\nLaTeX Warning: Hyper reference `models' on page 42 undefined on input line 4183\n.\n\n[42]\nOverfull \\hbox (113.24pt too wide) in paragraph at lines 4243--4245\n[]\\TU/lmr/m/n/10 You can replay_motion each motion data separately: \\TU/lmtt/m/\nn/10 ./control.sh replay_motion DATASET_PROCESSED/EVAL/motion_data/AAAAAAA_moti\non.json \n\nOverfull \\hbox (44.4639pt too wide) in paragraph at lines 4314--4319\n\\TU/lmr/m/n/10 A summary report of the session is also generated and will be sa\nved inside \\TU/lmtt/m/n/10 pose_to_motion/{$model_type}/output/train_report.csv\n \n\nOverfull \\hbox (64.365pt too wide) in paragraph at lines 4320--4326\n[]\\TU/lmr/m/n/10 There are two options for using the data and training a model.\n The resulting model is saved in \\TU/lmtt/m/n/10 {$model_type}/output/saved_mod\nel_states\\TU/lmr/m/n/10 .\n[43] [44] [45] [46]\nOverfull \\hbox (140.47499pt too wide) in paragraph at lines 4583--4583\n[]\\TU/lmtt/m/n/10 [gzserver-1] [ERROR] [1727951819.671190014] [jackal.gazebo_ro\ns2_control]: controller manager doesn[]t have an update_rate parameter[] \n\nOverfull \\hbox (289.36447pt too wide) in paragraph at lines 4599--4604\n\\TU/lmtt/m/n/10 docker compose \\TU/lmr/m/n/10 or \\TU/lmtt/m/n/10 docker-compose\n \\TU/lmr/m/n/10 is set correctly in the setting. [] \n[47] [48]\nOverfull \\hbox (313.72499pt too wide) in paragraph at lines 4645--4645\n[]\\TU/lmtt/m/n/10 nvidia-container-cli: requirement error: unsatisfied conditio\nn: cuda>=12.6, please update your driver to a newer version, or use an earlier \ncuda container: unknown[] \n\nOverfull \\hbox (124.72499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLdispatch.so.0)[] \n\nOverfull \\hbox (87.97499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLX.so.0)[] \n\nOverfull \\hbox (3.97499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get remove --purge nvidia-container-toolkit nvidia-\ncontainer-toolkit-base libnvidia-container*[] \n\nOverfull \\hbox (292.72499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get install nvidia-container-toolkit=1.17.4-1 nvidi\na-container-toolkit-base=1.17.4-1 libnvidia-container1=1.17.4-1 libnvidia-conta\niner-tools=1.17.4-1[] \n[49]\nUnderfull \\hbox (badness 1609) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “high-level_diagram_SIMLAN.drawio.png” ### Humanoid_mocap_flow.d\nrawio “Humanoid_mocap_flow.drawio.png”\n\nUnderfull \\hbox (badness 6461) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### legend.drawio “legend.drawio.png” ### ros2 launch aruco_loca\nlization multi_detection.launch.py.drawio\n\nUnderfull \\hbox (badness 4518) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “ros2 launch aruco_localization multi_detection.launch.py.drawio\n.png” ### ros2 launch camera_bird_eye_view\n\nOverfull \\hbox (8.435pt too wide) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 launch moveit_resources_panda_moveit_config demo.launch.py.drawi\no “ros2 launch moveit_resources_panda_moveit_config\n\nUnderfull \\hbox (badness 3229) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 demo.launch.py.drawio.png” ### ros2 launch pallet_truck_bringup \nmultiple_robot_spawn.launch.py.drawio “ros2\n\nUnderfull \\hbox (badness 5217) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### ros2 launch visualize_real_data scenario_replayer.launch.py.\ndrawio “ros2 launch visualize_real_data sce-\n[50]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4935--4942\n[]\\TU/lmr/m/n/10 Camera projection: - https://github.com/polygon-software/pytho\nn-visual-odometry/blob/master/Chapter%203%20-\n\nOverfull \\hbox (41.115pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 %20Camera%20Projection.ipynb - https://classic.gazebosim.org/tut\norials?tut=camera_distortion - https://learnopencv.com/rotation-\n\nOverfull \\hbox (160.00499pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 matrix-to-euler-angles/ - https://www.geeksforgeeks.org/calibrat\necamera-opencv-in-python/ - https://docs.opencv.org/4.x/dc/dbb/tutorial_py_cali\nbration.html\n[51] (/tmp/media-e0c46393b624552d/input.aux)\n\nLaTeX Warning: There were undefined references.\n\n\nLaTeX Warning: Label(s) may have changed. Rerun to get cross-references right.\n\n )\n(see the transcript file for additional information)\nOutput written on /tmp/media-e0c46393b624552d/input.pdf (51 pages).\nTranscript written on /tmp/media-e0c46393b624552d/input.log.\n",
        "description": "LaTeX output"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "LaTeX Warning: Label(s) may have changed. Rerun to get cross-references right.\nTOC is present",
        "description": "Rerun needed"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "",
        "description": "LaTeX run number 3"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "This is XeTeX, Version 3.141592653-2.6-0.999997 (TeX Live 2025) (preloaded format=xelatex)\n restricted \\write18 enabled.\nentering extended mode\n(/tmp/media-e0c46393b624552d/input.tex\nLaTeX2e <2025-11-01>\nL3 programming layer <2025-10-24>\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2025/01/22 v1.4n Standard LaTeX document class\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/size10.clo))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/xcolor.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-def/xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/dvipsnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/svgnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/x11nam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/geometry/geometry.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/keyval.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/ifvtex.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/iftex.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsmath.sty\nFor additional information on amsmath, use the `?' option.\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amstext.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsgen.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsopn.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amssymb.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3kernel/expl3.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3backend/l3backend-xetex.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/xparse/xparse.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/l3keys2e/l3keys2e.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fontenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fix-cm.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/ts1enc.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-table.tex))\n) (/opt/texlive/texdir/texmf-dist/tex/latex/lm/lmodern.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/upquote/upquote.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/textcomp.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype-xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.cfg))\n(/opt/texlive/texdir/texmf-dist/tex/latex/parskip/parskip.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvoptions/kvoptions.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/framed/framed.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/longtable.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/booktabs/booktabs.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/array.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/calc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/footnotehyper/footnotehyper.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphicx.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphics.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/trig.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bookmark.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hyperref.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdfescape/pdfescape.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/infwarerr/infwarerr.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hycolor/hycolor.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/nameref.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/refcount/refcount.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty))\n (/opt/texlive/texdir/texmf-dist/tex/generic/stringenc/stringenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/pd1enc.def)\n(/opt/texlive/texdir/texmf-dist/tex/generic/intcalc/intcalc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/puenc.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/url/url.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/bitset/bitset.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hxetex.def\n(/opt/texlive/texdir/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bkm-dvipdfm.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xurl/xurl.sty)\n(/tmp/media-e0c46393b624552d/input.aux)\n*geometry* driver: auto-detecting\n*geometry* detected driver: xetex\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-LatinModernRoman.cfg)\n(/tmp/media-e0c46393b624552d/input.toc\n(/opt/texlive/texdir/texmf-dist/tex/latex/lm/omllmm.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsa.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msa.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsb.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msb.cfg) [1] [2]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\n[3]) [4] [5]\n\nLaTeX Font Warning: Font shape `TU/lmtt/bx/it' in size <10> not available\n(Font)              Font shape `TU/lmtt/b/sl' tried instead on input line 285.\n\n[6] [7] [8] [9]\nOverfull \\hbox (219.22499pt too wide) in paragraph at lines 876--876\n[]\\TU/lmtt/m/n/10 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgke\ny | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.\ngpg \\[] \n\nOverfull \\hbox (9.22499pt too wide) in paragraph at lines 876--876\n[]  \\TU/lmtt/m/n/10 && curl -s -L https://nvidia.github.io/libnvidia-container/\nstable/deb/nvidia-container-toolkit.list | \\[] \n\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 876--876\n[]    \\TU/lmtt/m/n/10 sed []s#deb https://#deb [signed-by=/usr/share/keyrings/n\nvidia-container-toolkit-keyring.gpg] https://#g[] | \\[] \n[10]\nOverfull \\hbox (67.62201pt too wide) in paragraph at lines 899--901\n[]\\TU/lmr/m/n/10 To get the docker container up and running, download and insta\nll Docker Desktop for your system: https://www.docker.com/products/docker-\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☐ (U+2610) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\n[11] [12]\nOverfull \\hbox (122.597pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 It is possible to adjust the level fidelity for a world in \\TU/l\nmtt/m/n/10 config.sh\\TU/lmr/m/n/10 , there the \\TU/lmtt/m/n/10 world_setup \\TU/\nlmr/m/n/10 is sent to - \\TU/lmtt/m/n/10 simulation/simlan_bringup/launch/sim.la\nunch.py\\TU/lmr/m/n/10 .\n\nOverfull \\hbox (269.67499pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 - \\TU/lmtt/m/n/10 simulation/simlan_gazebo_environment/launch/si\nmlan_factory.launch.py \\TU/lmr/m/n/10 (for world generation) - \\TU/lmtt/m/n/10 \nsimulation/simlan_gazebo_environment/launch/generate_world_file.py\n\nOverfull \\hbox (225.56703pt too wide) in paragraph at lines 1146--1154\n\\TU/lmr/m/n/10 Aruco codes and cameras are all attached to the same link in Gaz\nebo. To create new static agents, go to \\TU/lmtt/m/n/10 simulation/static_agent\n_launcher/description/agents.urdf.xacro\\TU/lmr/m/n/10 .\n[13] [14] [15] [16]\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n\nOverfull \\hbox (329.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 /usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWar\nning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciP\ny (detected version 1.26.2[] \n[17]\nOverfull \\hbox (182.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 ValueError: bpy_struct \"PHOBOS_OT_define_submodel\" registrati\non error: []submodeltype[] EnumProperty could not register (see previous error)\n[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 IOR of negative value is not allowed for materials (using Ble\nnder default value instead)+-- Import Scene --------[] \n[18]\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1048, in toggleVisual[] \n\nOverfull \\hbox (61.72499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1051, in toggleCollision[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 [20231211_08:52:53] WARNING No text file README.md found. (ph\nobos/blender/utils/blender.py - readTextFile (l259))[] \nignored error: Infinite glue shrinkage found in box being split [19] [20]\nignored error: Infinite glue shrinkage found in box being split [21] [22]\nOverfull \\hbox (177.97891pt too wide) in paragraph at lines 2164--2166\n\\TU/lmr/m/n/10 One can see the URDF by running: \\TU/lmtt/m/n/10 roslaunch urdf_\ntutorial display.launch model:=[]$(find forklift_robot_description)/urdf/forkli\nft_simple.urdf[] \n\nOverfull \\hbox (15.40501pt too wide) in paragraph at lines 2238--2243\n[]\\TU/lmr/m/n/10 The \\TU/lmtt/m/n/10 camera_config.xacro \\TU/lmr/m/n/10 is then\n sent to the robot_state_publisher node and published to the /static_agent/robo\nt_description\n[23]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2301--2303\n[][]\n[24]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2323--2324\n[]\\TU/lmtt/m/n/10 launch_rviz_launch_argument = DeclareLaunchArgument(         \n\"rviz\",         default_value=\"False\",\n[25] [26]\nOverfull \\hbox (267.79501pt too wide) in paragraph at lines 2521--2524\n[]\\TU/lmr/m/n/10 The topic name is defined by the automatically generated gz_br\nidge() which can be found in /home/ros/src/simulation/pallet_truck/pallet_truck\n_bringup/launch/generate_gz_bridge.py \n[27]\nOverfull \\hbox (24.97499pt too wide) in paragraph at lines 2590--2590\n[]\\TU/lmtt/m/n/10 Node(  # Manually setting the joint between map and odom to 0\n 0 0, i.e. identical to each other. map -> odom[] \n\nOverfull \\hbox (81.9339pt too wide) in paragraph at lines 2621--2630\n\\TU/lmtt/m/n/10 ROBOTS \\TU/lmr/m/n/10 variable in config.sh. the pallet_trucks \nand forklifts also have an individual \\TU/lmtt/m/n/10 navigate_w_replaning_and_\nrecovery_robot_agent_x.xml\n[28]\nOverfull \\hbox (175.485pt too wide) in paragraph at lines 2655--2664\n\\TU/lmr/m/n/10 manoids on the other hand get their \\TU/lmtt/m/n/10 odom \\TU/lmr\n/m/n/10 frame from the ros2_controller \\TU/lmtt/m/n/10 simulation/humanoid_supp\nort_moveit_config/launch/launch_controllers.launch.py\\TU/lmr/m/n/10 .\nignored error: Infinite glue shrinkage found in box being split [29]\nOverfull \\hbox (345.22499pt too wide) in paragraph at lines 2782--2783\n[]\\TU/lmtt/m/n/10 ros2 launch urdf_tutorial display.launch.py model:=/home/ros/\nsrc/simulation/humanoid_robot/model/human-gazebo/humanSubjectWithMeshes/humanSu\nbjectWithMesh_simplified.urdf \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2837--2838\n []\\TU/lmr/m/n/10 Shoulder \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2839--2840\n []\\TU/lmr/m/n/10 Shoulder \n[30] [31]\nOverfull \\hbox (5.29701pt too wide) in paragraph at lines 2896--2905\n\\TU/lmr/m/n/10 This is the \\TU/lmtt/m/n/10 aruco_localization \\TU/lmr/m/n/10 pa\nckage, which runs a ros2 node that takes images from camera topics \\TU/lmtt/m/n\n/10 CAMERA_X/camera_info\n[32]\nOverfull \\hbox (0.38501pt too wide) in paragraph at lines 2996--3001\n\\TU/lmr/m/n/10 To implement geofencing and the safety situation in which a pall\net truck is not observable in any camera. \\TU/lmtt/m/n/10 aruco_localization\n\nOverfull \\hbox (258.045pt too wide) in paragraph at lines 3006--3017\n\\TU/lmr/m/n/10 At first we define a custom \\TU/lmtt/m/n/10 behavior_tree.xml \\T\nU/lmr/m/n/10 in \\TU/lmtt/m/n/10 src/simulation/pallet_truck/pallet_truck_naviga\ntion/config/navigate_w_replanning_and_recovery_robot_agent_X.xml\\TU/lmr/m/n/10 \n.\n\nOverfull \\hbox (330.03503pt too wide) in paragraph at lines 3051--3064\n[]\\TU/lmr/m/n/10 The first one we tried to use is the \\TU/lmtt/m/n/10 Transform\nAvailable \\TU/lmr/m/n/10 plugin (https://github.com/ros-navigation/navigation2/\nblob/main/nav2_behavior_tree/plugins/condition/transform_available_condition.cp\np).\n\nOverfull \\hbox (233.82503pt too wide) in paragraph at lines 3065--3072\n[]\\TU/lmr/m/n/10 The second plugin we tried is the \\TU/lmtt/m/n/10 IsStuckCondi\ntion \\TU/lmr/m/n/10 (https://github.com/ros-navigation/navigation2/blob/main/na\nv2_behavior_tree/plugins/condition/is_stuck_condition.cpp)\n[33]\nOverfull \\hbox (1069.72499pt too wide) in paragraph at lines 3134--3134\n[]\\TU/lmtt/m/n/10 [WARN] [humanoid.moveit.moveit.ros.planning_scene_monitor] [i\nd]: Unable to transform object from frame []unconnected_frame[] to planning fra\nme []base_link[] (Could not find a connection between []base_link[] and []uncon\nnected_frame[] because they are not part of the same tree. TF has two or more u\nnconnected trees)[] \n[34]\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n[35]\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3309--3309\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (8.37038pt too wide) in paragraph at lines 3310--3311\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (17.3987pt too wide) in paragraph at lines 3318--3318\n[]|\\TU/lmtt/m/n/10 frames_to_process|  \n\nOverfull \\hbox (27.8987pt too wide) in paragraph at lines 3320--3320\n[]|\\TU/lmtt/m/n/10 preprocess_all_data|  \n\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3323--3323\n[]|\\TU/lmtt/m/n/10 fake_orientation|  \n\nOverfull \\hbox (13.57378pt too wide) in paragraph at lines 3386--3386\n[]|\\TU/lmtt/m/n/10 gazebo_teleport_service|  \n\nOverfull \\hbox (49.50153pt too wide) in paragraph at lines 3427--3428\n[]|\\TU/lmtt/m/n/10 visualize_real_data|  \n\nOverfull \\hbox (12.75153pt too wide) in paragraph at lines 3429--3430\n[]|\\TU/lmtt/m/n/10 entity_topic|  \n\nOverfull \\hbox (21.35674pt too wide) in paragraph at lines 3434--3434\n[]|\\TU/lmtt/m/n/10 processing_time_limit|  \n[36] [37]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ⚡ (U+26A1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\n\nOverfull \\hbox (29.98172pt too wide) in paragraph at lines 3619--3624\n[]\\TU/lmr/m/n/10 This initializes three action servers: - \\TU/lmr/bx/n/10 🚀 tel\neport_action_server\\TU/lmr/m/n/10 : Handles teleportation of robots. - \\TU/lmr/\nbx/n/10 ⚡ set_speed_action_server\\TU/lmr/m/n/10 :\nMissing character: There is no 🔄 (U+1F504) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📐 (U+1F4D0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🏎 (U+1F3CE) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💠 (U+1F4A0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman12-bold]:mapping=tex-\ntext;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\n[38]\nMissing character: There is no ⏱ (U+23F1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 📍 (U+1F4CD) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\n\nOverfull \\hbox (36.725pt too wide) in paragraph at lines 3725--3728\n[]\\TU/lmr/m/n/10 To run our package make sure that gazebo simulator is running.\n Then we can run the \\TU/lmtt/m/n/10 panda_moveit_config/launch/demo.launch.py\n\nUnderfull \\hbox (badness 1231) in paragraph at lines 3745--3756\n\\TU/lmr/m/n/10 The folder[][]\\TU/lmtt/m/n/10 custom_motion_planning_python_api[\n][] \\TU/lmr/m/n/10 has scripting files that plans and executes motions for a pa\nnda\n\nOverfull \\hbox (37.46501pt too wide) in paragraph at lines 3745--3756\n\\TU/lmtt/m/n/10 motion_planning_python_api_planning_scene.py \\TU/lmr/m/n/10 is \nan original demo from moveit2 - \\TU/lmtt/m/n/10 motion_planning_python_api_tuto\nrial.py\n[39]\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\n\nUnderfull \\hbox (badness 1622) in paragraph at lines 3884--3884\n[]\\TU/lmr/bx/n/10 Deterministic, Disentanglement One-parameter Object Movements\n (one_object_deterministic\n[40]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4055--4059\n\n[41]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4092--4095\n\n\nUnderfull \\hbox (badness 10000) in paragraph at lines 4126--4129\n\n\nLaTeX Warning: Hyper reference `models' on page 42 undefined on input line 4183\n.\n\n[42]\nOverfull \\hbox (113.24pt too wide) in paragraph at lines 4243--4245\n[]\\TU/lmr/m/n/10 You can replay_motion each motion data separately: \\TU/lmtt/m/\nn/10 ./control.sh replay_motion DATASET_PROCESSED/EVAL/motion_data/AAAAAAA_moti\non.json \n\nOverfull \\hbox (44.4639pt too wide) in paragraph at lines 4314--4319\n\\TU/lmr/m/n/10 A summary report of the session is also generated and will be sa\nved inside \\TU/lmtt/m/n/10 pose_to_motion/{$model_type}/output/train_report.csv\n \n\nOverfull \\hbox (64.365pt too wide) in paragraph at lines 4320--4326\n[]\\TU/lmr/m/n/10 There are two options for using the data and training a model.\n The resulting model is saved in \\TU/lmtt/m/n/10 {$model_type}/output/saved_mod\nel_states\\TU/lmr/m/n/10 .\n[43] [44] [45] [46]\nOverfull \\hbox (140.47499pt too wide) in paragraph at lines 4583--4583\n[]\\TU/lmtt/m/n/10 [gzserver-1] [ERROR] [1727951819.671190014] [jackal.gazebo_ro\ns2_control]: controller manager doesn[]t have an update_rate parameter[] \n\nOverfull \\hbox (289.36447pt too wide) in paragraph at lines 4599--4604\n\\TU/lmtt/m/n/10 docker compose \\TU/lmr/m/n/10 or \\TU/lmtt/m/n/10 docker-compose\n \\TU/lmr/m/n/10 is set correctly in the setting. [] \n[47] [48]\nOverfull \\hbox (313.72499pt too wide) in paragraph at lines 4645--4645\n[]\\TU/lmtt/m/n/10 nvidia-container-cli: requirement error: unsatisfied conditio\nn: cuda>=12.6, please update your driver to a newer version, or use an earlier \ncuda container: unknown[] \n\nOverfull \\hbox (124.72499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLdispatch.so.0)[] \n\nOverfull \\hbox (87.97499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLX.so.0)[] \n\nOverfull \\hbox (3.97499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get remove --purge nvidia-container-toolkit nvidia-\ncontainer-toolkit-base libnvidia-container*[] \n\nOverfull \\hbox (292.72499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get install nvidia-container-toolkit=1.17.4-1 nvidi\na-container-toolkit-base=1.17.4-1 libnvidia-container1=1.17.4-1 libnvidia-conta\niner-tools=1.17.4-1[] \n[49]\nUnderfull \\hbox (badness 1609) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “high-level_diagram_SIMLAN.drawio.png” ### Humanoid_mocap_flow.d\nrawio “Humanoid_mocap_flow.drawio.png”\n\nUnderfull \\hbox (badness 6461) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### legend.drawio “legend.drawio.png” ### ros2 launch aruco_loca\nlization multi_detection.launch.py.drawio\n\nUnderfull \\hbox (badness 4518) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “ros2 launch aruco_localization multi_detection.launch.py.drawio\n.png” ### ros2 launch camera_bird_eye_view\n\nOverfull \\hbox (8.435pt too wide) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 launch moveit_resources_panda_moveit_config demo.launch.py.drawi\no “ros2 launch moveit_resources_panda_moveit_config\n\nUnderfull \\hbox (badness 3229) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 demo.launch.py.drawio.png” ### ros2 launch pallet_truck_bringup \nmultiple_robot_spawn.launch.py.drawio “ros2\n\nUnderfull \\hbox (badness 5217) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### ros2 launch visualize_real_data scenario_replayer.launch.py.\ndrawio “ros2 launch visualize_real_data sce-\n[50]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4935--4942\n[]\\TU/lmr/m/n/10 Camera projection: - https://github.com/polygon-software/pytho\nn-visual-odometry/blob/master/Chapter%203%20-\n\nOverfull \\hbox (41.115pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 %20Camera%20Projection.ipynb - https://classic.gazebosim.org/tut\norials?tut=camera_distortion - https://learnopencv.com/rotation-\n\nOverfull \\hbox (160.00499pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 matrix-to-euler-angles/ - https://www.geeksforgeeks.org/calibrat\necamera-opencv-in-python/ - https://docs.opencv.org/4.x/dc/dbb/tutorial_py_cali\nbration.html\n[51] (/tmp/media-e0c46393b624552d/input.aux)\n\nLaTeX Warning: There were undefined references.\n\n )\n(see the transcript file for additional information)\nOutput written on /tmp/media-e0c46393b624552d/input.pdf (51 pages).\nTranscript written on /tmp/media-e0c46393b624552d/input.log.\n",
        "description": "LaTeX output"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "TOC is present",
        "description": "Rerun needed"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "",
        "description": "LaTeX run number 4"
    },
    {
        "type": "MakePDFInfo",
        "verbosity": "INFO",
        "contents": "This is XeTeX, Version 3.141592653-2.6-0.999997 (TeX Live 2025) (preloaded format=xelatex)\n restricted \\write18 enabled.\nentering extended mode\n(/tmp/media-e0c46393b624552d/input.tex\nLaTeX2e <2025-11-01>\nL3 programming layer <2025-10-24>\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2025/01/22 v1.4n Standard LaTeX document class\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/size10.clo))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/xcolor.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/color.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-def/xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/mathcolor.ltx))\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/dvipsnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/svgnam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/xcolor/x11nam.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/geometry/geometry.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/keyval.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/ifvtex.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/iftex/iftex.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsmath.sty\nFor additional information on amsmath, use the `?' option.\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amstext.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsgen.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsmath/amsopn.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amssymb.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3kernel/expl3.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3backend/l3backend-xetex.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/xparse/xparse.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/l3packages/l3keys2e/l3keys2e.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec-xetex.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fontenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/fontspec/fontspec.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/fix-cm.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/ts1enc.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/unicode-math/unicode-math-table.tex))\n) (/opt/texlive/texdir/texmf-dist/tex/latex/lm/lmodern.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/upquote/upquote.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/base/textcomp.sty))\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype-xetex.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/microtype.cfg))\n(/opt/texlive/texdir/texmf-dist/tex/latex/parskip/parskip.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvoptions/kvoptions.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/framed/framed.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/longtable.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/booktabs/booktabs.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/array.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/tools/calc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/footnotehyper/footnotehyper.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphicx.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/graphics.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics/trig.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bookmark.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hyperref.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdfescape/pdfescape.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/infwarerr/infwarerr.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hycolor/hycolor.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/nameref.sty\n(/opt/texlive/texdir/texmf-dist/tex/latex/refcount/refcount.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty))\n (/opt/texlive/texdir/texmf-dist/tex/generic/stringenc/stringenc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/pd1enc.def)\n(/opt/texlive/texdir/texmf-dist/tex/generic/intcalc/intcalc.sty)\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/puenc.def)\n(/opt/texlive/texdir/texmf-dist/tex/latex/url/url.sty)\n(/opt/texlive/texdir/texmf-dist/tex/generic/bitset/bitset.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/hyperref/hxetex.def\n(/opt/texlive/texdir/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty\n(/opt/texlive/texdir/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty)))\n(/opt/texlive/texdir/texmf-dist/tex/latex/bookmark/bkm-dvipdfm.def))\n(/opt/texlive/texdir/texmf-dist/tex/latex/xurl/xurl.sty)\n(/tmp/media-e0c46393b624552d/input.aux)\n*geometry* driver: auto-detecting\n*geometry* detected driver: xetex\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-LatinModernRoman.cfg)\n(/tmp/media-e0c46393b624552d/input.toc\n(/opt/texlive/texdir/texmf-dist/tex/latex/lm/omllmm.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsa.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msa.cfg)\n(/opt/texlive/texdir/texmf-dist/tex/latex/amsfonts/umsb.fd)\n(/opt/texlive/texdir/texmf-dist/tex/latex/microtype/mt-msb.cfg) [1] [2]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🔄 (U+1F504) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman10-regular]:mapping=\ntex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-regular]:mapping=t\nex-text;!\n[3]) [4] [5]\n\nLaTeX Font Warning: Font shape `TU/lmtt/bx/it' in size <10> not available\n(Font)              Font shape `TU/lmtt/b/sl' tried instead on input line 285.\n\n[6] [7] [8] [9]\nOverfull \\hbox (219.22499pt too wide) in paragraph at lines 876--876\n[]\\TU/lmtt/m/n/10 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgke\ny | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.\ngpg \\[] \n\nOverfull \\hbox (9.22499pt too wide) in paragraph at lines 876--876\n[]  \\TU/lmtt/m/n/10 && curl -s -L https://nvidia.github.io/libnvidia-container/\nstable/deb/nvidia-container-toolkit.list | \\[] \n\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 876--876\n[]    \\TU/lmtt/m/n/10 sed []s#deb https://#deb [signed-by=/usr/share/keyrings/n\nvidia-container-toolkit-keyring.gpg] https://#g[] | \\[] \n[10]\nOverfull \\hbox (67.62201pt too wide) in paragraph at lines 899--901\n[]\\TU/lmr/m/n/10 To get the docker container up and running, download and insta\nll Docker Desktop for your system: https://www.docker.com/products/docker-\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◉ (U+25C9) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ◯ (U+25EF) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☐ (U+2610) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no ☑ (U+2611) in font [lmroman10-regular]:mapping=t\nex-text;!\n[11] [12]\nOverfull \\hbox (122.597pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 It is possible to adjust the level fidelity for a world in \\TU/l\nmtt/m/n/10 config.sh\\TU/lmr/m/n/10 , there the \\TU/lmtt/m/n/10 world_setup \\TU/\nlmr/m/n/10 is sent to - \\TU/lmtt/m/n/10 simulation/simlan_bringup/launch/sim.la\nunch.py\\TU/lmr/m/n/10 .\n\nOverfull \\hbox (269.67499pt too wide) in paragraph at lines 1135--1142\n\\TU/lmr/m/n/10 - \\TU/lmtt/m/n/10 simulation/simlan_gazebo_environment/launch/si\nmlan_factory.launch.py \\TU/lmr/m/n/10 (for world generation) - \\TU/lmtt/m/n/10 \nsimulation/simlan_gazebo_environment/launch/generate_world_file.py\n\nOverfull \\hbox (225.56703pt too wide) in paragraph at lines 1146--1154\n\\TU/lmr/m/n/10 Aruco codes and cameras are all attached to the same link in Gaz\nebo. To create new static agents, go to \\TU/lmtt/m/n/10 simulation/static_agent\n_launcher/description/agents.urdf.xacro\\TU/lmr/m/n/10 .\n[13] [14] [15] [16]\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n\nOverfull \\hbox (329.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 /usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWar\nning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciP\ny (detected version 1.26.2[] \n[17]\nOverfull \\hbox (182.47499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 ValueError: bpy_struct \"PHOBOS_OT_define_submodel\" registrati\non error: []submodeltype[] EnumProperty could not register (see previous error)\n[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 IOR of negative value is not allowed for materials (using Ble\nnder default value instead)+-- Import Scene --------[] \n[18]\nOverfull \\hbox (45.97499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1048, in toggleVisual[] \n\nOverfull \\hbox (61.72499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 File \"[HOME]/.config/blender/3.0/scripts/addons/phobos/blende\nr/operators/editing.py\", line 1051, in toggleCollision[] \n\nOverfull \\hbox (51.22499pt too wide) in paragraph at lines 1758--1758\n[]\\TU/lmtt/m/n/10 [20231211_08:52:53] WARNING No text file README.md found. (ph\nobos/blender/utils/blender.py - readTextFile (l259))[] \nignored error: Infinite glue shrinkage found in box being split [19] [20]\nignored error: Infinite glue shrinkage found in box being split [21] [22]\nOverfull \\hbox (177.97891pt too wide) in paragraph at lines 2164--2166\n\\TU/lmr/m/n/10 One can see the URDF by running: \\TU/lmtt/m/n/10 roslaunch urdf_\ntutorial display.launch model:=[]$(find forklift_robot_description)/urdf/forkli\nft_simple.urdf[] \n\nOverfull \\hbox (15.40501pt too wide) in paragraph at lines 2238--2243\n[]\\TU/lmr/m/n/10 The \\TU/lmtt/m/n/10 camera_config.xacro \\TU/lmr/m/n/10 is then\n sent to the robot_state_publisher node and published to the /static_agent/robo\nt_description\n[23]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2301--2303\n[][]\n[24]\nUnderfull \\hbox (badness 10000) in paragraph at lines 2323--2324\n[]\\TU/lmtt/m/n/10 launch_rviz_launch_argument = DeclareLaunchArgument(         \n\"rviz\",         default_value=\"False\",\n[25] [26]\nOverfull \\hbox (267.79501pt too wide) in paragraph at lines 2521--2524\n[]\\TU/lmr/m/n/10 The topic name is defined by the automatically generated gz_br\nidge() which can be found in /home/ros/src/simulation/pallet_truck/pallet_truck\n_bringup/launch/generate_gz_bridge.py \n[27]\nOverfull \\hbox (24.97499pt too wide) in paragraph at lines 2590--2590\n[]\\TU/lmtt/m/n/10 Node(  # Manually setting the joint between map and odom to 0\n 0 0, i.e. identical to each other. map -> odom[] \n\nOverfull \\hbox (81.9339pt too wide) in paragraph at lines 2621--2630\n\\TU/lmtt/m/n/10 ROBOTS \\TU/lmr/m/n/10 variable in config.sh. the pallet_trucks \nand forklifts also have an individual \\TU/lmtt/m/n/10 navigate_w_replaning_and_\nrecovery_robot_agent_x.xml\n[28]\nOverfull \\hbox (175.485pt too wide) in paragraph at lines 2655--2664\n\\TU/lmr/m/n/10 manoids on the other hand get their \\TU/lmtt/m/n/10 odom \\TU/lmr\n/m/n/10 frame from the ros2_controller \\TU/lmtt/m/n/10 simulation/humanoid_supp\nort_moveit_config/launch/launch_controllers.launch.py\\TU/lmr/m/n/10 .\nignored error: Infinite glue shrinkage found in box being split [29]\nOverfull \\hbox (345.22499pt too wide) in paragraph at lines 2782--2783\n[]\\TU/lmtt/m/n/10 ros2 launch urdf_tutorial display.launch.py model:=/home/ros/\nsrc/simulation/humanoid_robot/model/human-gazebo/humanSubjectWithMeshes/humanSu\nbjectWithMesh_simplified.urdf \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2837--2838\n []\\TU/lmr/m/n/10 Shoulder \n\nOverfull \\hbox (5.37726pt too wide) in paragraph at lines 2839--2840\n []\\TU/lmr/m/n/10 Shoulder \n[30] [31]\nOverfull \\hbox (5.29701pt too wide) in paragraph at lines 2896--2905\n\\TU/lmr/m/n/10 This is the \\TU/lmtt/m/n/10 aruco_localization \\TU/lmr/m/n/10 pa\nckage, which runs a ros2 node that takes images from camera topics \\TU/lmtt/m/n\n/10 CAMERA_X/camera_info\n[32]\nOverfull \\hbox (0.38501pt too wide) in paragraph at lines 2996--3001\n\\TU/lmr/m/n/10 To implement geofencing and the safety situation in which a pall\net truck is not observable in any camera. \\TU/lmtt/m/n/10 aruco_localization\n\nOverfull \\hbox (258.045pt too wide) in paragraph at lines 3006--3017\n\\TU/lmr/m/n/10 At first we define a custom \\TU/lmtt/m/n/10 behavior_tree.xml \\T\nU/lmr/m/n/10 in \\TU/lmtt/m/n/10 src/simulation/pallet_truck/pallet_truck_naviga\ntion/config/navigate_w_replanning_and_recovery_robot_agent_X.xml\\TU/lmr/m/n/10 \n.\n\nOverfull \\hbox (330.03503pt too wide) in paragraph at lines 3051--3064\n[]\\TU/lmr/m/n/10 The first one we tried to use is the \\TU/lmtt/m/n/10 Transform\nAvailable \\TU/lmr/m/n/10 plugin (https://github.com/ros-navigation/navigation2/\nblob/main/nav2_behavior_tree/plugins/condition/transform_available_condition.cp\np).\n\nOverfull \\hbox (233.82503pt too wide) in paragraph at lines 3065--3072\n[]\\TU/lmr/m/n/10 The second plugin we tried is the \\TU/lmtt/m/n/10 IsStuckCondi\ntion \\TU/lmr/m/n/10 (https://github.com/ros-navigation/navigation2/blob/main/na\nv2_behavior_tree/plugins/condition/is_stuck_condition.cpp)\n[33]\nOverfull \\hbox (1069.72499pt too wide) in paragraph at lines 3134--3134\n[]\\TU/lmtt/m/n/10 [WARN] [humanoid.moveit.moveit.ros.planning_scene_monitor] [i\nd]: Unable to transform object from frame []unconnected_frame[] to planning fra\nme []base_link[] (Could not find a connection between []base_link[] and []uncon\nnected_frame[] because they are not part of the same tree. TF has two or more u\nnconnected trees)[] \n[34]\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no ├ (U+251C) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no │ (U+2502) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no └ (U+2514) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\nMissing character: There is no ─ (U+2500) in font [lmmono10-regular]:!\n[35]\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3309--3309\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (8.37038pt too wide) in paragraph at lines 3310--3311\n[]|\\TU/lmtt/m/n/10 pointcloud_topic|  \n\nOverfull \\hbox (17.3987pt too wide) in paragraph at lines 3318--3318\n[]|\\TU/lmtt/m/n/10 frames_to_process|  \n\nOverfull \\hbox (27.8987pt too wide) in paragraph at lines 3320--3320\n[]|\\TU/lmtt/m/n/10 preprocess_all_data|  \n\nOverfull \\hbox (12.1487pt too wide) in paragraph at lines 3323--3323\n[]|\\TU/lmtt/m/n/10 fake_orientation|  \n\nOverfull \\hbox (13.57378pt too wide) in paragraph at lines 3386--3386\n[]|\\TU/lmtt/m/n/10 gazebo_teleport_service|  \n\nOverfull \\hbox (49.50153pt too wide) in paragraph at lines 3427--3428\n[]|\\TU/lmtt/m/n/10 visualize_real_data|  \n\nOverfull \\hbox (12.75153pt too wide) in paragraph at lines 3429--3430\n[]|\\TU/lmtt/m/n/10 entity_topic|  \n\nOverfull \\hbox (21.35674pt too wide) in paragraph at lines 3434--3434\n[]|\\TU/lmtt/m/n/10 processing_time_limit|  \n[36] [37]\nMissing character: There is no 🚀 (U+1F680) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚦 (U+1F6A6) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 🚀 (U+1F680) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ⚡ (U+26A1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\n\nOverfull \\hbox (29.98172pt too wide) in paragraph at lines 3619--3624\n[]\\TU/lmr/m/n/10 This initializes three action servers: - \\TU/lmr/bx/n/10 🚀 tel\neport_action_server\\TU/lmr/m/n/10 : Handles teleportation of robots. - \\TU/lmr/\nbx/n/10 ⚡ set_speed_action_server\\TU/lmr/m/n/10 :\nMissing character: There is no 🔄 (U+1F504) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no 📐 (U+1F4D0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🏎 (U+1F3CE) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 💠 (U+1F4A0) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 💥 (U+1F4A5) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 🎬 (U+1F3AC) in font [lmroman12-bold]:mapping=tex\n-text;!\nMissing character: There is no ⏳ (U+23F3) in font [lmroman12-bold]:mapping=tex-\ntext;!\nMissing character: There is no ▶ (U+25B6) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\n[38]\nMissing character: There is no ⏱ (U+23F1) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no ️ (U+FE0F) in font [lmroman10-bold]:mapping=tex-\ntext;!\nMissing character: There is no 📍 (U+1F4CD) in font [lmroman10-bold]:mapping=tex\n-text;!\nMissing character: There is no 📌 (U+1F4CC) in font [lmroman10-regular]:mapping=\ntex-text;!\n\nOverfull \\hbox (36.725pt too wide) in paragraph at lines 3725--3728\n[]\\TU/lmr/m/n/10 To run our package make sure that gazebo simulator is running.\n Then we can run the \\TU/lmtt/m/n/10 panda_moveit_config/launch/demo.launch.py\n\nUnderfull \\hbox (badness 1231) in paragraph at lines 3745--3756\n\\TU/lmr/m/n/10 The folder[][]\\TU/lmtt/m/n/10 custom_motion_planning_python_api[\n][] \\TU/lmr/m/n/10 has scripting files that plans and executes motions for a pa\nnda\n\nOverfull \\hbox (37.46501pt too wide) in paragraph at lines 3745--3756\n\\TU/lmtt/m/n/10 motion_planning_python_api_planning_scene.py \\TU/lmr/m/n/10 is \nan original demo from moveit2 - \\TU/lmtt/m/n/10 motion_planning_python_api_tuto\nrial.py\n[39]\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\nMissing character: There is no π (U+03C0) in font [lmroman10-regular]:mapping=t\nex-text;!\n\nUnderfull \\hbox (badness 1622) in paragraph at lines 3884--3884\n[]\\TU/lmr/bx/n/10 Deterministic, Disentanglement One-parameter Object Movements\n (one_object_deterministic\n[40]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4055--4059\n\n[41]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4092--4095\n\n\nUnderfull \\hbox (badness 10000) in paragraph at lines 4126--4129\n\n\nLaTeX Warning: Hyper reference `models' on page 42 undefined on input line 4183\n.\n\n[42]\nOverfull \\hbox (113.24pt too wide) in paragraph at lines 4243--4245\n[]\\TU/lmr/m/n/10 You can replay_motion each motion data separately: \\TU/lmtt/m/\nn/10 ./control.sh replay_motion DATASET_PROCESSED/EVAL/motion_data/AAAAAAA_moti\non.json \n\nOverfull \\hbox (44.4639pt too wide) in paragraph at lines 4314--4319\n\\TU/lmr/m/n/10 A summary report of the session is also generated and will be sa\nved inside \\TU/lmtt/m/n/10 pose_to_motion/{$model_type}/output/train_report.csv\n \n\nOverfull \\hbox (64.365pt too wide) in paragraph at lines 4320--4326\n[]\\TU/lmr/m/n/10 There are two options for using the data and training a model.\n The resulting model is saved in \\TU/lmtt/m/n/10 {$model_type}/output/saved_mod\nel_states\\TU/lmr/m/n/10 .\n[43] [44] [45] [46]\nOverfull \\hbox (140.47499pt too wide) in paragraph at lines 4583--4583\n[]\\TU/lmtt/m/n/10 [gzserver-1] [ERROR] [1727951819.671190014] [jackal.gazebo_ro\ns2_control]: controller manager doesn[]t have an update_rate parameter[] \n\nOverfull \\hbox (289.36447pt too wide) in paragraph at lines 4599--4604\n\\TU/lmtt/m/n/10 docker compose \\TU/lmr/m/n/10 or \\TU/lmtt/m/n/10 docker-compose\n \\TU/lmr/m/n/10 is set correctly in the setting. [] \n[47] [48]\nOverfull \\hbox (313.72499pt too wide) in paragraph at lines 4645--4645\n[]\\TU/lmtt/m/n/10 nvidia-container-cli: requirement error: unsatisfied conditio\nn: cuda>=12.6, please update your driver to a newer version, or use an earlier \ncuda container: unknown[] \n\nOverfull \\hbox (124.72499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLdispatch.so.0)[] \n\nOverfull \\hbox (87.97499pt too wide) in paragraph at lines 4658--4658\n[]\\TU/lmtt/m/n/10 $/usr/lib/x86_64-linux-gnu/libc.so.6: version []GLIBC_2.38[] \nnot found (required by /usr/lib/x86_64-linux-gnu/libGLX.so.0)[] \n\nOverfull \\hbox (3.97499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get remove --purge nvidia-container-toolkit nvidia-\ncontainer-toolkit-base libnvidia-container*[] \n\nOverfull \\hbox (292.72499pt too wide) in paragraph at lines 4667--4667\n[]\\TU/lmtt/m/n/10 $sudo apt-get install nvidia-container-toolkit=1.17.4-1 nvidi\na-container-toolkit-base=1.17.4-1 libnvidia-container1=1.17.4-1 libnvidia-conta\niner-tools=1.17.4-1[] \n[49]\nUnderfull \\hbox (badness 1609) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “high-level_diagram_SIMLAN.drawio.png” ### Humanoid_mocap_flow.d\nrawio “Humanoid_mocap_flow.drawio.png”\n\nUnderfull \\hbox (badness 6461) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### legend.drawio “legend.drawio.png” ### ros2 launch aruco_loca\nlization multi_detection.launch.py.drawio\n\nUnderfull \\hbox (badness 4518) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 “ros2 launch aruco_localization multi_detection.launch.py.drawio\n.png” ### ros2 launch camera_bird_eye_view\n\nOverfull \\hbox (8.435pt too wide) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 launch moveit_resources_panda_moveit_config demo.launch.py.drawi\no “ros2 launch moveit_resources_panda_moveit_config\n\nUnderfull \\hbox (badness 3229) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 demo.launch.py.drawio.png” ### ros2 launch pallet_truck_bringup \nmultiple_robot_spawn.launch.py.drawio “ros2\n\nUnderfull \\hbox (badness 5217) in paragraph at lines 4808--4833\n\\TU/lmr/m/n/10 ### ros2 launch visualize_real_data scenario_replayer.launch.py.\ndrawio “ros2 launch visualize_real_data sce-\n[50]\nUnderfull \\hbox (badness 10000) in paragraph at lines 4935--4942\n[]\\TU/lmr/m/n/10 Camera projection: - https://github.com/polygon-software/pytho\nn-visual-odometry/blob/master/Chapter%203%20-\n\nOverfull \\hbox (41.115pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 %20Camera%20Projection.ipynb - https://classic.gazebosim.org/tut\norials?tut=camera_distortion - https://learnopencv.com/rotation-\n\nOverfull \\hbox (160.00499pt too wide) in paragraph at lines 4935--4942\n\\TU/lmr/m/n/10 matrix-to-euler-angles/ - https://www.geeksforgeeks.org/calibrat\necamera-opencv-in-python/ - https://docs.opencv.org/4.x/dc/dbb/tutorial_py_cali\nbration.html\n[51] (/tmp/media-e0c46393b624552d/input.aux)\n\nLaTeX Warning: There were undefined references.\n\n )\n(see the transcript file for additional information)\nOutput written on /tmp/media-e0c46393b624552d/input.pdf (51 pages).\nTranscript written on /tmp/media-e0c46393b624552d/input.log.\n",
        "description": "LaTeX output"
    },
    {
        "type": "MakePDFWarning",
        "verbosity": "WARNING",
        "message": "LaTeX Warning: Hyper reference `models' on page 42 undefined\non input line 4183."
    },
    {
        "type": "MakePDFWarning",
        "verbosity": "WARNING",
        "message": "LaTeX Warning: There were undefined references."
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚀 (U+1F680) (U+1F680) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚀 (U+1F680) (U+1F680) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📌 (U+1F4CC) (U+1F4CC) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📌 (U+1F4CC) (U+1F4CC) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚦 (U+1F6A6) (U+1F6A6) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚦 (U+1F6A6) (U+1F6A6) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🔄 (U+1F504) (U+1F504) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🔄 (U+1F504) (U+1F504) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 💥 (U+1F4A5) (U+1F4A5) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 💥 (U+1F4A5) (U+1F4A5) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🎬 (U+1F3AC) (U+1F3AC) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🎬 (U+1F3AC) (U+1F3AC) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ⏳ (U+23F3) (U+23F3) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ⏳ (U+23F3) (U+23F3) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ▶ (U+25B6) (U+25B6) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ▶ (U+25B6) (U+25B6) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ▶ (U+25B6) (U+25B6) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◉ (U+25C9) (U+25C9) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◯ (U+25EF) (U+25EF) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◯ (U+25EF) (U+25EF) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◯ (U+25EF) (U+25EF) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◉ (U+25C9) (U+25C9) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◯ (U+25EF) (U+25EF) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ◯ (U+25EF) (U+25EF) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ☑ (U+2611) (U+2611) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ☑ (U+2611) (U+2611) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ☐ (U+2610) (U+2610) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ☑ (U+2611) (U+2611) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ├ (U+251C) (U+251C) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no │ (U+2502) (U+2502) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no └ (U+2514) (U+2514) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ─ (U+2500) (U+2500) in font [lmmono10-regular]:!"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚀 (U+1F680) (U+1F680) in font [lmroman12-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📌 (U+1F4CC) (U+1F4CC) in font [lmroman12-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚦 (U+1F6A6) (U+1F6A6) in font [lmroman12-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🚀 (U+1F680) (U+1F680) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ⚡ (U+26A1) (U+26A1) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 💥 (U+1F4A5) (U+1F4A5) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🔄 (U+1F504) (U+1F504) in font [lmroman12-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📐 (U+1F4D0) (U+1F4D0) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🏎 (U+1F3CE) (U+1F3CE) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 💠 (U+1F4A0) (U+1F4A0) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 💥 (U+1F4A5) (U+1F4A5) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 🎬 (U+1F3AC) (U+1F3AC) in font [lmroman12-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ⏳ (U+23F3) (U+23F3) in font [lmroman12-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ▶ (U+25B6) (U+25B6) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ⏱ (U+23F1) (U+23F1) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no ️ (U+FE0F) (U+FE0F) in font [lmroman10-bold]:mapping=tex-"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📍 (U+1F4CD) (U+1F4CD) in font [lmroman10-bold]:mapping=tex"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no 📌 (U+1F4CC) (U+1F4CC) in font [lmroman10-regular]:mapping="
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no π (U+03C0) (U+03C0) in font [lmroman10-regular]:mapping=t"
    },
    {
        "type": "MissingCharacter",
        "verbosity": "WARNING",
        "message": "There is no π (U+03C0) (U+03C0) in font [lmroman10-regular]:mapping=t"
    }
]