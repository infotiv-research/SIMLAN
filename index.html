<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="This simulation environment, based on the Gazebo Ignition simulator and ROS2, resembles a Volvo trucks warehouse and serves as a playground for rapid prototyping and testing of systems that rely on multi-camera setup for perception, monitoring, localization or even navigation. This project is inspired by GPSS (Generic photo-based sensor system) that utilizes ceiling mounted cameras, deep learning and computer vision algorithms, and very simple transport robots." /><meta name="author" content="Hamid Ebadi" /><link rel="canonical" href="https://infotiv-research.github.io/SIMLAN/" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>SIMLAN, Simulation for Multi-Camera Robotics</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "SIMLAN, Simulation for Multi-Camera Robotics";
        var mkdocs_page_input_path = "README.md";
        var mkdocs_page_url = "/SIMLAN/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/bash.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/c.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> SIMLAN, Simulation for Multi-Camera Robotics
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="./search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href=".">SIMLAN, Simulation for Multi-Camera Robotics</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#simlan-features-simlan-demo">SIMLAN Features   [ SIMLAN demo]</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#installation-demo">Installation [ Demo]</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#dependencies">Dependencies</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#quick-start">Quick Start</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#gpss-controls-pallet-trucks-aruco-demo">GPSS controls (pallet trucks, aruco) [ Demo]</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#rita-controls-humanoid-robotic-arm-demo">RITA controls (humanoid, robotic arm) [ Demo]</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#arm-controls">Arm controls</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#testing">Testing</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#advanced-options">Advanced options</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#customized-startup">Customized startup</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#world-fidelity">World fidelity</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#filtering-log-output">Filtering log output</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#older-versions">Older versions</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#documentation">Documentation</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#research-funding">Research Funding</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="dependencies/">Dependencies</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="contributing/">Contributing</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="config_generation/">Config Generation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Simulation</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/simlan_gazebo_environment/worlds/">Gazebo Worlds</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/static_agent_launcher/">GPSS cameras</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/camera_bird_eye_view/">Camera Bird Eye View</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/aruco_localization/">Aruco Localization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/bt_failsafe/">Failsafe</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/simlan_bringup/">SIMLAN Bringup</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Pallet Truck</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="simulation/pallet_truck/">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="simulation/pallet_truck/pallet_truck_bringup/">Bringup</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="simulation/pallet_truck/pallet_truck_description/urdf/">URDF</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="simulation/pallet_truck/pallet_truck_control/">Control</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="simulation/pallet_truck/pallet_truck_navigation/">Navigation</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="#">Humanoid Robot</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="simulation/humanoid_robot/">Overview</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="simulation/humanoid_support_moveit_config/">Humanoid Moveit</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/moveit2/">Panda MoveIt2</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/object_mover/">Object Mover</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Humanoid Motion Capture Utility</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="humanoid_utility/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="humanoid_utility/pose_to_motion/autogluon/">Pose to Motion AutoGluon model</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Models</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/raw_models/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/raw_models/objects/">Object Modeling</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="simulation/raw_models/warehouse/">Warehouse Specification</a>
                  </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="credits/">Credits</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Appendix</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="CHANGELOG/">Changelog</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="resources/ISSUES/">Issues</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="resources/diagrams/">Diagrams</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">SIMLAN, Simulation for Multi-Camera Robotics</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">SIMLAN, Simulation for Multi-Camera Robotics</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/infotiv-research/SIMLAN/edit/master/docs/README.md">Edit on infotiv-research/SIMLAN</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="simlan-simulation-for-multi-camera-robotics-300">SIMLAN, Simulation for Multi-Camera Robotics (3.0.0)</h1>
<p>This simulation environment, based on the Gazebo Ignition simulator and ROS2, resembles a Volvo trucks warehouse and serves as a playground for rapid prototyping and testing of systems that rely on multi-camera setup for perception, monitoring, localization or even navigation. This project is inspired by <a href="https://www.volvogroup.com/en/news-and-media/news/2024/nov/ai-modern-manufacturing.html">GPSS (Generic photo-based sensor system)</a> that utilizes ceiling mounted cameras, deep learning and computer vision algorithms, and very simple transport robots.
[<a href="https://www.youtube.com/watch?v=DA7lKiCdkCc"><img alt="" src="/resources/logos/youtube.png" /> GPSS demo</a>]</p>
<h2 id="simlan-features-simlan-demo">SIMLAN Features   [<a href="https://www.youtube.com/watch?v=mhA51PPdABc"><img alt="" src="/resources/logos/youtube.png" /> SIMLAN demo</a>]</h2>
<ul>
<li>Ignition Gazebo</li>
<li>Library of assets</li>
<li>Real-World environment inspired design (camera position and warehouse layout)</li>
<li>ROS 2 interfaces (Humble and Jazzy)</li>
<li>ArUco marker localization</li>
<li>Simple GPSS (Generic Photo-based Sensor System) navigation</li>
<li>Multi-Robot localization and navigation using Nav2</li>
<li>Bird's-Eye view projection</li>
<li>Multi-Sensor Support (LiDAR, RGB camera, semantic segmentation, Depth etc.)</li>
<li>Geofencing for safe zones and safestop on collision</li>
<li>Motion capture for Human-Robot Collaboration/Interaction (HRC/HRI)</li>
</ul>
<p>Please click the youTube link below to view the SIMLAN demo video:</p>
<p><img alt="SIMLAN, Simulation for Indoor Multi-Camera Localization and Navigation" src="resources/demo.png" /></p>
<p>Here are list of advantages of using SIMLAN Multi-Camera system</p>
<ul>
<li>Rapid prototyping and iteration of ML based algorithm. (e.g. reinforcement learning)</li>
<li>Enhanced monitoring and coordination using bird eye view</li>
<li>Simplified robot design and maintenance.</li>
<li>Extendible with additional ML based vision systems</li>
<li>Safety testing without physical risk or privacy concerns</li>
<li>Scalable and reproducible testing (CI/CD)</li>
<li>Cost-effective development</li>
</ul>
<h2 id="installation-demo">Installation [<a href="https://www.youtube.com/watch?v=DgJXlsXUa-w"><img alt="" src="/resources/logos/youtube.png" /> Demo</a>]</h2>
<h3 id="dependencies">Dependencies</h3>
<p><strong>Ubuntu 24.04:</strong> use instruction in <a href="dependencies/#linux-dependencies">dependencies.md#linux-dependencies</a> to install docker and ensure that your linux user account has <code>docker</code> access.
<em>Attention</em>: Make sure to restart the computer (for the changes in group membership to take effect.) before proceeding to the next step.</p>
<p><strong>Windows 11:</strong> use instruction in <a href="dependencies/#windows-dependencies">dependencies.md#windows-dependencies</a> to install dependencies.</p>
<p><strong>Production environment</strong>: follow installation procedure used in <a href=".devcontainer/Dockerfile">.devcontainer/Dockerfile</a> to install dependencies.</p>
<p><strong>Development environment</strong>: to improve collaboration we use vscode and docker as explained in <a href="https://www.allisonthackston.com/articles/docker-development.html">this instruction</a> and <a href="https://github.com/athackst/dockerfiles">docker files</a>.
Install Visual Studio Code (VS Code) and open the project folder. VS Code will prompt you to install the required extension dependencies.
Make sure the <code>Dev containers</code> extension is installed. Reopen the project in VS Code, and you will be prompted to rebuild the container. Accept the prompt, this process may take a few minutes.
Once VS Code is connected to Docker (as shown in the image below), open the terminal and run the following commands:</p>
<p><img alt="dev container in vscode" src="resources/vscode.png" /></p>
<p>(if you don't see this try to build manually in vscode by pressing <code>Ctrl + Shift + P</code> and select <code>Dev containers: Rebuild and Reopen in container</code>.
)</p>
<h3 id="quick-start">Quick Start</h3>
<p>The best place to learn about the various features, start different components, and understand the project structure is <a href="control.sh"><code>./control.sh</code></a>.</p>
<p><em>Attention</em>: The following commands (using <code>./control.sh</code>) are executed in a separate terminal tab inside <em>vscode</em>.</p>
<p>To kill all the relevant process (related to gazebo, ros2), delete build files, delete recorded images and rosbag files using the following command:</p>
<pre><code class="language-bash">./control.sh clean
</code></pre>
<p>To clean up and build the ros2 simulation</p>
<pre><code class="language-bash">./control.sh build
</code></pre>
<p>(optionally, in vscode you can click on Terminal-&gt; Run Task/Run build Task or use <code>Ctrl + Shift + B</code>)</p>
<h2 id="gpss-controls-pallet-trucks-aruco-demo">GPSS controls (pallet trucks, aruco) [<a href="https://www.youtube.com/watch?v=_UhRFR-L9iQ"><img alt="" src="/resources/logos/youtube.png" /> Demo</a>]</h2>
<p>It is possible for the cameras to detect ArUco markers on the floor and publish their location to TF, both relative to the camera, and the ArUcos transform from origin. The package <a href="./camera_utility/aruco_localization">./camera_utility/aruco_localization</a> contain the code for handling ArUco detection.</p>
<p>You can also use nav2 to make a robot_agent (that can be either robot/pallet_truck) navigate by itself to a goal position. You can find the code in <a href="simulation/pallet_truck/pallet_truck_navigation">simulation/pallet_truck/pallet_truck_navigation</a></p>
<p><strong>Run these three in separate terminals</strong></p>
<pre><code class="language-bash">./control.sh gpss # spawn the simulation, robot_agents and GPSS ArUco detection
./control.sh nav  # spawn map server, and separate nav2 stack in a separate namespace for each robot_agent
./control.sh send_goal # send navigation goals to nav2 stack for each robot_agent
</code></pre>
<p>If you want to control any robot (pallet truck, humanoid, etc) manually you can run the following command. Remember to specify what robot you want to control by adding its namespace as argument, i.e. <code>./control.sh teleop pallet_truck_1</code></p>
<pre><code class="language-bash">./control.sh teleop ${YOUR_ROBOT_NAMESPACE}
</code></pre>
<p>If you want to record any of your topics during the tests you can run the following command. Change the topic in the control.sh script: <code>ros2 bag record /topic</code> to whatever topic you want to record.</p>
<pre><code class="language-bash">./control.sh ros_record
</code></pre>
<p>To replay your latest recorded rosbag run the following command:</p>
<pre><code class="language-bash">./control.sh ros_replay
</code></pre>
<p>If you want to do a camera dump and save the image from each camera as a .png run the following command. The images will appear at <code>/src/camera_utility/camera_number</code>.</p>
<pre><code class="language-bash">./control.sh camera_dump
</code></pre>
<p><img alt="" src="/resources/different-views.png" /></p>
<p>If you want to take a screenshot of one of the cameras view, run the following command. Replace <code>###</code> with the camera you want to take a screenshot of. (163, 164, 165 or 166)</p>
<pre><code class="language-bash">./control.sh screenshot ###
</code></pre>
<pre><code class="language-bash">./control.sh birdeye
</code></pre>
<p><img alt="" src="/resources/stitched.png" /></p>
<p>If you want to add the tf links between the cameras and the ArUco markers without running the <code>gpss</code> command you can run the following command. This is not that usable as the <code>gpss</code> run this as well, but it can be good for debugging.</p>
<pre><code class="language-bash">./control.sh aruco_detection
</code></pre>
<p>Finally, to view the bird's-eye perspective from each camera, run the following command and open <code>rviz</code> Then, navigate to the scroll menu to the left, and under "Camera" change the Topic <code>/static_agents/camera_XXX/image_projected</code> topic to visualize the corresponding camera feed:</p>
<p><img alt="" src="/resources/aruco_localisation.png" /></p>
<h2 id="rita-controls-humanoid-robotic-arm-demo">RITA controls (humanoid, robotic arm) [<a href="https://www.youtube.com/watch?v=EiCNiPeifPk"><img alt="" src="/resources/logos/youtube.png" /> Demo</a>]</h2>
<pre><code class="language-bash">./control.sh humanoid
</code></pre>
<p>To move humanoid around in the simulator</p>
<pre><code class="language-bash">./control.sh teleop ${YOUR_HUMANOID_NAMESPACE}
</code></pre>
<p><img alt="" src="/resources/arm-humanoid.png" /></p>
<h4 id="arm-controls">Arm controls</h4>
<p>Spawn the Panda arm inside SIMLAN and instruct it to pick and place a box around with the following commands:</p>
<pre><code>./control panda
./control plan_motion
./control pick
</code></pre>
<h2 id="testing">Testing</h2>
<p>Integration tests can be found inside of the <a href="./integration_tests/test/">test</a> package. Running the tests help maintain the project's quality. For more information about how the tests are setup, checkout the package <a href="integration_tests/">README</a> To run all tests, run the following command:</p>
<pre><code>./control.sh test
</code></pre>
<h2 id="advanced-options">Advanced options</h2>
<p>See <a href="resources/ISSUES/">resources/ISSUES.md</a> to learn about additional advanced options and to check known issues before reporting any issue or requesting new features. To start the project <strong>without NVIDIA GPU</strong> please comment out these lines in <code>docker-compose.yaml</code> as shown below:</p>
<pre><code class="language-bash">  #   runtime: nvidia
  #
  # factory_simulation_nvidia:
  #  &lt;&lt;: *research-base
  #  container_name: factory_simulation_nvidia
  #  runtime: nvidia
  #  deploy:
  #    resources:
  #      reservations:
  #        devices:
  #          - driver: nvidia
  #            count: &quot;all&quot;
  #            capabilities: [compute,utility,graphics,display]
</code></pre>
<p><code>camera_enabled_ids</code> specifies which cameras are enabled in the scene for ArUco code detection and birdeye view.</p>
<h3 id="customized-startup">Customized startup</h3>
<p>In <code>config.sh</code> it is possible to customize your scenarios. From there you can edit what world you want to run, how many cameras you want enabled, and also edit Humanoid related properties. Modifying these variables are preferred, rather than modifying the <code>control.sh</code> file.</p>
<h3 id="world-fidelity">World fidelity</h3>
<p>in the <code>config.sh</code> script, you can adjust the world fidelity</p>
<p>The active worlds are:</p>
<table>
<thead>
<tr>
<th>arguments</th>
<th>configuration</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>default</code></td>
<td>Contains the default world with maximum objects</td>
</tr>
<tr>
<td><code>medium</code></td>
<td>Based on default but boxes are removed</td>
</tr>
<tr>
<td><code>light</code></td>
<td>Based on medium but shelves are removed</td>
</tr>
<tr>
<td><code>empty</code></td>
<td>Everything except the ground is removed</td>
</tr>
</tbody>
</table>
<h3 id="filtering-log-output">Filtering log output</h3>
<p>In <code>config.sh</code> you can set the level of logs you want outputted into the terminal. Per default it is set to "info" to allow all logs. Possible values are: "debug", "info", "warn", and "error". Setting it to "warn" filters out all debug and info messages. Additionally, to filter out specific lines you can add the phrase you want filtered, inside of <code>log_blacklist.txt</code> and setting the <code>log_level</code> flag to "warn" or "error" will start filtering out all phrases found in the blacklist.</p>
<h3 id="older-versions">Older versions</h3>
<ul>
<li><a href="https://github.com/infotiv-research/SIMLAN/tree/gz_classic_humble"><code>gz_classic_humble</code></a> branch contain code for  <strong>Gazebo Classic (Gazebo11)</strong> that has reached end-of-life (EOL).</li>
<li><a href="https://github.com/infotiv-research/SIMLAN/tree/ign_humble"><code>ign_humble</code></a> branch contain code for  <strong>ROS2 humble &amp; Gazebo ignition</strong>, an earlier version of this repository.</li>
</ul>
<h2 id="documentation">Documentation</h2>
<p>Learn more about the project by reading these documents:</p>
<ul>
<li>
<p><a href="control.sh"><code>control.sh</code> script</a> is  a shortcut to run different launch scripts, please also see <a href="resources/diagrams/">these diagram</a>.</p>
</li>
<li>
<p><a href="config.sh"><code>config.sh</code></a> contains information about, which world is loaded, which cameras are active, what and where the robots are spawned.</p>
</li>
<li>
<p><a href="PRESENTATION.md">Marp Markdown Presentation</a></p>
</li>
<li>
<p><a href="simulation/pallet_truck/pallet_truck_navigation/">Pallet Truck Navigation Documentation</a></p>
</li>
<li>
<p><a href="camera_utility/">Camera Utilities and notebooks</a>:  (<a href="camera_utility/camera_calib.ipynb">Extrinsic/Intrinsic calibrations</a> and <a href="camera_utility/projection.ipynb">Projection</a> )</p>
</li>
<li>
<p><a href="humanoid_utility/">Humanoid Utilities (pose2motion)</a></p>
</li>
<li>
<p><a href="config_generation/">Configuration Generation</a></p>
</li>
<li>
<p><a href="simulation/"><code>simulation/</code></a>: ROS2 packages</p>
</li>
<li>
<p><a href="simulation/">Simulation and Warehouse Specification (fidelity)</a></p>
</li>
<li><a href="simulation/raw_models/">Building Gazebo models (Blender/Phobos)</a></li>
<li><a href="simulation/raw_models/objects/">Objects Specifications</a></li>
<li><a href="simulation/raw_models/warehouse/">Warehouse Specification</a></li>
<li><a href="simulation/aruco_localization/">Aruco Localization Documentation</a></li>
<li><a href="simulation/humanoid_robot/">humanoid_robot Simulation</a></li>
<li><a href="simulation/bt_failsafe/">Geofencing and Collision safe stop</a></li>
<li><a href="simulation/visualize_real_data/">Visualize Real Data</a> <strong>requires data from Volvo</strong></li>
<li>
<p><a href="simulation/humanoid_support_moveit_config/">Humanoid Control</a></p>
</li>
<li>
<p><a href="CHANGELOG/"><code>CHANGELOG.md</code></a></p>
</li>
<li>
<p><a href="credits/"><code>credits.md</code></a></p>
</li>
<li>
<p><a href="LICENSE"><code>LICENSE</code> (apache 2)</a></p>
</li>
<li>
<p><a href="contributing/"><code>contributing.md</code></a></p>
</li>
</ul>
<h2 id="research-funding">Research Funding</h2>
<p>This work was carried out within these research projects:</p>
<ul>
<li>The <a href="https://www.vinnova.se/p/smile-iv/">SMILE IV</a> project financed by Vinnova, FFI, Fordonsstrategisk forskning och innovation under the grant number 2023-00789.</li>
<li>The EUREKA ITEA4 <a href="https://www.vinnova.se/p/artwork---the-smart-and-connected-worker/">ArtWork</a> - The smart and connected worker financed by Vinnova under the grant number 2023-00970.</li>
</ul>
<table>
<thead>
<tr>
<th>INFOTIV AB</th>
<th>Dyno-robotics</th>
<th>RISE Research Institutes of Sweden</th>
<th>CHALMERS</th>
<th>Volvo Group</th>
</tr>
</thead>
<tbody>
<tr>
<td><img alt="" src="resources/logos/INFOTIV-logo.png" /></td>
<td><img alt="" src="resources/logos/dyno-robotics.png" /></td>
<td><img alt="" src="resources/logos/RISE-logo.png" /></td>
<td><img alt="" src="resources/logos/CHALMERS-logo.png" /></td>
<td><img alt="" src="resources/logos/volvo.jpg" /></td>
</tr>
</tbody>
</table>
<p><a href="https://github.com/infotiv-research/SIMLAN">SIMLAN</a> project is started and is currently maintained by <a href="https://github.com/ebadi">Hamid Ebadi</a>. To see a complete list of contributors see  the <a href="CHANGELOG/">changelog</a>.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="dependencies/" class="btn btn-neutral float-right" title="Dependencies">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
      <span><a href="dependencies/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="js/jquery-3.6.0.min.js"></script>
    <script>var base_url = ".";</script>
    <script src="js/theme_extra.js"></script>
    <script src="js/theme.js"></script>
      <script src="search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>

<!--
MkDocs version : 1.5.3
Build Date UTC : 2025-11-14 08:11:54.813878+00:00
-->
